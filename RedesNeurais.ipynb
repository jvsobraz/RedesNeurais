{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOvoG4P7OSK643/IpxeiBAU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Dica 1) A quantidade de neurônios ocultos deve estar entre a\n","quantidade de entrada e a de saída.\n","\n","Podemos utilizar uma média para isso:\n","\n","**N° neurônios camada oculta = (no entrada + no saída) / 2**\n","\n","Dica 2) O número de neurônios ocultos deve ser 2⁄3 da camada de\n","entrada + o número de neurônios da camada de saída:\n","\n","**N° neurônios camada oculta = (no entrada) * 2/3 + (no saída)**\n","\n","Dica 3) O número de neurônios ocultos precisa ser menor que o\n","dobro da quantidade de neurônios da camada de entrada\n","\n","**N° neurônios camada oculta < 2 * (no entrada)**\n","\n","Biblioteca para estudo:\n","\n","**Scikitlearn**"],"metadata":{"id":"5FiV4mpTTFg-"}},{"cell_type":"code","source":["from sklearn.neural_network import MLPClassifier\n","from sklearn import datasets\n","\n","iris = datasets.load_iris()"],"metadata":{"id":"_Bh3CioLYn2E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["entradas = iris.data\n","saidas = iris.target"],"metadata":{"id":"lfJ12EA3YyP7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["redeneural = MLPClassifier(verbose=True,\n","                           max_iter=10000,\n","                           tol=0.000001,\n","                           activation='relu',\n","                           #hdden_layer_sizes=(30,30,30),\n","                           learning_rate_init=0.0001)"],"metadata":{"id":"9Dxjr6Pya3Yf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["redeneural.fit(entradas, saidas)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"W_J8Vn1CbNz3","executionInfo":{"status":"ok","timestamp":1678450252182,"user_tz":180,"elapsed":17320,"user":{"displayName":"João Vitor Braz","userId":"02116333837339986756"}},"outputId":"fc1198ea-2a1a-4aa3-9900-5d1aa6a797f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n","Iteration 5001, loss = 0.06547383\n","Iteration 5002, loss = 0.06546060\n","Iteration 5003, loss = 0.06544734\n","Iteration 5004, loss = 0.06543405\n","Iteration 5005, loss = 0.06542082\n","Iteration 5006, loss = 0.06540754\n","Iteration 5007, loss = 0.06539437\n","Iteration 5008, loss = 0.06538122\n","Iteration 5009, loss = 0.06536801\n","Iteration 5010, loss = 0.06535479\n","Iteration 5011, loss = 0.06534154\n","Iteration 5012, loss = 0.06532844\n","Iteration 5013, loss = 0.06531529\n","Iteration 5014, loss = 0.06530201\n","Iteration 5015, loss = 0.06528890\n","Iteration 5016, loss = 0.06527575\n","Iteration 5017, loss = 0.06526263\n","Iteration 5018, loss = 0.06524951\n","Iteration 5019, loss = 0.06523641\n","Iteration 5020, loss = 0.06522333\n","Iteration 5021, loss = 0.06521023\n","Iteration 5022, loss = 0.06519715\n","Iteration 5023, loss = 0.06518407\n","Iteration 5024, loss = 0.06517105\n","Iteration 5025, loss = 0.06515802\n","Iteration 5026, loss = 0.06514495\n","Iteration 5027, loss = 0.06513200\n","Iteration 5028, loss = 0.06511893\n","Iteration 5029, loss = 0.06510597\n","Iteration 5030, loss = 0.06509304\n","Iteration 5031, loss = 0.06508005\n","Iteration 5032, loss = 0.06506706\n","Iteration 5033, loss = 0.06505404\n","Iteration 5034, loss = 0.06504110\n","Iteration 5035, loss = 0.06502817\n","Iteration 5036, loss = 0.06501519\n","Iteration 5037, loss = 0.06500230\n","Iteration 5038, loss = 0.06498939\n","Iteration 5039, loss = 0.06497645\n","Iteration 5040, loss = 0.06496365\n","Iteration 5041, loss = 0.06495074\n","Iteration 5042, loss = 0.06493784\n","Iteration 5043, loss = 0.06492502\n","Iteration 5044, loss = 0.06491217\n","Iteration 5045, loss = 0.06489930\n","Iteration 5046, loss = 0.06488640\n","Iteration 5047, loss = 0.06487378\n","Iteration 5048, loss = 0.06486098\n","Iteration 5049, loss = 0.06484802\n","Iteration 5050, loss = 0.06483529\n","Iteration 5051, loss = 0.06482262\n","Iteration 5052, loss = 0.06480989\n","Iteration 5053, loss = 0.06479714\n","Iteration 5054, loss = 0.06478436\n","Iteration 5055, loss = 0.06477156\n","Iteration 5056, loss = 0.06475873\n","Iteration 5057, loss = 0.06474598\n","Iteration 5058, loss = 0.06473332\n","Iteration 5059, loss = 0.06472051\n","Iteration 5060, loss = 0.06470784\n","Iteration 5061, loss = 0.06469516\n","Iteration 5062, loss = 0.06468252\n","Iteration 5063, loss = 0.06466987\n","Iteration 5064, loss = 0.06465721\n","Iteration 5065, loss = 0.06464453\n","Iteration 5066, loss = 0.06463190\n","Iteration 5067, loss = 0.06461928\n","Iteration 5068, loss = 0.06460672\n","Iteration 5069, loss = 0.06459405\n","Iteration 5070, loss = 0.06458149\n","Iteration 5071, loss = 0.06456893\n","Iteration 5072, loss = 0.06455633\n","Iteration 5073, loss = 0.06454378\n","Iteration 5074, loss = 0.06453119\n","Iteration 5075, loss = 0.06451878\n","Iteration 5076, loss = 0.06450621\n","Iteration 5077, loss = 0.06449366\n","Iteration 5078, loss = 0.06448121\n","Iteration 5079, loss = 0.06446872\n","Iteration 5080, loss = 0.06445620\n","Iteration 5081, loss = 0.06444366\n","Iteration 5082, loss = 0.06443120\n","Iteration 5083, loss = 0.06441874\n","Iteration 5084, loss = 0.06440627\n","Iteration 5085, loss = 0.06439387\n","Iteration 5086, loss = 0.06438143\n","Iteration 5087, loss = 0.06436897\n","Iteration 5088, loss = 0.06435653\n","Iteration 5089, loss = 0.06434412\n","Iteration 5090, loss = 0.06433173\n","Iteration 5091, loss = 0.06431937\n","Iteration 5092, loss = 0.06430703\n","Iteration 5093, loss = 0.06429466\n","Iteration 5094, loss = 0.06428226\n","Iteration 5095, loss = 0.06426995\n","Iteration 5096, loss = 0.06425761\n","Iteration 5097, loss = 0.06424527\n","Iteration 5098, loss = 0.06423296\n","Iteration 5099, loss = 0.06422065\n","Iteration 5100, loss = 0.06420831\n","Iteration 5101, loss = 0.06419612\n","Iteration 5102, loss = 0.06418378\n","Iteration 5103, loss = 0.06417156\n","Iteration 5104, loss = 0.06415936\n","Iteration 5105, loss = 0.06414706\n","Iteration 5106, loss = 0.06413481\n","Iteration 5107, loss = 0.06412253\n","Iteration 5108, loss = 0.06411030\n","Iteration 5109, loss = 0.06409808\n","Iteration 5110, loss = 0.06408589\n","Iteration 5111, loss = 0.06407373\n","Iteration 5112, loss = 0.06406154\n","Iteration 5113, loss = 0.06404937\n","Iteration 5114, loss = 0.06403711\n","Iteration 5115, loss = 0.06402516\n","Iteration 5116, loss = 0.06401304\n","Iteration 5117, loss = 0.06400075\n","Iteration 5118, loss = 0.06398869\n","Iteration 5119, loss = 0.06397668\n","Iteration 5120, loss = 0.06396462\n","Iteration 5121, loss = 0.06395253\n","Iteration 5122, loss = 0.06394041\n","Iteration 5123, loss = 0.06392826\n","Iteration 5124, loss = 0.06391609\n","Iteration 5125, loss = 0.06390394\n","Iteration 5126, loss = 0.06389216\n","Iteration 5127, loss = 0.06388021\n","Iteration 5128, loss = 0.06386809\n","Iteration 5129, loss = 0.06385581\n","Iteration 5130, loss = 0.06384395\n","Iteration 5131, loss = 0.06383207\n","Iteration 5132, loss = 0.06382015\n","Iteration 5133, loss = 0.06380820\n","Iteration 5134, loss = 0.06379622\n","Iteration 5135, loss = 0.06378423\n","Iteration 5136, loss = 0.06377229\n","Iteration 5137, loss = 0.06376027\n","Iteration 5138, loss = 0.06374821\n","Iteration 5139, loss = 0.06373617\n","Iteration 5140, loss = 0.06372421\n","Iteration 5141, loss = 0.06371241\n","Iteration 5142, loss = 0.06370043\n","Iteration 5143, loss = 0.06368851\n","Iteration 5144, loss = 0.06367669\n","Iteration 5145, loss = 0.06366483\n","Iteration 5146, loss = 0.06365295\n","Iteration 5147, loss = 0.06364105\n","Iteration 5148, loss = 0.06362913\n","Iteration 5149, loss = 0.06361741\n","Iteration 5150, loss = 0.06360561\n","Iteration 5151, loss = 0.06359365\n","Iteration 5152, loss = 0.06358195\n","Iteration 5153, loss = 0.06357024\n","Iteration 5154, loss = 0.06355849\n","Iteration 5155, loss = 0.06354671\n","Iteration 5156, loss = 0.06353492\n","Iteration 5157, loss = 0.06352309\n","Iteration 5158, loss = 0.06351126\n","Iteration 5159, loss = 0.06349940\n","Iteration 5160, loss = 0.06348795\n","Iteration 5161, loss = 0.06347631\n","Iteration 5162, loss = 0.06346450\n","Iteration 5163, loss = 0.06345252\n","Iteration 5164, loss = 0.06344099\n","Iteration 5165, loss = 0.06342942\n","Iteration 5166, loss = 0.06341783\n","Iteration 5167, loss = 0.06340618\n","Iteration 5168, loss = 0.06339453\n","Iteration 5169, loss = 0.06338287\n","Iteration 5170, loss = 0.06337119\n","Iteration 5171, loss = 0.06335951\n","Iteration 5172, loss = 0.06334780\n","Iteration 5173, loss = 0.06333607\n","Iteration 5174, loss = 0.06332432\n","Iteration 5175, loss = 0.06331304\n","Iteration 5176, loss = 0.06330159\n","Iteration 5177, loss = 0.06328995\n","Iteration 5178, loss = 0.06327814\n","Iteration 5179, loss = 0.06326647\n","Iteration 5180, loss = 0.06325503\n","Iteration 5181, loss = 0.06324359\n","Iteration 5182, loss = 0.06323205\n","Iteration 5183, loss = 0.06322054\n","Iteration 5184, loss = 0.06320900\n","Iteration 5185, loss = 0.06319744\n","Iteration 5186, loss = 0.06318585\n","Iteration 5187, loss = 0.06317427\n","Iteration 5188, loss = 0.06316284\n","Iteration 5189, loss = 0.06315130\n","Iteration 5190, loss = 0.06313984\n","Iteration 5191, loss = 0.06312835\n","Iteration 5192, loss = 0.06311694\n","Iteration 5193, loss = 0.06310546\n","Iteration 5194, loss = 0.06309403\n","Iteration 5195, loss = 0.06308264\n","Iteration 5196, loss = 0.06307127\n","Iteration 5197, loss = 0.06305987\n","Iteration 5198, loss = 0.06304844\n","Iteration 5199, loss = 0.06303698\n","Iteration 5200, loss = 0.06302576\n","Iteration 5201, loss = 0.06301442\n","Iteration 5202, loss = 0.06300285\n","Iteration 5203, loss = 0.06299166\n","Iteration 5204, loss = 0.06298043\n","Iteration 5205, loss = 0.06296916\n","Iteration 5206, loss = 0.06295785\n","Iteration 5207, loss = 0.06294652\n","Iteration 5208, loss = 0.06293516\n","Iteration 5209, loss = 0.06292377\n","Iteration 5210, loss = 0.06291237\n","Iteration 5211, loss = 0.06290110\n","Iteration 5212, loss = 0.06288993\n","Iteration 5213, loss = 0.06287855\n","Iteration 5214, loss = 0.06286728\n","Iteration 5215, loss = 0.06285612\n","Iteration 5216, loss = 0.06284492\n","Iteration 5217, loss = 0.06283369\n","Iteration 5218, loss = 0.06282243\n","Iteration 5219, loss = 0.06281115\n","Iteration 5220, loss = 0.06279987\n","Iteration 5221, loss = 0.06278881\n","Iteration 5222, loss = 0.06277767\n","Iteration 5223, loss = 0.06276636\n","Iteration 5224, loss = 0.06275518\n","Iteration 5225, loss = 0.06274411\n","Iteration 5226, loss = 0.06273300\n","Iteration 5227, loss = 0.06272186\n","Iteration 5228, loss = 0.06271068\n","Iteration 5229, loss = 0.06269950\n","Iteration 5230, loss = 0.06268830\n","Iteration 5231, loss = 0.06267721\n","Iteration 5232, loss = 0.06266615\n","Iteration 5233, loss = 0.06265493\n","Iteration 5234, loss = 0.06264386\n","Iteration 5235, loss = 0.06263278\n","Iteration 5236, loss = 0.06262173\n","Iteration 5237, loss = 0.06261064\n","Iteration 5238, loss = 0.06259961\n","Iteration 5239, loss = 0.06258852\n","Iteration 5240, loss = 0.06257753\n","Iteration 5241, loss = 0.06256652\n","Iteration 5242, loss = 0.06255549\n","Iteration 5243, loss = 0.06254442\n","Iteration 5244, loss = 0.06253360\n","Iteration 5245, loss = 0.06252258\n","Iteration 5246, loss = 0.06251146\n","Iteration 5247, loss = 0.06250054\n","Iteration 5248, loss = 0.06248956\n","Iteration 5249, loss = 0.06247858\n","Iteration 5250, loss = 0.06246757\n","Iteration 5251, loss = 0.06245681\n","Iteration 5252, loss = 0.06244585\n","Iteration 5253, loss = 0.06243478\n","Iteration 5254, loss = 0.06242391\n","Iteration 5255, loss = 0.06241299\n","Iteration 5256, loss = 0.06240207\n","Iteration 5257, loss = 0.06239114\n","Iteration 5258, loss = 0.06238026\n","Iteration 5259, loss = 0.06236937\n","Iteration 5260, loss = 0.06235854\n","Iteration 5261, loss = 0.06234764\n","Iteration 5262, loss = 0.06233680\n","Iteration 5263, loss = 0.06232593\n","Iteration 5264, loss = 0.06231518\n","Iteration 5265, loss = 0.06230429\n","Iteration 5266, loss = 0.06229350\n","Iteration 5267, loss = 0.06228275\n","Iteration 5268, loss = 0.06227197\n","Iteration 5269, loss = 0.06226119\n","Iteration 5270, loss = 0.06225033\n","Iteration 5271, loss = 0.06223949\n","Iteration 5272, loss = 0.06222871\n","Iteration 5273, loss = 0.06221796\n","Iteration 5274, loss = 0.06220717\n","Iteration 5275, loss = 0.06219645\n","Iteration 5276, loss = 0.06218571\n","Iteration 5277, loss = 0.06217494\n","Iteration 5278, loss = 0.06216420\n","Iteration 5279, loss = 0.06215346\n","Iteration 5280, loss = 0.06214274\n","Iteration 5281, loss = 0.06213212\n","Iteration 5282, loss = 0.06212136\n","Iteration 5283, loss = 0.06211066\n","Iteration 5284, loss = 0.06210001\n","Iteration 5285, loss = 0.06208934\n","Iteration 5286, loss = 0.06207869\n","Iteration 5287, loss = 0.06206803\n","Iteration 5288, loss = 0.06205735\n","Iteration 5289, loss = 0.06204674\n","Iteration 5290, loss = 0.06203611\n","Iteration 5291, loss = 0.06202547\n","Iteration 5292, loss = 0.06201494\n","Iteration 5293, loss = 0.06200427\n","Iteration 5294, loss = 0.06199370\n","Iteration 5295, loss = 0.06198318\n","Iteration 5296, loss = 0.06197263\n","Iteration 5297, loss = 0.06196204\n","Iteration 5298, loss = 0.06195143\n","Iteration 5299, loss = 0.06194079\n","Iteration 5300, loss = 0.06193033\n","Iteration 5301, loss = 0.06191978\n","Iteration 5302, loss = 0.06190915\n","Iteration 5303, loss = 0.06189867\n","Iteration 5304, loss = 0.06188816\n","Iteration 5305, loss = 0.06187762\n","Iteration 5306, loss = 0.06186716\n","Iteration 5307, loss = 0.06185659\n","Iteration 5308, loss = 0.06184616\n","Iteration 5309, loss = 0.06183575\n","Iteration 5310, loss = 0.06182529\n","Iteration 5311, loss = 0.06181481\n","Iteration 5312, loss = 0.06180433\n","Iteration 5313, loss = 0.06179382\n","Iteration 5314, loss = 0.06178339\n","Iteration 5315, loss = 0.06177296\n","Iteration 5316, loss = 0.06176247\n","Iteration 5317, loss = 0.06175211\n","Iteration 5318, loss = 0.06174169\n","Iteration 5319, loss = 0.06173125\n","Iteration 5320, loss = 0.06172085\n","Iteration 5321, loss = 0.06171046\n","Iteration 5322, loss = 0.06170007\n","Iteration 5323, loss = 0.06168976\n","Iteration 5324, loss = 0.06167932\n","Iteration 5325, loss = 0.06166896\n","Iteration 5326, loss = 0.06165858\n","Iteration 5327, loss = 0.06164837\n","Iteration 5328, loss = 0.06163796\n","Iteration 5329, loss = 0.06162769\n","Iteration 5330, loss = 0.06161743\n","Iteration 5331, loss = 0.06160714\n","Iteration 5332, loss = 0.06159682\n","Iteration 5333, loss = 0.06158651\n","Iteration 5334, loss = 0.06157615\n","Iteration 5335, loss = 0.06156582\n","Iteration 5336, loss = 0.06155556\n","Iteration 5337, loss = 0.06154535\n","Iteration 5338, loss = 0.06153513\n","Iteration 5339, loss = 0.06152488\n","Iteration 5340, loss = 0.06151459\n","Iteration 5341, loss = 0.06150429\n","Iteration 5342, loss = 0.06149419\n","Iteration 5343, loss = 0.06148395\n","Iteration 5344, loss = 0.06147363\n","Iteration 5345, loss = 0.06146348\n","Iteration 5346, loss = 0.06145330\n","Iteration 5347, loss = 0.06144308\n","Iteration 5348, loss = 0.06143284\n","Iteration 5349, loss = 0.06142279\n","Iteration 5350, loss = 0.06141258\n","Iteration 5351, loss = 0.06140237\n","Iteration 5352, loss = 0.06139228\n","Iteration 5353, loss = 0.06138216\n","Iteration 5354, loss = 0.06137200\n","Iteration 5355, loss = 0.06136181\n","Iteration 5356, loss = 0.06135170\n","Iteration 5357, loss = 0.06134153\n","Iteration 5358, loss = 0.06133153\n","Iteration 5359, loss = 0.06132148\n","Iteration 5360, loss = 0.06131134\n","Iteration 5361, loss = 0.06130126\n","Iteration 5362, loss = 0.06129116\n","Iteration 5363, loss = 0.06128104\n","Iteration 5364, loss = 0.06127120\n","Iteration 5365, loss = 0.06126116\n","Iteration 5366, loss = 0.06125093\n","Iteration 5367, loss = 0.06124092\n","Iteration 5368, loss = 0.06123096\n","Iteration 5369, loss = 0.06122096\n","Iteration 5370, loss = 0.06121095\n","Iteration 5371, loss = 0.06120094\n","Iteration 5372, loss = 0.06119088\n","Iteration 5373, loss = 0.06118082\n","Iteration 5374, loss = 0.06117074\n","Iteration 5375, loss = 0.06116072\n","Iteration 5376, loss = 0.06115082\n","Iteration 5377, loss = 0.06114074\n","Iteration 5378, loss = 0.06113082\n","Iteration 5379, loss = 0.06112087\n","Iteration 5380, loss = 0.06111093\n","Iteration 5381, loss = 0.06110100\n","Iteration 5382, loss = 0.06109107\n","Iteration 5383, loss = 0.06108110\n","Iteration 5384, loss = 0.06107121\n","Iteration 5385, loss = 0.06106126\n","Iteration 5386, loss = 0.06105136\n","Iteration 5387, loss = 0.06104148\n","Iteration 5388, loss = 0.06103156\n","Iteration 5389, loss = 0.06102170\n","Iteration 5390, loss = 0.06101180\n","Iteration 5391, loss = 0.06100195\n","Iteration 5392, loss = 0.06099206\n","Iteration 5393, loss = 0.06098221\n","Iteration 5394, loss = 0.06097234\n","Iteration 5395, loss = 0.06096264\n","Iteration 5396, loss = 0.06095273\n","Iteration 5397, loss = 0.06094294\n","Iteration 5398, loss = 0.06093317\n","Iteration 5399, loss = 0.06092340\n","Iteration 5400, loss = 0.06091357\n","Iteration 5401, loss = 0.06090377\n","Iteration 5402, loss = 0.06089394\n","Iteration 5403, loss = 0.06088409\n","Iteration 5404, loss = 0.06087431\n","Iteration 5405, loss = 0.06086459\n","Iteration 5406, loss = 0.06085478\n","Iteration 5407, loss = 0.06084501\n","Iteration 5408, loss = 0.06083533\n","Iteration 5409, loss = 0.06082559\n","Iteration 5410, loss = 0.06081581\n","Iteration 5411, loss = 0.06080609\n","Iteration 5412, loss = 0.06079637\n","Iteration 5413, loss = 0.06078674\n","Iteration 5414, loss = 0.06077696\n","Iteration 5415, loss = 0.06076726\n","Iteration 5416, loss = 0.06075762\n","Iteration 5417, loss = 0.06074788\n","Iteration 5418, loss = 0.06073819\n","Iteration 5419, loss = 0.06072851\n","Iteration 5420, loss = 0.06071885\n","Iteration 5421, loss = 0.06070918\n","Iteration 5422, loss = 0.06069955\n","Iteration 5423, loss = 0.06068988\n","Iteration 5424, loss = 0.06068025\n","Iteration 5425, loss = 0.06067064\n","Iteration 5426, loss = 0.06066101\n","Iteration 5427, loss = 0.06065137\n","Iteration 5428, loss = 0.06064189\n","Iteration 5429, loss = 0.06063221\n","Iteration 5430, loss = 0.06062268\n","Iteration 5431, loss = 0.06061314\n","Iteration 5432, loss = 0.06060358\n","Iteration 5433, loss = 0.06059401\n","Iteration 5434, loss = 0.06058441\n","Iteration 5435, loss = 0.06057480\n","Iteration 5436, loss = 0.06056519\n","Iteration 5437, loss = 0.06055571\n","Iteration 5438, loss = 0.06054618\n","Iteration 5439, loss = 0.06053653\n","Iteration 5440, loss = 0.06052706\n","Iteration 5441, loss = 0.06051753\n","Iteration 5442, loss = 0.06050799\n","Iteration 5443, loss = 0.06049849\n","Iteration 5444, loss = 0.06048900\n","Iteration 5445, loss = 0.06047950\n","Iteration 5446, loss = 0.06046998\n","Iteration 5447, loss = 0.06046061\n","Iteration 5448, loss = 0.06045105\n","Iteration 5449, loss = 0.06044164\n","Iteration 5450, loss = 0.06043225\n","Iteration 5451, loss = 0.06042283\n","Iteration 5452, loss = 0.06041339\n","Iteration 5453, loss = 0.06040392\n","Iteration 5454, loss = 0.06039445\n","Iteration 5455, loss = 0.06038494\n","Iteration 5456, loss = 0.06037561\n","Iteration 5457, loss = 0.06036623\n","Iteration 5458, loss = 0.06035673\n","Iteration 5459, loss = 0.06034737\n","Iteration 5460, loss = 0.06033797\n","Iteration 5461, loss = 0.06032854\n","Iteration 5462, loss = 0.06031914\n","Iteration 5463, loss = 0.06030994\n","Iteration 5464, loss = 0.06030051\n","Iteration 5465, loss = 0.06029106\n","Iteration 5466, loss = 0.06028176\n","Iteration 5467, loss = 0.06027243\n","Iteration 5468, loss = 0.06026309\n","Iteration 5469, loss = 0.06025371\n","Iteration 5470, loss = 0.06024433\n","Iteration 5471, loss = 0.06023519\n","Iteration 5472, loss = 0.06022583\n","Iteration 5473, loss = 0.06021641\n","Iteration 5474, loss = 0.06020715\n","Iteration 5475, loss = 0.06019789\n","Iteration 5476, loss = 0.06018860\n","Iteration 5477, loss = 0.06017928\n","Iteration 5478, loss = 0.06017002\n","Iteration 5479, loss = 0.06016072\n","Iteration 5480, loss = 0.06015153\n","Iteration 5481, loss = 0.06014233\n","Iteration 5482, loss = 0.06013312\n","Iteration 5483, loss = 0.06012389\n","Iteration 5484, loss = 0.06011462\n","Iteration 5485, loss = 0.06010533\n","Iteration 5486, loss = 0.06009603\n","Iteration 5487, loss = 0.06008698\n","Iteration 5488, loss = 0.06007781\n","Iteration 5489, loss = 0.06006842\n","Iteration 5490, loss = 0.06005932\n","Iteration 5491, loss = 0.06005022\n","Iteration 5492, loss = 0.06004108\n","Iteration 5493, loss = 0.06003198\n","Iteration 5494, loss = 0.06002280\n","Iteration 5495, loss = 0.06001359\n","Iteration 5496, loss = 0.06000440\n","Iteration 5497, loss = 0.05999519\n","Iteration 5498, loss = 0.05998595\n","Iteration 5499, loss = 0.05997681\n","Iteration 5500, loss = 0.05996776\n","Iteration 5501, loss = 0.05995849\n","Iteration 5502, loss = 0.05994939\n","Iteration 5503, loss = 0.05994029\n","Iteration 5504, loss = 0.05993118\n","Iteration 5505, loss = 0.05992210\n","Iteration 5506, loss = 0.05991300\n","Iteration 5507, loss = 0.05990394\n","Iteration 5508, loss = 0.05989482\n","Iteration 5509, loss = 0.05988582\n","Iteration 5510, loss = 0.05987670\n","Iteration 5511, loss = 0.05986767\n","Iteration 5512, loss = 0.05985866\n","Iteration 5513, loss = 0.05984963\n","Iteration 5514, loss = 0.05984059\n","Iteration 5515, loss = 0.05983153\n","Iteration 5516, loss = 0.05982247\n","Iteration 5517, loss = 0.05981336\n","Iteration 5518, loss = 0.05980450\n","Iteration 5519, loss = 0.05979551\n","Iteration 5520, loss = 0.05978632\n","Iteration 5521, loss = 0.05977736\n","Iteration 5522, loss = 0.05976837\n","Iteration 5523, loss = 0.05975938\n","Iteration 5524, loss = 0.05975038\n","Iteration 5525, loss = 0.05974140\n","Iteration 5526, loss = 0.05973247\n","Iteration 5527, loss = 0.05972347\n","Iteration 5528, loss = 0.05971457\n","Iteration 5529, loss = 0.05970556\n","Iteration 5530, loss = 0.05969664\n","Iteration 5531, loss = 0.05968769\n","Iteration 5532, loss = 0.05967881\n","Iteration 5533, loss = 0.05966990\n","Iteration 5534, loss = 0.05966099\n","Iteration 5535, loss = 0.05965205\n","Iteration 5536, loss = 0.05964311\n","Iteration 5537, loss = 0.05963437\n","Iteration 5538, loss = 0.05962545\n","Iteration 5539, loss = 0.05961644\n","Iteration 5540, loss = 0.05960765\n","Iteration 5541, loss = 0.05959878\n","Iteration 5542, loss = 0.05958990\n","Iteration 5543, loss = 0.05958103\n","Iteration 5544, loss = 0.05957213\n","Iteration 5545, loss = 0.05956342\n","Iteration 5546, loss = 0.05955454\n","Iteration 5547, loss = 0.05954557\n","Iteration 5548, loss = 0.05953678\n","Iteration 5549, loss = 0.05952799\n","Iteration 5550, loss = 0.05951915\n","Iteration 5551, loss = 0.05951031\n","Iteration 5552, loss = 0.05950145\n","Iteration 5553, loss = 0.05949286\n","Iteration 5554, loss = 0.05948403\n","Iteration 5555, loss = 0.05947510\n","Iteration 5556, loss = 0.05946638\n","Iteration 5557, loss = 0.05945763\n","Iteration 5558, loss = 0.05944884\n","Iteration 5559, loss = 0.05944003\n","Iteration 5560, loss = 0.05943125\n","Iteration 5561, loss = 0.05942251\n","Iteration 5562, loss = 0.05941377\n","Iteration 5563, loss = 0.05940503\n","Iteration 5564, loss = 0.05939629\n","Iteration 5565, loss = 0.05938760\n","Iteration 5566, loss = 0.05937889\n","Iteration 5567, loss = 0.05937014\n","Iteration 5568, loss = 0.05936153\n","Iteration 5569, loss = 0.05935272\n","Iteration 5570, loss = 0.05934403\n","Iteration 5571, loss = 0.05933542\n","Iteration 5572, loss = 0.05932679\n","Iteration 5573, loss = 0.05931807\n","Iteration 5574, loss = 0.05930938\n","Iteration 5575, loss = 0.05930070\n","Iteration 5576, loss = 0.05929199\n","Iteration 5577, loss = 0.05928336\n","Iteration 5578, loss = 0.05927469\n","Iteration 5579, loss = 0.05926598\n","Iteration 5580, loss = 0.05925735\n","Iteration 5581, loss = 0.05924881\n","Iteration 5582, loss = 0.05924020\n","Iteration 5583, loss = 0.05923150\n","Iteration 5584, loss = 0.05922279\n","Iteration 5585, loss = 0.05921420\n","Iteration 5586, loss = 0.05920560\n","Iteration 5587, loss = 0.05919704\n","Iteration 5588, loss = 0.05918841\n","Iteration 5589, loss = 0.05917982\n","Iteration 5590, loss = 0.05917130\n","Iteration 5591, loss = 0.05916270\n","Iteration 5592, loss = 0.05915419\n","Iteration 5593, loss = 0.05914556\n","Iteration 5594, loss = 0.05913706\n","Iteration 5595, loss = 0.05912858\n","Iteration 5596, loss = 0.05912007\n","Iteration 5597, loss = 0.05911152\n","Iteration 5598, loss = 0.05910294\n","Iteration 5599, loss = 0.05909434\n","Iteration 5600, loss = 0.05908580\n","Iteration 5601, loss = 0.05907732\n","Iteration 5602, loss = 0.05906877\n","Iteration 5603, loss = 0.05906023\n","Iteration 5604, loss = 0.05905180\n","Iteration 5605, loss = 0.05904333\n","Iteration 5606, loss = 0.05903482\n","Iteration 5607, loss = 0.05902630\n","Iteration 5608, loss = 0.05901774\n","Iteration 5609, loss = 0.05900944\n","Iteration 5610, loss = 0.05900096\n","Iteration 5611, loss = 0.05899234\n","Iteration 5612, loss = 0.05898398\n","Iteration 5613, loss = 0.05897558\n","Iteration 5614, loss = 0.05896715\n","Iteration 5615, loss = 0.05895869\n","Iteration 5616, loss = 0.05895020\n","Iteration 5617, loss = 0.05894184\n","Iteration 5618, loss = 0.05893335\n","Iteration 5619, loss = 0.05892493\n","Iteration 5620, loss = 0.05891660\n","Iteration 5621, loss = 0.05890818\n","Iteration 5622, loss = 0.05889977\n","Iteration 5623, loss = 0.05889138\n","Iteration 5624, loss = 0.05888297\n","Iteration 5625, loss = 0.05887452\n","Iteration 5626, loss = 0.05886635\n","Iteration 5627, loss = 0.05885795\n","Iteration 5628, loss = 0.05884942\n","Iteration 5629, loss = 0.05884119\n","Iteration 5630, loss = 0.05883288\n","Iteration 5631, loss = 0.05882461\n","Iteration 5632, loss = 0.05881634\n","Iteration 5633, loss = 0.05880802\n","Iteration 5634, loss = 0.05879968\n","Iteration 5635, loss = 0.05879130\n","Iteration 5636, loss = 0.05878291\n","Iteration 5637, loss = 0.05877449\n","Iteration 5638, loss = 0.05876620\n","Iteration 5639, loss = 0.05875789\n","Iteration 5640, loss = 0.05874961\n","Iteration 5641, loss = 0.05874115\n","Iteration 5642, loss = 0.05873295\n","Iteration 5643, loss = 0.05872471\n","Iteration 5644, loss = 0.05871644\n","Iteration 5645, loss = 0.05870821\n","Iteration 5646, loss = 0.05869991\n","Iteration 5647, loss = 0.05869164\n","Iteration 5648, loss = 0.05868335\n","Iteration 5649, loss = 0.05867513\n","Iteration 5650, loss = 0.05866677\n","Iteration 5651, loss = 0.05865863\n","Iteration 5652, loss = 0.05865043\n","Iteration 5653, loss = 0.05864223\n","Iteration 5654, loss = 0.05863391\n","Iteration 5655, loss = 0.05862569\n","Iteration 5656, loss = 0.05861751\n","Iteration 5657, loss = 0.05860930\n","Iteration 5658, loss = 0.05860125\n","Iteration 5659, loss = 0.05859297\n","Iteration 5660, loss = 0.05858477\n","Iteration 5661, loss = 0.05857661\n","Iteration 5662, loss = 0.05856844\n","Iteration 5663, loss = 0.05856030\n","Iteration 5664, loss = 0.05855209\n","Iteration 5665, loss = 0.05854390\n","Iteration 5666, loss = 0.05853570\n","Iteration 5667, loss = 0.05852749\n","Iteration 5668, loss = 0.05851956\n","Iteration 5669, loss = 0.05851142\n","Iteration 5670, loss = 0.05850311\n","Iteration 5671, loss = 0.05849505\n","Iteration 5672, loss = 0.05848702\n","Iteration 5673, loss = 0.05847898\n","Iteration 5674, loss = 0.05847091\n","Iteration 5675, loss = 0.05846280\n","Iteration 5676, loss = 0.05845466\n","Iteration 5677, loss = 0.05844660\n","Iteration 5678, loss = 0.05843847\n","Iteration 5679, loss = 0.05843027\n","Iteration 5680, loss = 0.05842211\n","Iteration 5681, loss = 0.05841406\n","Iteration 5682, loss = 0.05840605\n","Iteration 5683, loss = 0.05839790\n","Iteration 5684, loss = 0.05838985\n","Iteration 5685, loss = 0.05838177\n","Iteration 5686, loss = 0.05837369\n","Iteration 5687, loss = 0.05836563\n","Iteration 5688, loss = 0.05835771\n","Iteration 5689, loss = 0.05834962\n","Iteration 5690, loss = 0.05834156\n","Iteration 5691, loss = 0.05833363\n","Iteration 5692, loss = 0.05832563\n","Iteration 5693, loss = 0.05831764\n","Iteration 5694, loss = 0.05830963\n","Iteration 5695, loss = 0.05830160\n","Iteration 5696, loss = 0.05829355\n","Iteration 5697, loss = 0.05828547\n","Iteration 5698, loss = 0.05827776\n","Iteration 5699, loss = 0.05826979\n","Iteration 5700, loss = 0.05826155\n","Iteration 5701, loss = 0.05825370\n","Iteration 5702, loss = 0.05824586\n","Iteration 5703, loss = 0.05823798\n","Iteration 5704, loss = 0.05823006\n","Iteration 5705, loss = 0.05822211\n","Iteration 5706, loss = 0.05821412\n","Iteration 5707, loss = 0.05820613\n","Iteration 5708, loss = 0.05819817\n","Iteration 5709, loss = 0.05819016\n","Iteration 5710, loss = 0.05818217\n","Iteration 5711, loss = 0.05817416\n","Iteration 5712, loss = 0.05816650\n","Iteration 5713, loss = 0.05815865\n","Iteration 5714, loss = 0.05815057\n","Iteration 5715, loss = 0.05814262\n","Iteration 5716, loss = 0.05813480\n","Iteration 5717, loss = 0.05812695\n","Iteration 5718, loss = 0.05811909\n","Iteration 5719, loss = 0.05811121\n","Iteration 5720, loss = 0.05810335\n","Iteration 5721, loss = 0.05809547\n","Iteration 5722, loss = 0.05808756\n","Iteration 5723, loss = 0.05807963\n","Iteration 5724, loss = 0.05807168\n","Iteration 5725, loss = 0.05806411\n","Iteration 5726, loss = 0.05805634\n","Iteration 5727, loss = 0.05804833\n","Iteration 5728, loss = 0.05804043\n","Iteration 5729, loss = 0.05803267\n","Iteration 5730, loss = 0.05802491\n","Iteration 5731, loss = 0.05801712\n","Iteration 5732, loss = 0.05800932\n","Iteration 5733, loss = 0.05800152\n","Iteration 5734, loss = 0.05799369\n","Iteration 5735, loss = 0.05798583\n","Iteration 5736, loss = 0.05797802\n","Iteration 5737, loss = 0.05797017\n","Iteration 5738, loss = 0.05796240\n","Iteration 5739, loss = 0.05795466\n","Iteration 5740, loss = 0.05794678\n","Iteration 5741, loss = 0.05793906\n","Iteration 5742, loss = 0.05793129\n","Iteration 5743, loss = 0.05792356\n","Iteration 5744, loss = 0.05791581\n","Iteration 5745, loss = 0.05790808\n","Iteration 5746, loss = 0.05790029\n","Iteration 5747, loss = 0.05789254\n","Iteration 5748, loss = 0.05788483\n","Iteration 5749, loss = 0.05787720\n","Iteration 5750, loss = 0.05786937\n","Iteration 5751, loss = 0.05786168\n","Iteration 5752, loss = 0.05785399\n","Iteration 5753, loss = 0.05784628\n","Iteration 5754, loss = 0.05783870\n","Iteration 5755, loss = 0.05783087\n","Iteration 5756, loss = 0.05782321\n","Iteration 5757, loss = 0.05781566\n","Iteration 5758, loss = 0.05780805\n","Iteration 5759, loss = 0.05780037\n","Iteration 5760, loss = 0.05779262\n","Iteration 5761, loss = 0.05778499\n","Iteration 5762, loss = 0.05777734\n","Iteration 5763, loss = 0.05776966\n","Iteration 5764, loss = 0.05776196\n","Iteration 5765, loss = 0.05775441\n","Iteration 5766, loss = 0.05774675\n","Iteration 5767, loss = 0.05773894\n","Iteration 5768, loss = 0.05773129\n","Iteration 5769, loss = 0.05772378\n","Iteration 5770, loss = 0.05771621\n","Iteration 5771, loss = 0.05770856\n","Iteration 5772, loss = 0.05770086\n","Iteration 5773, loss = 0.05769328\n","Iteration 5774, loss = 0.05768565\n","Iteration 5775, loss = 0.05767807\n","Iteration 5776, loss = 0.05767053\n","Iteration 5777, loss = 0.05766295\n","Iteration 5778, loss = 0.05765536\n","Iteration 5779, loss = 0.05764779\n","Iteration 5780, loss = 0.05764018\n","Iteration 5781, loss = 0.05763258\n","Iteration 5782, loss = 0.05762495\n","Iteration 5783, loss = 0.05761747\n","Iteration 5784, loss = 0.05760989\n","Iteration 5785, loss = 0.05760231\n","Iteration 5786, loss = 0.05759483\n","Iteration 5787, loss = 0.05758730\n","Iteration 5788, loss = 0.05757977\n","Iteration 5789, loss = 0.05757221\n","Iteration 5790, loss = 0.05756470\n","Iteration 5791, loss = 0.05755715\n","Iteration 5792, loss = 0.05754967\n","Iteration 5793, loss = 0.05754209\n","Iteration 5794, loss = 0.05753461\n","Iteration 5795, loss = 0.05752717\n","Iteration 5796, loss = 0.05751968\n","Iteration 5797, loss = 0.05751220\n","Iteration 5798, loss = 0.05750469\n","Iteration 5799, loss = 0.05749723\n","Iteration 5800, loss = 0.05748971\n","Iteration 5801, loss = 0.05748215\n","Iteration 5802, loss = 0.05747484\n","Iteration 5803, loss = 0.05746735\n","Iteration 5804, loss = 0.05745978\n","Iteration 5805, loss = 0.05745236\n","Iteration 5806, loss = 0.05744495\n","Iteration 5807, loss = 0.05743753\n","Iteration 5808, loss = 0.05743007\n","Iteration 5809, loss = 0.05742258\n","Iteration 5810, loss = 0.05741513\n","Iteration 5811, loss = 0.05740789\n","Iteration 5812, loss = 0.05740038\n","Iteration 5813, loss = 0.05739291\n","Iteration 5814, loss = 0.05738558\n","Iteration 5815, loss = 0.05737821\n","Iteration 5816, loss = 0.05737080\n","Iteration 5817, loss = 0.05736337\n","Iteration 5818, loss = 0.05735590\n","Iteration 5819, loss = 0.05734856\n","Iteration 5820, loss = 0.05734120\n","Iteration 5821, loss = 0.05733379\n","Iteration 5822, loss = 0.05732634\n","Iteration 5823, loss = 0.05731901\n","Iteration 5824, loss = 0.05731167\n","Iteration 5825, loss = 0.05730435\n","Iteration 5826, loss = 0.05729700\n","Iteration 5827, loss = 0.05728961\n","Iteration 5828, loss = 0.05728220\n","Iteration 5829, loss = 0.05727491\n","Iteration 5830, loss = 0.05726752\n","Iteration 5831, loss = 0.05726017\n","Iteration 5832, loss = 0.05725284\n","Iteration 5833, loss = 0.05724558\n","Iteration 5834, loss = 0.05723829\n","Iteration 5835, loss = 0.05723097\n","Iteration 5836, loss = 0.05722363\n","Iteration 5837, loss = 0.05721631\n","Iteration 5838, loss = 0.05720897\n","Iteration 5839, loss = 0.05720175\n","Iteration 5840, loss = 0.05719438\n","Iteration 5841, loss = 0.05718716\n","Iteration 5842, loss = 0.05717992\n","Iteration 5843, loss = 0.05717267\n","Iteration 5844, loss = 0.05716542\n","Iteration 5845, loss = 0.05715814\n","Iteration 5846, loss = 0.05715085\n","Iteration 5847, loss = 0.05714354\n","Iteration 5848, loss = 0.05713627\n","Iteration 5849, loss = 0.05712898\n","Iteration 5850, loss = 0.05712197\n","Iteration 5851, loss = 0.05711470\n","Iteration 5852, loss = 0.05710726\n","Iteration 5853, loss = 0.05710014\n","Iteration 5854, loss = 0.05709296\n","Iteration 5855, loss = 0.05708583\n","Iteration 5856, loss = 0.05707868\n","Iteration 5857, loss = 0.05707149\n","Iteration 5858, loss = 0.05706427\n","Iteration 5859, loss = 0.05705701\n","Iteration 5860, loss = 0.05704979\n","Iteration 5861, loss = 0.05704257\n","Iteration 5862, loss = 0.05703530\n","Iteration 5863, loss = 0.05702806\n","Iteration 5864, loss = 0.05702083\n","Iteration 5865, loss = 0.05701367\n","Iteration 5866, loss = 0.05700652\n","Iteration 5867, loss = 0.05699921\n","Iteration 5868, loss = 0.05699214\n","Iteration 5869, loss = 0.05698502\n","Iteration 5870, loss = 0.05697783\n","Iteration 5871, loss = 0.05697059\n","Iteration 5872, loss = 0.05696343\n","Iteration 5873, loss = 0.05695643\n","Iteration 5874, loss = 0.05694919\n","Iteration 5875, loss = 0.05694210\n","Iteration 5876, loss = 0.05693503\n","Iteration 5877, loss = 0.05692789\n","Iteration 5878, loss = 0.05692083\n","Iteration 5879, loss = 0.05691375\n","Iteration 5880, loss = 0.05690663\n","Iteration 5881, loss = 0.05689948\n","Iteration 5882, loss = 0.05689230\n","Iteration 5883, loss = 0.05688510\n","Iteration 5884, loss = 0.05687817\n","Iteration 5885, loss = 0.05687110\n","Iteration 5886, loss = 0.05686395\n","Iteration 5887, loss = 0.05685683\n","Iteration 5888, loss = 0.05684981\n","Iteration 5889, loss = 0.05684280\n","Iteration 5890, loss = 0.05683575\n","Iteration 5891, loss = 0.05682866\n","Iteration 5892, loss = 0.05682155\n","Iteration 5893, loss = 0.05681441\n","Iteration 5894, loss = 0.05680748\n","Iteration 5895, loss = 0.05680043\n","Iteration 5896, loss = 0.05679332\n","Iteration 5897, loss = 0.05678631\n","Iteration 5898, loss = 0.05677923\n","Iteration 5899, loss = 0.05677224\n","Iteration 5900, loss = 0.05676525\n","Iteration 5901, loss = 0.05675823\n","Iteration 5902, loss = 0.05675118\n","Iteration 5903, loss = 0.05674410\n","Iteration 5904, loss = 0.05673721\n","Iteration 5905, loss = 0.05673013\n","Iteration 5906, loss = 0.05672307\n","Iteration 5907, loss = 0.05671609\n","Iteration 5908, loss = 0.05670913\n","Iteration 5909, loss = 0.05670217\n","Iteration 5910, loss = 0.05669518\n","Iteration 5911, loss = 0.05668816\n","Iteration 5912, loss = 0.05668118\n","Iteration 5913, loss = 0.05667418\n","Iteration 5914, loss = 0.05666725\n","Iteration 5915, loss = 0.05666028\n","Iteration 5916, loss = 0.05665335\n","Iteration 5917, loss = 0.05664645\n","Iteration 5918, loss = 0.05663951\n","Iteration 5919, loss = 0.05663254\n","Iteration 5920, loss = 0.05662559\n","Iteration 5921, loss = 0.05661867\n","Iteration 5922, loss = 0.05661167\n","Iteration 5923, loss = 0.05660470\n","Iteration 5924, loss = 0.05659778\n","Iteration 5925, loss = 0.05659085\n","Iteration 5926, loss = 0.05658390\n","Iteration 5927, loss = 0.05657703\n","Iteration 5928, loss = 0.05657011\n","Iteration 5929, loss = 0.05656321\n","Iteration 5930, loss = 0.05655633\n","Iteration 5931, loss = 0.05654941\n","Iteration 5932, loss = 0.05654251\n","Iteration 5933, loss = 0.05653559\n","Iteration 5934, loss = 0.05652889\n","Iteration 5935, loss = 0.05652192\n","Iteration 5936, loss = 0.05651503\n","Iteration 5937, loss = 0.05650822\n","Iteration 5938, loss = 0.05650138\n","Iteration 5939, loss = 0.05649451\n","Iteration 5940, loss = 0.05648772\n","Iteration 5941, loss = 0.05648086\n","Iteration 5942, loss = 0.05647393\n","Iteration 5943, loss = 0.05646707\n","Iteration 5944, loss = 0.05646022\n","Iteration 5945, loss = 0.05645344\n","Iteration 5946, loss = 0.05644657\n","Iteration 5947, loss = 0.05643969\n","Iteration 5948, loss = 0.05643290\n","Iteration 5949, loss = 0.05642612\n","Iteration 5950, loss = 0.05641929\n","Iteration 5951, loss = 0.05641249\n","Iteration 5952, loss = 0.05640569\n","Iteration 5953, loss = 0.05639886\n","Iteration 5954, loss = 0.05639199\n","Iteration 5955, loss = 0.05638522\n","Iteration 5956, loss = 0.05637839\n","Iteration 5957, loss = 0.05637162\n","Iteration 5958, loss = 0.05636489\n","Iteration 5959, loss = 0.05635812\n","Iteration 5960, loss = 0.05635140\n","Iteration 5961, loss = 0.05634463\n","Iteration 5962, loss = 0.05633780\n","Iteration 5963, loss = 0.05633101\n","Iteration 5964, loss = 0.05632420\n","Iteration 5965, loss = 0.05631742\n","Iteration 5966, loss = 0.05631086\n","Iteration 5967, loss = 0.05630409\n","Iteration 5968, loss = 0.05629716\n","Iteration 5969, loss = 0.05629048\n","Iteration 5970, loss = 0.05628376\n","Iteration 5971, loss = 0.05627704\n","Iteration 5972, loss = 0.05627032\n","Iteration 5973, loss = 0.05626357\n","Iteration 5974, loss = 0.05625684\n","Iteration 5975, loss = 0.05625012\n","Iteration 5976, loss = 0.05624340\n","Iteration 5977, loss = 0.05623666\n","Iteration 5978, loss = 0.05623000\n","Iteration 5979, loss = 0.05622335\n","Iteration 5980, loss = 0.05621657\n","Iteration 5981, loss = 0.05620994\n","Iteration 5982, loss = 0.05620329\n","Iteration 5983, loss = 0.05619661\n","Iteration 5984, loss = 0.05618989\n","Iteration 5985, loss = 0.05618323\n","Iteration 5986, loss = 0.05617648\n","Iteration 5987, loss = 0.05616985\n","Iteration 5988, loss = 0.05616314\n","Iteration 5989, loss = 0.05615650\n","Iteration 5990, loss = 0.05614999\n","Iteration 5991, loss = 0.05614322\n","Iteration 5992, loss = 0.05613656\n","Iteration 5993, loss = 0.05612987\n","Iteration 5994, loss = 0.05612331\n","Iteration 5995, loss = 0.05611679\n","Iteration 5996, loss = 0.05611004\n","Iteration 5997, loss = 0.05610335\n","Iteration 5998, loss = 0.05609676\n","Iteration 5999, loss = 0.05609013\n","Iteration 6000, loss = 0.05608349\n","Iteration 6001, loss = 0.05607690\n","Iteration 6002, loss = 0.05607031\n","Iteration 6003, loss = 0.05606369\n","Iteration 6004, loss = 0.05605709\n","Iteration 6005, loss = 0.05605045\n","Iteration 6006, loss = 0.05604394\n","Iteration 6007, loss = 0.05603729\n","Iteration 6008, loss = 0.05603070\n","Iteration 6009, loss = 0.05602413\n","Iteration 6010, loss = 0.05601753\n","Iteration 6011, loss = 0.05601105\n","Iteration 6012, loss = 0.05600436\n","Iteration 6013, loss = 0.05599784\n","Iteration 6014, loss = 0.05599126\n","Iteration 6015, loss = 0.05598469\n","Iteration 6016, loss = 0.05597816\n","Iteration 6017, loss = 0.05597170\n","Iteration 6018, loss = 0.05596506\n","Iteration 6019, loss = 0.05595856\n","Iteration 6020, loss = 0.05595201\n","Iteration 6021, loss = 0.05594544\n","Iteration 6022, loss = 0.05593893\n","Iteration 6023, loss = 0.05593252\n","Iteration 6024, loss = 0.05592584\n","Iteration 6025, loss = 0.05591940\n","Iteration 6026, loss = 0.05591294\n","Iteration 6027, loss = 0.05590643\n","Iteration 6028, loss = 0.05589990\n","Iteration 6029, loss = 0.05589333\n","Iteration 6030, loss = 0.05588680\n","Iteration 6031, loss = 0.05588045\n","Iteration 6032, loss = 0.05587380\n","Iteration 6033, loss = 0.05586737\n","Iteration 6034, loss = 0.05586093\n","Iteration 6035, loss = 0.05585446\n","Iteration 6036, loss = 0.05584795\n","Iteration 6037, loss = 0.05584142\n","Iteration 6038, loss = 0.05583501\n","Iteration 6039, loss = 0.05582857\n","Iteration 6040, loss = 0.05582219\n","Iteration 6041, loss = 0.05581555\n","Iteration 6042, loss = 0.05580914\n","Iteration 6043, loss = 0.05580271\n","Iteration 6044, loss = 0.05579625\n","Iteration 6045, loss = 0.05578982\n","Iteration 6046, loss = 0.05578337\n","Iteration 6047, loss = 0.05577690\n","Iteration 6048, loss = 0.05577047\n","Iteration 6049, loss = 0.05576404\n","Iteration 6050, loss = 0.05575765\n","Iteration 6051, loss = 0.05575123\n","Iteration 6052, loss = 0.05574482\n","Iteration 6053, loss = 0.05573843\n","Iteration 6054, loss = 0.05573201\n","Iteration 6055, loss = 0.05572557\n","Iteration 6056, loss = 0.05571915\n","Iteration 6057, loss = 0.05571277\n","Iteration 6058, loss = 0.05570635\n","Iteration 6059, loss = 0.05569998\n","Iteration 6060, loss = 0.05569360\n","Iteration 6061, loss = 0.05568721\n","Iteration 6062, loss = 0.05568088\n","Iteration 6063, loss = 0.05567454\n","Iteration 6064, loss = 0.05566817\n","Iteration 6065, loss = 0.05566177\n","Iteration 6066, loss = 0.05565537\n","Iteration 6067, loss = 0.05564901\n","Iteration 6068, loss = 0.05564265\n","Iteration 6069, loss = 0.05563629\n","Iteration 6070, loss = 0.05562991\n","Iteration 6071, loss = 0.05562365\n","Iteration 6072, loss = 0.05561727\n","Iteration 6073, loss = 0.05561091\n","Iteration 6074, loss = 0.05560459\n","Iteration 6075, loss = 0.05559825\n","Iteration 6076, loss = 0.05559196\n","Iteration 6077, loss = 0.05558563\n","Iteration 6078, loss = 0.05557930\n","Iteration 6079, loss = 0.05557300\n","Iteration 6080, loss = 0.05556667\n","Iteration 6081, loss = 0.05556033\n","Iteration 6082, loss = 0.05555401\n","Iteration 6083, loss = 0.05554771\n","Iteration 6084, loss = 0.05554145\n","Iteration 6085, loss = 0.05553513\n","Iteration 6086, loss = 0.05552883\n","Iteration 6087, loss = 0.05552256\n","Iteration 6088, loss = 0.05551627\n","Iteration 6089, loss = 0.05551003\n","Iteration 6090, loss = 0.05550373\n","Iteration 6091, loss = 0.05549748\n","Iteration 6092, loss = 0.05549123\n","Iteration 6093, loss = 0.05548496\n","Iteration 6094, loss = 0.05547865\n","Iteration 6095, loss = 0.05547239\n","Iteration 6096, loss = 0.05546614\n","Iteration 6097, loss = 0.05545985\n","Iteration 6098, loss = 0.05545361\n","Iteration 6099, loss = 0.05544737\n","Iteration 6100, loss = 0.05544115\n","Iteration 6101, loss = 0.05543492\n","Iteration 6102, loss = 0.05542869\n","Iteration 6103, loss = 0.05542244\n","Iteration 6104, loss = 0.05541622\n","Iteration 6105, loss = 0.05541001\n","Iteration 6106, loss = 0.05540379\n","Iteration 6107, loss = 0.05539755\n","Iteration 6108, loss = 0.05539136\n","Iteration 6109, loss = 0.05538513\n","Iteration 6110, loss = 0.05537889\n","Iteration 6111, loss = 0.05537283\n","Iteration 6112, loss = 0.05536650\n","Iteration 6113, loss = 0.05536032\n","Iteration 6114, loss = 0.05535413\n","Iteration 6115, loss = 0.05534796\n","Iteration 6116, loss = 0.05534180\n","Iteration 6117, loss = 0.05533560\n","Iteration 6118, loss = 0.05532939\n","Iteration 6119, loss = 0.05532329\n","Iteration 6120, loss = 0.05531713\n","Iteration 6121, loss = 0.05531090\n","Iteration 6122, loss = 0.05530472\n","Iteration 6123, loss = 0.05529861\n","Iteration 6124, loss = 0.05529246\n","Iteration 6125, loss = 0.05528630\n","Iteration 6126, loss = 0.05528011\n","Iteration 6127, loss = 0.05527401\n","Iteration 6128, loss = 0.05526790\n","Iteration 6129, loss = 0.05526172\n","Iteration 6130, loss = 0.05525554\n","Iteration 6131, loss = 0.05524944\n","Iteration 6132, loss = 0.05524330\n","Iteration 6133, loss = 0.05523714\n","Iteration 6134, loss = 0.05523100\n","Iteration 6135, loss = 0.05522488\n","Iteration 6136, loss = 0.05521873\n","Iteration 6137, loss = 0.05521263\n","Iteration 6138, loss = 0.05520650\n","Iteration 6139, loss = 0.05520043\n","Iteration 6140, loss = 0.05519432\n","Iteration 6141, loss = 0.05518823\n","Iteration 6142, loss = 0.05518215\n","Iteration 6143, loss = 0.05517604\n","Iteration 6144, loss = 0.05516991\n","Iteration 6145, loss = 0.05516390\n","Iteration 6146, loss = 0.05515782\n","Iteration 6147, loss = 0.05515168\n","Iteration 6148, loss = 0.05514559\n","Iteration 6149, loss = 0.05513954\n","Iteration 6150, loss = 0.05513347\n","Iteration 6151, loss = 0.05512751\n","Iteration 6152, loss = 0.05512127\n","Iteration 6153, loss = 0.05511526\n","Iteration 6154, loss = 0.05510923\n","Iteration 6155, loss = 0.05510314\n","Iteration 6156, loss = 0.05509709\n","Iteration 6157, loss = 0.05509107\n","Iteration 6158, loss = 0.05508503\n","Iteration 6159, loss = 0.05507895\n","Iteration 6160, loss = 0.05507287\n","Iteration 6161, loss = 0.05506683\n","Iteration 6162, loss = 0.05506081\n","Iteration 6163, loss = 0.05505478\n","Iteration 6164, loss = 0.05504881\n","Iteration 6165, loss = 0.05504274\n","Iteration 6166, loss = 0.05503673\n","Iteration 6167, loss = 0.05503072\n","Iteration 6168, loss = 0.05502473\n","Iteration 6169, loss = 0.05501872\n","Iteration 6170, loss = 0.05501268\n","Iteration 6171, loss = 0.05500676\n","Iteration 6172, loss = 0.05500077\n","Iteration 6173, loss = 0.05499472\n","Iteration 6174, loss = 0.05498871\n","Iteration 6175, loss = 0.05498275\n","Iteration 6176, loss = 0.05497676\n","Iteration 6177, loss = 0.05497075\n","Iteration 6178, loss = 0.05496472\n","Iteration 6179, loss = 0.05495881\n","Iteration 6180, loss = 0.05495288\n","Iteration 6181, loss = 0.05494688\n","Iteration 6182, loss = 0.05494088\n","Iteration 6183, loss = 0.05493496\n","Iteration 6184, loss = 0.05492900\n","Iteration 6185, loss = 0.05492302\n","Iteration 6186, loss = 0.05491703\n","Iteration 6187, loss = 0.05491108\n","Iteration 6188, loss = 0.05490515\n","Iteration 6189, loss = 0.05489921\n","Iteration 6190, loss = 0.05489325\n","Iteration 6191, loss = 0.05488729\n","Iteration 6192, loss = 0.05488134\n","Iteration 6193, loss = 0.05487548\n","Iteration 6194, loss = 0.05486949\n","Iteration 6195, loss = 0.05486358\n","Iteration 6196, loss = 0.05485766\n","Iteration 6197, loss = 0.05485176\n","Iteration 6198, loss = 0.05484584\n","Iteration 6199, loss = 0.05483994\n","Iteration 6200, loss = 0.05483402\n","Iteration 6201, loss = 0.05482811\n","Iteration 6202, loss = 0.05482224\n","Iteration 6203, loss = 0.05481631\n","Iteration 6204, loss = 0.05481043\n","Iteration 6205, loss = 0.05480456\n","Iteration 6206, loss = 0.05479865\n","Iteration 6207, loss = 0.05479272\n","Iteration 6208, loss = 0.05478690\n","Iteration 6209, loss = 0.05478100\n","Iteration 6210, loss = 0.05477508\n","Iteration 6211, loss = 0.05476922\n","Iteration 6212, loss = 0.05476336\n","Iteration 6213, loss = 0.05475751\n","Iteration 6214, loss = 0.05475164\n","Iteration 6215, loss = 0.05474577\n","Iteration 6216, loss = 0.05473997\n","Iteration 6217, loss = 0.05473410\n","Iteration 6218, loss = 0.05472820\n","Iteration 6219, loss = 0.05472236\n","Iteration 6220, loss = 0.05471650\n","Iteration 6221, loss = 0.05471066\n","Iteration 6222, loss = 0.05470479\n","Iteration 6223, loss = 0.05469896\n","Iteration 6224, loss = 0.05469324\n","Iteration 6225, loss = 0.05468731\n","Iteration 6226, loss = 0.05468148\n","Iteration 6227, loss = 0.05467570\n","Iteration 6228, loss = 0.05466988\n","Iteration 6229, loss = 0.05466405\n","Iteration 6230, loss = 0.05465825\n","Iteration 6231, loss = 0.05465244\n","Iteration 6232, loss = 0.05464660\n","Iteration 6233, loss = 0.05464086\n","Iteration 6234, loss = 0.05463511\n","Iteration 6235, loss = 0.05462928\n","Iteration 6236, loss = 0.05462352\n","Iteration 6237, loss = 0.05461774\n","Iteration 6238, loss = 0.05461195\n","Iteration 6239, loss = 0.05460626\n","Iteration 6240, loss = 0.05460036\n","Iteration 6241, loss = 0.05459459\n","Iteration 6242, loss = 0.05458887\n","Iteration 6243, loss = 0.05458307\n","Iteration 6244, loss = 0.05457736\n","Iteration 6245, loss = 0.05457163\n","Iteration 6246, loss = 0.05456588\n","Iteration 6247, loss = 0.05456009\n","Iteration 6248, loss = 0.05455429\n","Iteration 6249, loss = 0.05454855\n","Iteration 6250, loss = 0.05454281\n","Iteration 6251, loss = 0.05453707\n","Iteration 6252, loss = 0.05453131\n","Iteration 6253, loss = 0.05452558\n","Iteration 6254, loss = 0.05451983\n","Iteration 6255, loss = 0.05451411\n","Iteration 6256, loss = 0.05450845\n","Iteration 6257, loss = 0.05450274\n","Iteration 6258, loss = 0.05449698\n","Iteration 6259, loss = 0.05449129\n","Iteration 6260, loss = 0.05448560\n","Iteration 6261, loss = 0.05447990\n","Iteration 6262, loss = 0.05447419\n","Iteration 6263, loss = 0.05446847\n","Iteration 6264, loss = 0.05446276\n","Iteration 6265, loss = 0.05445707\n","Iteration 6266, loss = 0.05445137\n","Iteration 6267, loss = 0.05444564\n","Iteration 6268, loss = 0.05443995\n","Iteration 6269, loss = 0.05443425\n","Iteration 6270, loss = 0.05442860\n","Iteration 6271, loss = 0.05442291\n","Iteration 6272, loss = 0.05441721\n","Iteration 6273, loss = 0.05441154\n","Iteration 6274, loss = 0.05440591\n","Iteration 6275, loss = 0.05440024\n","Iteration 6276, loss = 0.05439457\n","Iteration 6277, loss = 0.05438890\n","Iteration 6278, loss = 0.05438323\n","Iteration 6279, loss = 0.05437759\n","Iteration 6280, loss = 0.05437193\n","Iteration 6281, loss = 0.05436626\n","Iteration 6282, loss = 0.05436063\n","Iteration 6283, loss = 0.05435495\n","Iteration 6284, loss = 0.05434933\n","Iteration 6285, loss = 0.05434373\n","Iteration 6286, loss = 0.05433816\n","Iteration 6287, loss = 0.05433246\n","Iteration 6288, loss = 0.05432683\n","Iteration 6289, loss = 0.05432119\n","Iteration 6290, loss = 0.05431554\n","Iteration 6291, loss = 0.05431004\n","Iteration 6292, loss = 0.05430445\n","Iteration 6293, loss = 0.05429876\n","Iteration 6294, loss = 0.05429311\n","Iteration 6295, loss = 0.05428754\n","Iteration 6296, loss = 0.05428195\n","Iteration 6297, loss = 0.05427634\n","Iteration 6298, loss = 0.05427073\n","Iteration 6299, loss = 0.05426513\n","Iteration 6300, loss = 0.05425950\n","Iteration 6301, loss = 0.05425384\n","Iteration 6302, loss = 0.05424837\n","Iteration 6303, loss = 0.05424278\n","Iteration 6304, loss = 0.05423715\n","Iteration 6305, loss = 0.05423156\n","Iteration 6306, loss = 0.05422602\n","Iteration 6307, loss = 0.05422047\n","Iteration 6308, loss = 0.05421491\n","Iteration 6309, loss = 0.05420933\n","Iteration 6310, loss = 0.05420374\n","Iteration 6311, loss = 0.05419816\n","Iteration 6312, loss = 0.05419257\n","Iteration 6313, loss = 0.05418702\n","Iteration 6314, loss = 0.05418146\n","Iteration 6315, loss = 0.05417592\n","Iteration 6316, loss = 0.05417036\n","Iteration 6317, loss = 0.05416480\n","Iteration 6318, loss = 0.05415924\n","Iteration 6319, loss = 0.05415380\n","Iteration 6320, loss = 0.05414816\n","Iteration 6321, loss = 0.05414267\n","Iteration 6322, loss = 0.05413711\n","Iteration 6323, loss = 0.05413159\n","Iteration 6324, loss = 0.05412606\n","Iteration 6325, loss = 0.05412059\n","Iteration 6326, loss = 0.05411504\n","Iteration 6327, loss = 0.05410954\n","Iteration 6328, loss = 0.05410406\n","Iteration 6329, loss = 0.05409855\n","Iteration 6330, loss = 0.05409304\n","Iteration 6331, loss = 0.05408753\n","Iteration 6332, loss = 0.05408202\n","Iteration 6333, loss = 0.05407650\n","Iteration 6334, loss = 0.05407098\n","Iteration 6335, loss = 0.05406552\n","Iteration 6336, loss = 0.05406001\n","Iteration 6337, loss = 0.05405452\n","Iteration 6338, loss = 0.05404902\n","Iteration 6339, loss = 0.05404356\n","Iteration 6340, loss = 0.05403809\n","Iteration 6341, loss = 0.05403261\n","Iteration 6342, loss = 0.05402713\n","Iteration 6343, loss = 0.05402166\n","Iteration 6344, loss = 0.05401620\n","Iteration 6345, loss = 0.05401071\n","Iteration 6346, loss = 0.05400524\n","Iteration 6347, loss = 0.05399977\n","Iteration 6348, loss = 0.05399432\n","Iteration 6349, loss = 0.05398886\n","Iteration 6350, loss = 0.05398340\n","Iteration 6351, loss = 0.05397795\n","Iteration 6352, loss = 0.05397259\n","Iteration 6353, loss = 0.05396706\n","Iteration 6354, loss = 0.05396162\n","Iteration 6355, loss = 0.05395618\n","Iteration 6356, loss = 0.05395082\n","Iteration 6357, loss = 0.05394535\n","Iteration 6358, loss = 0.05393992\n","Iteration 6359, loss = 0.05393451\n","Iteration 6360, loss = 0.05392910\n","Iteration 6361, loss = 0.05392368\n","Iteration 6362, loss = 0.05391828\n","Iteration 6363, loss = 0.05391284\n","Iteration 6364, loss = 0.05390742\n","Iteration 6365, loss = 0.05390199\n","Iteration 6366, loss = 0.05389656\n","Iteration 6367, loss = 0.05389113\n","Iteration 6368, loss = 0.05388573\n","Iteration 6369, loss = 0.05388039\n","Iteration 6370, loss = 0.05387499\n","Iteration 6371, loss = 0.05386956\n","Iteration 6372, loss = 0.05386419\n","Iteration 6373, loss = 0.05385882\n","Iteration 6374, loss = 0.05385344\n","Iteration 6375, loss = 0.05384805\n","Iteration 6376, loss = 0.05384267\n","Iteration 6377, loss = 0.05383729\n","Iteration 6378, loss = 0.05383190\n","Iteration 6379, loss = 0.05382650\n","Iteration 6380, loss = 0.05382118\n","Iteration 6381, loss = 0.05381577\n","Iteration 6382, loss = 0.05381040\n","Iteration 6383, loss = 0.05380505\n","Iteration 6384, loss = 0.05379970\n","Iteration 6385, loss = 0.05379436\n","Iteration 6386, loss = 0.05378900\n","Iteration 6387, loss = 0.05378366\n","Iteration 6388, loss = 0.05377832\n","Iteration 6389, loss = 0.05377297\n","Iteration 6390, loss = 0.05376762\n","Iteration 6391, loss = 0.05376226\n","Iteration 6392, loss = 0.05375695\n","Iteration 6393, loss = 0.05375159\n","Iteration 6394, loss = 0.05374627\n","Iteration 6395, loss = 0.05374095\n","Iteration 6396, loss = 0.05373565\n","Iteration 6397, loss = 0.05373032\n","Iteration 6398, loss = 0.05372500\n","Iteration 6399, loss = 0.05371968\n","Iteration 6400, loss = 0.05371435\n","Iteration 6401, loss = 0.05370902\n","Iteration 6402, loss = 0.05370376\n","Iteration 6403, loss = 0.05369838\n","Iteration 6404, loss = 0.05369315\n","Iteration 6405, loss = 0.05368784\n","Iteration 6406, loss = 0.05368251\n","Iteration 6407, loss = 0.05367723\n","Iteration 6408, loss = 0.05367195\n","Iteration 6409, loss = 0.05366666\n","Iteration 6410, loss = 0.05366137\n","Iteration 6411, loss = 0.05365608\n","Iteration 6412, loss = 0.05365078\n","Iteration 6413, loss = 0.05364548\n","Iteration 6414, loss = 0.05364019\n","Iteration 6415, loss = 0.05363491\n","Iteration 6416, loss = 0.05362962\n","Iteration 6417, loss = 0.05362434\n","Iteration 6418, loss = 0.05361908\n","Iteration 6419, loss = 0.05361392\n","Iteration 6420, loss = 0.05360857\n","Iteration 6421, loss = 0.05360333\n","Iteration 6422, loss = 0.05359808\n","Iteration 6423, loss = 0.05359283\n","Iteration 6424, loss = 0.05358758\n","Iteration 6425, loss = 0.05358232\n","Iteration 6426, loss = 0.05357707\n","Iteration 6427, loss = 0.05357183\n","Iteration 6428, loss = 0.05356659\n","Iteration 6429, loss = 0.05356135\n","Iteration 6430, loss = 0.05355610\n","Iteration 6431, loss = 0.05355090\n","Iteration 6432, loss = 0.05354563\n","Iteration 6433, loss = 0.05354040\n","Iteration 6434, loss = 0.05353517\n","Iteration 6435, loss = 0.05352994\n","Iteration 6436, loss = 0.05352484\n","Iteration 6437, loss = 0.05351953\n","Iteration 6438, loss = 0.05351430\n","Iteration 6439, loss = 0.05350911\n","Iteration 6440, loss = 0.05350391\n","Iteration 6441, loss = 0.05349870\n","Iteration 6442, loss = 0.05349349\n","Iteration 6443, loss = 0.05348835\n","Iteration 6444, loss = 0.05348309\n","Iteration 6445, loss = 0.05347790\n","Iteration 6446, loss = 0.05347271\n","Iteration 6447, loss = 0.05346751\n","Iteration 6448, loss = 0.05346233\n","Iteration 6449, loss = 0.05345713\n","Iteration 6450, loss = 0.05345195\n","Iteration 6451, loss = 0.05344677\n","Iteration 6452, loss = 0.05344158\n","Iteration 6453, loss = 0.05343652\n","Iteration 6454, loss = 0.05343122\n","Iteration 6455, loss = 0.05342610\n","Iteration 6456, loss = 0.05342090\n","Iteration 6457, loss = 0.05341575\n","Iteration 6458, loss = 0.05341059\n","Iteration 6459, loss = 0.05340543\n","Iteration 6460, loss = 0.05340029\n","Iteration 6461, loss = 0.05339515\n","Iteration 6462, loss = 0.05339000\n","Iteration 6463, loss = 0.05338485\n","Iteration 6464, loss = 0.05337969\n","Iteration 6465, loss = 0.05337453\n","Iteration 6466, loss = 0.05336937\n","Iteration 6467, loss = 0.05336427\n","Iteration 6468, loss = 0.05335908\n","Iteration 6469, loss = 0.05335396\n","Iteration 6470, loss = 0.05334894\n","Iteration 6471, loss = 0.05334376\n","Iteration 6472, loss = 0.05333864\n","Iteration 6473, loss = 0.05333353\n","Iteration 6474, loss = 0.05332841\n","Iteration 6475, loss = 0.05332329\n","Iteration 6476, loss = 0.05331817\n","Iteration 6477, loss = 0.05331305\n","Iteration 6478, loss = 0.05330791\n","Iteration 6479, loss = 0.05330278\n","Iteration 6480, loss = 0.05329774\n","Iteration 6481, loss = 0.05329263\n","Iteration 6482, loss = 0.05328746\n","Iteration 6483, loss = 0.05328237\n","Iteration 6484, loss = 0.05327728\n","Iteration 6485, loss = 0.05327220\n","Iteration 6486, loss = 0.05326708\n","Iteration 6487, loss = 0.05326202\n","Iteration 6488, loss = 0.05325691\n","Iteration 6489, loss = 0.05325183\n","Iteration 6490, loss = 0.05324676\n","Iteration 6491, loss = 0.05324168\n","Iteration 6492, loss = 0.05323662\n","Iteration 6493, loss = 0.05323154\n","Iteration 6494, loss = 0.05322648\n","Iteration 6495, loss = 0.05322141\n","Iteration 6496, loss = 0.05321635\n","Iteration 6497, loss = 0.05321128\n","Iteration 6498, loss = 0.05320621\n","Iteration 6499, loss = 0.05320114\n","Iteration 6500, loss = 0.05319606\n","Iteration 6501, loss = 0.05319102\n","Iteration 6502, loss = 0.05318594\n","Iteration 6503, loss = 0.05318089\n","Iteration 6504, loss = 0.05317584\n","Iteration 6505, loss = 0.05317088\n","Iteration 6506, loss = 0.05316578\n","Iteration 6507, loss = 0.05316074\n","Iteration 6508, loss = 0.05315572\n","Iteration 6509, loss = 0.05315069\n","Iteration 6510, loss = 0.05314566\n","Iteration 6511, loss = 0.05314063\n","Iteration 6512, loss = 0.05313561\n","Iteration 6513, loss = 0.05313057\n","Iteration 6514, loss = 0.05312556\n","Iteration 6515, loss = 0.05312053\n","Iteration 6516, loss = 0.05311551\n","Iteration 6517, loss = 0.05311048\n","Iteration 6518, loss = 0.05310551\n","Iteration 6519, loss = 0.05310045\n","Iteration 6520, loss = 0.05309545\n","Iteration 6521, loss = 0.05309044\n","Iteration 6522, loss = 0.05308543\n","Iteration 6523, loss = 0.05308046\n","Iteration 6524, loss = 0.05307544\n","Iteration 6525, loss = 0.05307049\n","Iteration 6526, loss = 0.05306546\n","Iteration 6527, loss = 0.05306047\n","Iteration 6528, loss = 0.05305552\n","Iteration 6529, loss = 0.05305053\n","Iteration 6530, loss = 0.05304556\n","Iteration 6531, loss = 0.05304060\n","Iteration 6532, loss = 0.05303564\n","Iteration 6533, loss = 0.05303067\n","Iteration 6534, loss = 0.05302570\n","Iteration 6535, loss = 0.05302075\n","Iteration 6536, loss = 0.05301576\n","Iteration 6537, loss = 0.05301080\n","Iteration 6538, loss = 0.05300584\n","Iteration 6539, loss = 0.05300087\n","Iteration 6540, loss = 0.05299590\n","Iteration 6541, loss = 0.05299094\n","Iteration 6542, loss = 0.05298599\n","Iteration 6543, loss = 0.05298105\n","Iteration 6544, loss = 0.05297610\n","Iteration 6545, loss = 0.05297115\n","Iteration 6546, loss = 0.05296620\n","Iteration 6547, loss = 0.05296133\n","Iteration 6548, loss = 0.05295634\n","Iteration 6549, loss = 0.05295143\n","Iteration 6550, loss = 0.05294654\n","Iteration 6551, loss = 0.05294172\n","Iteration 6552, loss = 0.05293669\n","Iteration 6553, loss = 0.05293173\n","Iteration 6554, loss = 0.05292679\n","Iteration 6555, loss = 0.05292193\n","Iteration 6556, loss = 0.05291702\n","Iteration 6557, loss = 0.05291206\n","Iteration 6558, loss = 0.05290716\n","Iteration 6559, loss = 0.05290228\n","Iteration 6560, loss = 0.05289737\n","Iteration 6561, loss = 0.05289246\n","Iteration 6562, loss = 0.05288759\n","Iteration 6563, loss = 0.05288267\n","Iteration 6564, loss = 0.05287777\n","Iteration 6565, loss = 0.05287293\n","Iteration 6566, loss = 0.05286804\n","Iteration 6567, loss = 0.05286312\n","Iteration 6568, loss = 0.05285817\n","Iteration 6569, loss = 0.05285334\n","Iteration 6570, loss = 0.05284845\n","Iteration 6571, loss = 0.05284350\n","Iteration 6572, loss = 0.05283870\n","Iteration 6573, loss = 0.05283382\n","Iteration 6574, loss = 0.05282889\n","Iteration 6575, loss = 0.05282406\n","Iteration 6576, loss = 0.05281919\n","Iteration 6577, loss = 0.05281431\n","Iteration 6578, loss = 0.05280947\n","Iteration 6579, loss = 0.05280459\n","Iteration 6580, loss = 0.05279972\n","Iteration 6581, loss = 0.05279484\n","Iteration 6582, loss = 0.05279002\n","Iteration 6583, loss = 0.05278515\n","Iteration 6584, loss = 0.05278030\n","Iteration 6585, loss = 0.05277549\n","Iteration 6586, loss = 0.05277062\n","Iteration 6587, loss = 0.05276582\n","Iteration 6588, loss = 0.05276098\n","Iteration 6589, loss = 0.05275612\n","Iteration 6590, loss = 0.05275135\n","Iteration 6591, loss = 0.05274652\n","Iteration 6592, loss = 0.05274165\n","Iteration 6593, loss = 0.05273686\n","Iteration 6594, loss = 0.05273202\n","Iteration 6595, loss = 0.05272720\n","Iteration 6596, loss = 0.05272239\n","Iteration 6597, loss = 0.05271753\n","Iteration 6598, loss = 0.05271271\n","Iteration 6599, loss = 0.05270793\n","Iteration 6600, loss = 0.05270310\n","Iteration 6601, loss = 0.05269832\n","Iteration 6602, loss = 0.05269350\n","Iteration 6603, loss = 0.05268868\n","Iteration 6604, loss = 0.05268389\n","Iteration 6605, loss = 0.05267907\n","Iteration 6606, loss = 0.05267427\n","Iteration 6607, loss = 0.05266952\n","Iteration 6608, loss = 0.05266474\n","Iteration 6609, loss = 0.05265991\n","Iteration 6610, loss = 0.05265516\n","Iteration 6611, loss = 0.05265039\n","Iteration 6612, loss = 0.05264558\n","Iteration 6613, loss = 0.05264076\n","Iteration 6614, loss = 0.05263599\n","Iteration 6615, loss = 0.05263121\n","Iteration 6616, loss = 0.05262647\n","Iteration 6617, loss = 0.05262170\n","Iteration 6618, loss = 0.05261690\n","Iteration 6619, loss = 0.05261216\n","Iteration 6620, loss = 0.05260742\n","Iteration 6621, loss = 0.05260265\n","Iteration 6622, loss = 0.05259783\n","Iteration 6623, loss = 0.05259316\n","Iteration 6624, loss = 0.05258845\n","Iteration 6625, loss = 0.05258368\n","Iteration 6626, loss = 0.05257886\n","Iteration 6627, loss = 0.05257407\n","Iteration 6628, loss = 0.05256936\n","Iteration 6629, loss = 0.05256461\n","Iteration 6630, loss = 0.05255984\n","Iteration 6631, loss = 0.05255517\n","Iteration 6632, loss = 0.05255041\n","Iteration 6633, loss = 0.05254566\n","Iteration 6634, loss = 0.05254087\n","Iteration 6635, loss = 0.05253616\n","Iteration 6636, loss = 0.05253143\n","Iteration 6637, loss = 0.05252671\n","Iteration 6638, loss = 0.05252199\n","Iteration 6639, loss = 0.05251726\n","Iteration 6640, loss = 0.05251254\n","Iteration 6641, loss = 0.05250783\n","Iteration 6642, loss = 0.05250309\n","Iteration 6643, loss = 0.05249843\n","Iteration 6644, loss = 0.05249372\n","Iteration 6645, loss = 0.05248900\n","Iteration 6646, loss = 0.05248432\n","Iteration 6647, loss = 0.05247963\n","Iteration 6648, loss = 0.05247492\n","Iteration 6649, loss = 0.05247017\n","Iteration 6650, loss = 0.05246551\n","Iteration 6651, loss = 0.05246086\n","Iteration 6652, loss = 0.05245615\n","Iteration 6653, loss = 0.05245139\n","Iteration 6654, loss = 0.05244674\n","Iteration 6655, loss = 0.05244209\n","Iteration 6656, loss = 0.05243740\n","Iteration 6657, loss = 0.05243267\n","Iteration 6658, loss = 0.05242791\n","Iteration 6659, loss = 0.05242327\n","Iteration 6660, loss = 0.05241856\n","Iteration 6661, loss = 0.05241393\n","Iteration 6662, loss = 0.05240927\n","Iteration 6663, loss = 0.05240457\n","Iteration 6664, loss = 0.05239988\n","Iteration 6665, loss = 0.05239523\n","Iteration 6666, loss = 0.05239053\n","Iteration 6667, loss = 0.05238588\n","Iteration 6668, loss = 0.05238123\n","Iteration 6669, loss = 0.05237656\n","Iteration 6670, loss = 0.05237192\n","Iteration 6671, loss = 0.05236727\n","Iteration 6672, loss = 0.05236258\n","Iteration 6673, loss = 0.05235793\n","Iteration 6674, loss = 0.05235331\n","Iteration 6675, loss = 0.05234865\n","Iteration 6676, loss = 0.05234401\n","Iteration 6677, loss = 0.05233937\n","Iteration 6678, loss = 0.05233470\n","Iteration 6679, loss = 0.05233007\n","Iteration 6680, loss = 0.05232545\n","Iteration 6681, loss = 0.05232080\n","Iteration 6682, loss = 0.05231622\n","Iteration 6683, loss = 0.05231161\n","Iteration 6684, loss = 0.05230695\n","Iteration 6685, loss = 0.05230230\n","Iteration 6686, loss = 0.05229769\n","Iteration 6687, loss = 0.05229303\n","Iteration 6688, loss = 0.05228849\n","Iteration 6689, loss = 0.05228388\n","Iteration 6690, loss = 0.05227925\n","Iteration 6691, loss = 0.05227457\n","Iteration 6692, loss = 0.05227004\n","Iteration 6693, loss = 0.05226547\n","Iteration 6694, loss = 0.05226086\n","Iteration 6695, loss = 0.05225619\n","Iteration 6696, loss = 0.05225157\n","Iteration 6697, loss = 0.05224701\n","Iteration 6698, loss = 0.05224241\n","Iteration 6699, loss = 0.05223777\n","Iteration 6700, loss = 0.05223319\n","Iteration 6701, loss = 0.05222862\n","Iteration 6702, loss = 0.05222401\n","Iteration 6703, loss = 0.05221939\n","Iteration 6704, loss = 0.05221480\n","Iteration 6705, loss = 0.05221019\n","Iteration 6706, loss = 0.05220568\n","Iteration 6707, loss = 0.05220111\n","Iteration 6708, loss = 0.05219650\n","Iteration 6709, loss = 0.05219196\n","Iteration 6710, loss = 0.05218736\n","Iteration 6711, loss = 0.05218278\n","Iteration 6712, loss = 0.05217820\n","Iteration 6713, loss = 0.05217364\n","Iteration 6714, loss = 0.05216907\n","Iteration 6715, loss = 0.05216450\n","Iteration 6716, loss = 0.05215997\n","Iteration 6717, loss = 0.05215540\n","Iteration 6718, loss = 0.05215084\n","Iteration 6719, loss = 0.05214628\n","Iteration 6720, loss = 0.05214173\n","Iteration 6721, loss = 0.05213717\n","Iteration 6722, loss = 0.05213266\n","Iteration 6723, loss = 0.05212812\n","Iteration 6724, loss = 0.05212353\n","Iteration 6725, loss = 0.05211905\n","Iteration 6726, loss = 0.05211451\n","Iteration 6727, loss = 0.05210994\n","Iteration 6728, loss = 0.05210539\n","Iteration 6729, loss = 0.05210087\n","Iteration 6730, loss = 0.05209632\n","Iteration 6731, loss = 0.05209179\n","Iteration 6732, loss = 0.05208727\n","Iteration 6733, loss = 0.05208273\n","Iteration 6734, loss = 0.05207825\n","Iteration 6735, loss = 0.05207376\n","Iteration 6736, loss = 0.05206922\n","Iteration 6737, loss = 0.05206465\n","Iteration 6738, loss = 0.05206016\n","Iteration 6739, loss = 0.05205568\n","Iteration 6740, loss = 0.05205116\n","Iteration 6741, loss = 0.05204658\n","Iteration 6742, loss = 0.05204212\n","Iteration 6743, loss = 0.05203767\n","Iteration 6744, loss = 0.05203316\n","Iteration 6745, loss = 0.05202861\n","Iteration 6746, loss = 0.05202403\n","Iteration 6747, loss = 0.05201965\n","Iteration 6748, loss = 0.05201521\n","Iteration 6749, loss = 0.05201072\n","Iteration 6750, loss = 0.05200618\n","Iteration 6751, loss = 0.05200160\n","Iteration 6752, loss = 0.05199714\n","Iteration 6753, loss = 0.05199272\n","Iteration 6754, loss = 0.05198825\n","Iteration 6755, loss = 0.05198374\n","Iteration 6756, loss = 0.05197921\n","Iteration 6757, loss = 0.05197466\n","Iteration 6758, loss = 0.05197023\n","Iteration 6759, loss = 0.05196575\n","Iteration 6760, loss = 0.05196121\n","Iteration 6761, loss = 0.05195682\n","Iteration 6762, loss = 0.05195239\n","Iteration 6763, loss = 0.05194792\n","Iteration 6764, loss = 0.05194341\n","Iteration 6765, loss = 0.05193887\n","Iteration 6766, loss = 0.05193444\n","Iteration 6767, loss = 0.05192996\n","Iteration 6768, loss = 0.05192554\n","Iteration 6769, loss = 0.05192110\n","Iteration 6770, loss = 0.05191661\n","Iteration 6771, loss = 0.05191214\n","Iteration 6772, loss = 0.05190771\n","Iteration 6773, loss = 0.05190322\n","Iteration 6774, loss = 0.05189885\n","Iteration 6775, loss = 0.05189443\n","Iteration 6776, loss = 0.05188997\n","Iteration 6777, loss = 0.05188546\n","Iteration 6778, loss = 0.05188107\n","Iteration 6779, loss = 0.05187668\n","Iteration 6780, loss = 0.05187223\n","Iteration 6781, loss = 0.05186773\n","Iteration 6782, loss = 0.05186332\n","Iteration 6783, loss = 0.05185894\n","Iteration 6784, loss = 0.05185451\n","Iteration 6785, loss = 0.05185004\n","Iteration 6786, loss = 0.05184556\n","Iteration 6787, loss = 0.05184120\n","Iteration 6788, loss = 0.05183672\n","Iteration 6789, loss = 0.05183233\n","Iteration 6790, loss = 0.05182794\n","Iteration 6791, loss = 0.05182354\n","Iteration 6792, loss = 0.05181908\n","Iteration 6793, loss = 0.05181468\n","Iteration 6794, loss = 0.05181025\n","Iteration 6795, loss = 0.05180591\n","Iteration 6796, loss = 0.05180154\n","Iteration 6797, loss = 0.05179713\n","Iteration 6798, loss = 0.05179267\n","Iteration 6799, loss = 0.05178831\n","Iteration 6800, loss = 0.05178395\n","Iteration 6801, loss = 0.05177954\n","Iteration 6802, loss = 0.05177508\n","Iteration 6803, loss = 0.05177074\n","Iteration 6804, loss = 0.05176640\n","Iteration 6805, loss = 0.05176201\n","Iteration 6806, loss = 0.05175759\n","Iteration 6807, loss = 0.05175313\n","Iteration 6808, loss = 0.05174877\n","Iteration 6809, loss = 0.05174436\n","Iteration 6810, loss = 0.05174004\n","Iteration 6811, loss = 0.05173569\n","Iteration 6812, loss = 0.05173129\n","Iteration 6813, loss = 0.05172687\n","Iteration 6814, loss = 0.05172251\n","Iteration 6815, loss = 0.05171814\n","Iteration 6816, loss = 0.05171376\n","Iteration 6817, loss = 0.05170943\n","Iteration 6818, loss = 0.05170507\n","Iteration 6819, loss = 0.05170066\n","Iteration 6820, loss = 0.05169630\n","Iteration 6821, loss = 0.05169198\n","Iteration 6822, loss = 0.05168762\n","Iteration 6823, loss = 0.05168326\n","Iteration 6824, loss = 0.05167891\n","Iteration 6825, loss = 0.05167452\n","Iteration 6826, loss = 0.05167021\n","Iteration 6827, loss = 0.05166584\n","Iteration 6828, loss = 0.05166149\n","Iteration 6829, loss = 0.05165716\n","Iteration 6830, loss = 0.05165281\n","Iteration 6831, loss = 0.05164847\n","Iteration 6832, loss = 0.05164413\n","Iteration 6833, loss = 0.05163978\n","Iteration 6834, loss = 0.05163551\n","Iteration 6835, loss = 0.05163118\n","Iteration 6836, loss = 0.05162681\n","Iteration 6837, loss = 0.05162253\n","Iteration 6838, loss = 0.05161824\n","Iteration 6839, loss = 0.05161390\n","Iteration 6840, loss = 0.05160952\n","Iteration 6841, loss = 0.05160521\n","Iteration 6842, loss = 0.05160094\n","Iteration 6843, loss = 0.05159659\n","Iteration 6844, loss = 0.05159220\n","Iteration 6845, loss = 0.05158799\n","Iteration 6846, loss = 0.05158373\n","Iteration 6847, loss = 0.05157942\n","Iteration 6848, loss = 0.05157506\n","Iteration 6849, loss = 0.05157069\n","Iteration 6850, loss = 0.05156643\n","Iteration 6851, loss = 0.05156219\n","Iteration 6852, loss = 0.05155789\n","Iteration 6853, loss = 0.05155354\n","Iteration 6854, loss = 0.05154914\n","Iteration 6855, loss = 0.05154497\n","Iteration 6856, loss = 0.05154074\n","Iteration 6857, loss = 0.05153646\n","Iteration 6858, loss = 0.05153217\n","Iteration 6859, loss = 0.05152779\n","Iteration 6860, loss = 0.05152341\n","Iteration 6861, loss = 0.05151921\n","Iteration 6862, loss = 0.05151501\n","Iteration 6863, loss = 0.05151074\n","Iteration 6864, loss = 0.05150643\n","Iteration 6865, loss = 0.05150209\n","Iteration 6866, loss = 0.05149772\n","Iteration 6867, loss = 0.05149351\n","Iteration 6868, loss = 0.05148925\n","Iteration 6869, loss = 0.05148495\n","Iteration 6870, loss = 0.05148061\n","Iteration 6871, loss = 0.05147636\n","Iteration 6872, loss = 0.05147209\n","Iteration 6873, loss = 0.05146781\n","Iteration 6874, loss = 0.05146361\n","Iteration 6875, loss = 0.05145936\n","Iteration 6876, loss = 0.05145505\n","Iteration 6877, loss = 0.05145086\n","Iteration 6878, loss = 0.05144664\n","Iteration 6879, loss = 0.05144237\n","Iteration 6880, loss = 0.05143807\n","Iteration 6881, loss = 0.05143380\n","Iteration 6882, loss = 0.05142962\n","Iteration 6883, loss = 0.05142532\n","Iteration 6884, loss = 0.05142104\n","Iteration 6885, loss = 0.05141683\n","Iteration 6886, loss = 0.05141257\n","Iteration 6887, loss = 0.05140835\n","Iteration 6888, loss = 0.05140411\n","Iteration 6889, loss = 0.05139988\n","Iteration 6890, loss = 0.05139563\n","Iteration 6891, loss = 0.05139143\n","Iteration 6892, loss = 0.05138718\n","Iteration 6893, loss = 0.05138298\n","Iteration 6894, loss = 0.05137876\n","Iteration 6895, loss = 0.05137448\n","Iteration 6896, loss = 0.05137033\n","Iteration 6897, loss = 0.05136613\n","Iteration 6898, loss = 0.05136190\n","Iteration 6899, loss = 0.05135762\n","Iteration 6900, loss = 0.05135341\n","Iteration 6901, loss = 0.05134922\n","Iteration 6902, loss = 0.05134498\n","Iteration 6903, loss = 0.05134073\n","Iteration 6904, loss = 0.05133654\n","Iteration 6905, loss = 0.05133232\n","Iteration 6906, loss = 0.05132812\n","Iteration 6907, loss = 0.05132391\n","Iteration 6908, loss = 0.05131971\n","Iteration 6909, loss = 0.05131550\n","Iteration 6910, loss = 0.05131132\n","Iteration 6911, loss = 0.05130710\n","Iteration 6912, loss = 0.05130295\n","Iteration 6913, loss = 0.05129875\n","Iteration 6914, loss = 0.05129450\n","Iteration 6915, loss = 0.05129038\n","Iteration 6916, loss = 0.05128622\n","Iteration 6917, loss = 0.05128202\n","Iteration 6918, loss = 0.05127778\n","Iteration 6919, loss = 0.05127359\n","Iteration 6920, loss = 0.05126945\n","Iteration 6921, loss = 0.05126525\n","Iteration 6922, loss = 0.05126102\n","Iteration 6923, loss = 0.05125686\n","Iteration 6924, loss = 0.05125268\n","Iteration 6925, loss = 0.05124850\n","Iteration 6926, loss = 0.05124433\n","Iteration 6927, loss = 0.05124015\n","Iteration 6928, loss = 0.05123598\n","Iteration 6929, loss = 0.05123182\n","Iteration 6930, loss = 0.05122764\n","Iteration 6931, loss = 0.05122353\n","Iteration 6932, loss = 0.05121937\n","Iteration 6933, loss = 0.05121516\n","Iteration 6934, loss = 0.05121106\n","Iteration 6935, loss = 0.05120694\n","Iteration 6936, loss = 0.05120277\n","Iteration 6937, loss = 0.05119857\n","Iteration 6938, loss = 0.05119442\n","Iteration 6939, loss = 0.05119031\n","Iteration 6940, loss = 0.05118614\n","Iteration 6941, loss = 0.05118193\n","Iteration 6942, loss = 0.05117780\n","Iteration 6943, loss = 0.05117365\n","Iteration 6944, loss = 0.05116950\n","Iteration 6945, loss = 0.05116537\n","Iteration 6946, loss = 0.05116123\n","Iteration 6947, loss = 0.05115709\n","Iteration 6948, loss = 0.05115296\n","Iteration 6949, loss = 0.05114881\n","Iteration 6950, loss = 0.05114474\n","Iteration 6951, loss = 0.05114061\n","Iteration 6952, loss = 0.05113643\n","Iteration 6953, loss = 0.05113235\n","Iteration 6954, loss = 0.05112829\n","Iteration 6955, loss = 0.05112414\n","Iteration 6956, loss = 0.05111997\n","Iteration 6957, loss = 0.05111583\n","Iteration 6958, loss = 0.05111174\n","Iteration 6959, loss = 0.05110759\n","Iteration 6960, loss = 0.05110348\n","Iteration 6961, loss = 0.05109939\n","Iteration 6962, loss = 0.05109528\n","Iteration 6963, loss = 0.05109112\n","Iteration 6964, loss = 0.05108702\n","Iteration 6965, loss = 0.05108291\n","Iteration 6966, loss = 0.05107880\n","Iteration 6967, loss = 0.05107471\n","Iteration 6968, loss = 0.05107059\n","Iteration 6969, loss = 0.05106651\n","Iteration 6970, loss = 0.05106244\n","Iteration 6971, loss = 0.05105830\n","Iteration 6972, loss = 0.05105423\n","Iteration 6973, loss = 0.05105015\n","Iteration 6974, loss = 0.05104601\n","Iteration 6975, loss = 0.05104197\n","Iteration 6976, loss = 0.05103792\n","Iteration 6977, loss = 0.05103382\n","Iteration 6978, loss = 0.05102968\n","Iteration 6979, loss = 0.05102558\n","Iteration 6980, loss = 0.05102153\n","Iteration 6981, loss = 0.05101742\n","Iteration 6982, loss = 0.05101336\n","Iteration 6983, loss = 0.05100930\n","Iteration 6984, loss = 0.05100521\n","Iteration 6985, loss = 0.05100108\n","Iteration 6986, loss = 0.05099709\n","Iteration 6987, loss = 0.05099307\n","Iteration 6988, loss = 0.05098896\n","Iteration 6989, loss = 0.05098481\n","Iteration 6990, loss = 0.05098080\n","Iteration 6991, loss = 0.05097680\n","Iteration 6992, loss = 0.05097274\n","Iteration 6993, loss = 0.05096865\n","Iteration 6994, loss = 0.05096450\n","Iteration 6995, loss = 0.05096020\n","Iteration 6996, loss = 0.05095586\n","Iteration 6997, loss = 0.05095137\n","Iteration 6998, loss = 0.05094591\n","Iteration 6999, loss = 0.05093988\n","Iteration 7000, loss = 0.05093404\n","Iteration 7001, loss = 0.05092915\n","Iteration 7002, loss = 0.05092545\n","Iteration 7003, loss = 0.05092168\n","Iteration 7004, loss = 0.05091728\n","Iteration 7005, loss = 0.05091279\n","Iteration 7006, loss = 0.05090830\n","Iteration 7007, loss = 0.05090395\n","Iteration 7008, loss = 0.05089963\n","Iteration 7009, loss = 0.05089536\n","Iteration 7010, loss = 0.05089103\n","Iteration 7011, loss = 0.05088677\n","Iteration 7012, loss = 0.05088250\n","Iteration 7013, loss = 0.05087820\n","Iteration 7014, loss = 0.05087386\n","Iteration 7015, loss = 0.05086965\n","Iteration 7016, loss = 0.05086541\n","Iteration 7017, loss = 0.05086110\n","Iteration 7018, loss = 0.05085673\n","Iteration 7019, loss = 0.05085254\n","Iteration 7020, loss = 0.05084833\n","Iteration 7021, loss = 0.05084407\n","Iteration 7022, loss = 0.05083978\n","Iteration 7023, loss = 0.05083545\n","Iteration 7024, loss = 0.05083114\n","Iteration 7025, loss = 0.05082693\n","Iteration 7026, loss = 0.05082267\n","Iteration 7027, loss = 0.05081840\n","Iteration 7028, loss = 0.05081418\n","Iteration 7029, loss = 0.05080992\n","Iteration 7030, loss = 0.05080574\n","Iteration 7031, loss = 0.05080152\n","Iteration 7032, loss = 0.05079723\n","Iteration 7033, loss = 0.05079305\n","Iteration 7034, loss = 0.05078886\n","Iteration 7035, loss = 0.05078463\n","Iteration 7036, loss = 0.05078036\n","Iteration 7037, loss = 0.05077611\n","Iteration 7038, loss = 0.05077192\n","Iteration 7039, loss = 0.05076768\n","Iteration 7040, loss = 0.05076351\n","Iteration 7041, loss = 0.05075933\n","Iteration 7042, loss = 0.05075511\n","Iteration 7043, loss = 0.05075085\n","Iteration 7044, loss = 0.05074672\n","Iteration 7045, loss = 0.05074256\n","Iteration 7046, loss = 0.05073834\n","Iteration 7047, loss = 0.05073406\n","Iteration 7048, loss = 0.05072996\n","Iteration 7049, loss = 0.05072583\n","Iteration 7050, loss = 0.05072166\n","Iteration 7051, loss = 0.05071744\n","Iteration 7052, loss = 0.05071319\n","Iteration 7053, loss = 0.05070894\n","Iteration 7054, loss = 0.05070482\n","Iteration 7055, loss = 0.05070062\n","Iteration 7056, loss = 0.05069642\n","Iteration 7057, loss = 0.05069227\n","Iteration 7058, loss = 0.05068807\n","Iteration 7059, loss = 0.05068395\n","Iteration 7060, loss = 0.05067979\n","Iteration 7061, loss = 0.05067557\n","Iteration 7062, loss = 0.05067149\n","Iteration 7063, loss = 0.05066733\n","Iteration 7064, loss = 0.05066317\n","Iteration 7065, loss = 0.05065897\n","Iteration 7066, loss = 0.05065478\n","Iteration 7067, loss = 0.05065066\n","Iteration 7068, loss = 0.05064647\n","Iteration 7069, loss = 0.05064236\n","Iteration 7070, loss = 0.05063823\n","Iteration 7071, loss = 0.05063407\n","Iteration 7072, loss = 0.05062988\n","Iteration 7073, loss = 0.05062582\n","Iteration 7074, loss = 0.05062171\n","Iteration 7075, loss = 0.05061754\n","Iteration 7076, loss = 0.05061332\n","Iteration 7077, loss = 0.05060925\n","Iteration 7078, loss = 0.05060517\n","Iteration 7079, loss = 0.05060109\n","Iteration 7080, loss = 0.05059690\n","Iteration 7081, loss = 0.05059270\n","Iteration 7082, loss = 0.05058853\n","Iteration 7083, loss = 0.05058445\n","Iteration 7084, loss = 0.05058031\n","Iteration 7085, loss = 0.05057614\n","Iteration 7086, loss = 0.05057205\n","Iteration 7087, loss = 0.05056789\n","Iteration 7088, loss = 0.05056385\n","Iteration 7089, loss = 0.05055975\n","Iteration 7090, loss = 0.05055558\n","Iteration 7091, loss = 0.05055149\n","Iteration 7092, loss = 0.05054742\n","Iteration 7093, loss = 0.05054330\n","Iteration 7094, loss = 0.05053914\n","Iteration 7095, loss = 0.05053503\n","Iteration 7096, loss = 0.05053096\n","Iteration 7097, loss = 0.05052683\n","Iteration 7098, loss = 0.05052273\n","Iteration 7099, loss = 0.05051866\n","Iteration 7100, loss = 0.05051454\n","Iteration 7101, loss = 0.05051039\n","Iteration 7102, loss = 0.05050630\n","Iteration 7103, loss = 0.05050224\n","Iteration 7104, loss = 0.05049818\n","Iteration 7105, loss = 0.05049403\n","Iteration 7106, loss = 0.05049000\n","Iteration 7107, loss = 0.05048593\n","Iteration 7108, loss = 0.05048181\n","Iteration 7109, loss = 0.05047771\n","Iteration 7110, loss = 0.05047366\n","Iteration 7111, loss = 0.05046956\n","Iteration 7112, loss = 0.05046546\n","Iteration 7113, loss = 0.05046144\n","Iteration 7114, loss = 0.05045740\n","Iteration 7115, loss = 0.05045330\n","Iteration 7116, loss = 0.05044914\n","Iteration 7117, loss = 0.05044516\n","Iteration 7118, loss = 0.05044115\n","Iteration 7119, loss = 0.05043709\n","Iteration 7120, loss = 0.05043300\n","Iteration 7121, loss = 0.05042887\n","Iteration 7122, loss = 0.05042473\n","Iteration 7123, loss = 0.05042072\n","Iteration 7124, loss = 0.05041664\n","Iteration 7125, loss = 0.05041257\n","Iteration 7126, loss = 0.05040853\n","Iteration 7127, loss = 0.05040444\n","Iteration 7128, loss = 0.05040042\n","Iteration 7129, loss = 0.05039637\n","Iteration 7130, loss = 0.05039227\n","Iteration 7131, loss = 0.05038828\n","Iteration 7132, loss = 0.05038427\n","Iteration 7133, loss = 0.05038022\n","Iteration 7134, loss = 0.05037613\n","Iteration 7135, loss = 0.05037205\n","Iteration 7136, loss = 0.05036803\n","Iteration 7137, loss = 0.05036395\n","Iteration 7138, loss = 0.05035997\n","Iteration 7139, loss = 0.05035593\n","Iteration 7140, loss = 0.05035188\n","Iteration 7141, loss = 0.05034779\n","Iteration 7142, loss = 0.05034385\n","Iteration 7143, loss = 0.05033985\n","Iteration 7144, loss = 0.05033579\n","Iteration 7145, loss = 0.05033167\n","Iteration 7146, loss = 0.05032773\n","Iteration 7147, loss = 0.05032374\n","Iteration 7148, loss = 0.05031973\n","Iteration 7149, loss = 0.05031568\n","Iteration 7150, loss = 0.05031159\n","Iteration 7151, loss = 0.05030755\n","Iteration 7152, loss = 0.05030358\n","Iteration 7153, loss = 0.05029954\n","Iteration 7154, loss = 0.05029545\n","Iteration 7155, loss = 0.05029156\n","Iteration 7156, loss = 0.05028757\n","Iteration 7157, loss = 0.05028356\n","Iteration 7158, loss = 0.05027952\n","Iteration 7159, loss = 0.05027544\n","Iteration 7160, loss = 0.05027144\n","Iteration 7161, loss = 0.05026749\n","Iteration 7162, loss = 0.05026347\n","Iteration 7163, loss = 0.05025941\n","Iteration 7164, loss = 0.05025543\n","Iteration 7165, loss = 0.05025148\n","Iteration 7166, loss = 0.05024749\n","Iteration 7167, loss = 0.05024346\n","Iteration 7168, loss = 0.05023938\n","Iteration 7169, loss = 0.05023548\n","Iteration 7170, loss = 0.05023154\n","Iteration 7171, loss = 0.05022754\n","Iteration 7172, loss = 0.05022349\n","Iteration 7173, loss = 0.05021943\n","Iteration 7174, loss = 0.05021549\n","Iteration 7175, loss = 0.05021151\n","Iteration 7176, loss = 0.05020749\n","Iteration 7177, loss = 0.05020350\n","Iteration 7178, loss = 0.05019953\n","Iteration 7179, loss = 0.05019550\n","Iteration 7180, loss = 0.05019158\n","Iteration 7181, loss = 0.05018764\n","Iteration 7182, loss = 0.05018365\n","Iteration 7183, loss = 0.05017963\n","Iteration 7184, loss = 0.05017568\n","Iteration 7185, loss = 0.05017175\n","Iteration 7186, loss = 0.05016775\n","Iteration 7187, loss = 0.05016371\n","Iteration 7188, loss = 0.05015976\n","Iteration 7189, loss = 0.05015577\n","Iteration 7190, loss = 0.05015190\n","Iteration 7191, loss = 0.05014789\n","Iteration 7192, loss = 0.05014388\n","Iteration 7193, loss = 0.05014002\n","Iteration 7194, loss = 0.05013611\n","Iteration 7195, loss = 0.05013216\n","Iteration 7196, loss = 0.05012816\n","Iteration 7197, loss = 0.05012413\n","Iteration 7198, loss = 0.05012021\n","Iteration 7199, loss = 0.05011623\n","Iteration 7200, loss = 0.05011229\n","Iteration 7201, loss = 0.05010835\n","Iteration 7202, loss = 0.05010439\n","Iteration 7203, loss = 0.05010046\n","Iteration 7204, loss = 0.05009650\n","Iteration 7205, loss = 0.05009255\n","Iteration 7206, loss = 0.05008861\n","Iteration 7207, loss = 0.05008462\n","Iteration 7208, loss = 0.05008075\n","Iteration 7209, loss = 0.05007685\n","Iteration 7210, loss = 0.05007284\n","Iteration 7211, loss = 0.05006891\n","Iteration 7212, loss = 0.05006502\n","Iteration 7213, loss = 0.05006108\n","Iteration 7214, loss = 0.05005710\n","Iteration 7215, loss = 0.05005327\n","Iteration 7216, loss = 0.05004937\n","Iteration 7217, loss = 0.05004542\n","Iteration 7218, loss = 0.05004140\n","Iteration 7219, loss = 0.05003757\n","Iteration 7220, loss = 0.05003371\n","Iteration 7221, loss = 0.05002979\n","Iteration 7222, loss = 0.05002584\n","Iteration 7223, loss = 0.05002184\n","Iteration 7224, loss = 0.05001786\n","Iteration 7225, loss = 0.05001398\n","Iteration 7226, loss = 0.05001008\n","Iteration 7227, loss = 0.05000610\n","Iteration 7228, loss = 0.05000221\n","Iteration 7229, loss = 0.04999828\n","Iteration 7230, loss = 0.04999440\n","Iteration 7231, loss = 0.04999048\n","Iteration 7232, loss = 0.04998665\n","Iteration 7233, loss = 0.04998275\n","Iteration 7234, loss = 0.04997879\n","Iteration 7235, loss = 0.04997495\n","Iteration 7236, loss = 0.04997109\n","Iteration 7237, loss = 0.04996718\n","Iteration 7238, loss = 0.04996323\n","Iteration 7239, loss = 0.04995927\n","Iteration 7240, loss = 0.04995540\n","Iteration 7241, loss = 0.04995146\n","Iteration 7242, loss = 0.04994762\n","Iteration 7243, loss = 0.04994375\n","Iteration 7244, loss = 0.04993984\n","Iteration 7245, loss = 0.04993589\n","Iteration 7246, loss = 0.04993209\n","Iteration 7247, loss = 0.04992824\n","Iteration 7248, loss = 0.04992433\n","Iteration 7249, loss = 0.04992039\n","Iteration 7250, loss = 0.04991654\n","Iteration 7251, loss = 0.04991273\n","Iteration 7252, loss = 0.04990886\n","Iteration 7253, loss = 0.04990495\n","Iteration 7254, loss = 0.04990101\n","Iteration 7255, loss = 0.04989715\n","Iteration 7256, loss = 0.04989333\n","Iteration 7257, loss = 0.04988944\n","Iteration 7258, loss = 0.04988549\n","Iteration 7259, loss = 0.04988168\n","Iteration 7260, loss = 0.04987784\n","Iteration 7261, loss = 0.04987398\n","Iteration 7262, loss = 0.04987008\n","Iteration 7263, loss = 0.04986613\n","Iteration 7264, loss = 0.04986238\n","Iteration 7265, loss = 0.04985858\n","Iteration 7266, loss = 0.04985471\n","Iteration 7267, loss = 0.04985081\n","Iteration 7268, loss = 0.04984683\n","Iteration 7269, loss = 0.04984303\n","Iteration 7270, loss = 0.04983918\n","Iteration 7271, loss = 0.04983528\n","Iteration 7272, loss = 0.04983148\n","Iteration 7273, loss = 0.04982765\n","Iteration 7274, loss = 0.04982376\n","Iteration 7275, loss = 0.04981988\n","Iteration 7276, loss = 0.04981609\n","Iteration 7277, loss = 0.04981221\n","Iteration 7278, loss = 0.04980833\n","Iteration 7279, loss = 0.04980449\n","Iteration 7280, loss = 0.04980068\n","Iteration 7281, loss = 0.04979684\n","Iteration 7282, loss = 0.04979296\n","Iteration 7283, loss = 0.04978921\n","Iteration 7284, loss = 0.04978539\n","Iteration 7285, loss = 0.04978156\n","Iteration 7286, loss = 0.04977762\n","Iteration 7287, loss = 0.04977382\n","Iteration 7288, loss = 0.04976998\n","Iteration 7289, loss = 0.04976616\n","Iteration 7290, loss = 0.04976233\n","Iteration 7291, loss = 0.04975848\n","Iteration 7292, loss = 0.04975466\n","Iteration 7293, loss = 0.04975084\n","Iteration 7294, loss = 0.04974699\n","Iteration 7295, loss = 0.04974324\n","Iteration 7296, loss = 0.04973944\n","Iteration 7297, loss = 0.04973559\n","Iteration 7298, loss = 0.04973175\n","Iteration 7299, loss = 0.04972794\n","Iteration 7300, loss = 0.04972409\n","Iteration 7301, loss = 0.04972027\n","Iteration 7302, loss = 0.04971651\n","Iteration 7303, loss = 0.04971273\n","Iteration 7304, loss = 0.04970885\n","Iteration 7305, loss = 0.04970506\n","Iteration 7306, loss = 0.04970125\n","Iteration 7307, loss = 0.04969746\n","Iteration 7308, loss = 0.04969367\n","Iteration 7309, loss = 0.04968987\n","Iteration 7310, loss = 0.04968606\n","Iteration 7311, loss = 0.04968229\n","Iteration 7312, loss = 0.04967848\n","Iteration 7313, loss = 0.04967470\n","Iteration 7314, loss = 0.04967090\n","Iteration 7315, loss = 0.04966709\n","Iteration 7316, loss = 0.04966329\n","Iteration 7317, loss = 0.04965948\n","Iteration 7318, loss = 0.04965567\n","Iteration 7319, loss = 0.04965189\n","Iteration 7320, loss = 0.04964808\n","Iteration 7321, loss = 0.04964429\n","Iteration 7322, loss = 0.04964049\n","Iteration 7323, loss = 0.04963676\n","Iteration 7324, loss = 0.04963301\n","Iteration 7325, loss = 0.04962919\n","Iteration 7326, loss = 0.04962537\n","Iteration 7327, loss = 0.04962160\n","Iteration 7328, loss = 0.04961786\n","Iteration 7329, loss = 0.04961407\n","Iteration 7330, loss = 0.04961032\n","Iteration 7331, loss = 0.04960656\n","Iteration 7332, loss = 0.04960276\n","Iteration 7333, loss = 0.04959899\n","Iteration 7334, loss = 0.04959523\n","Iteration 7335, loss = 0.04959141\n","Iteration 7336, loss = 0.04958771\n","Iteration 7337, loss = 0.04958397\n","Iteration 7338, loss = 0.04958018\n","Iteration 7339, loss = 0.04957635\n","Iteration 7340, loss = 0.04957259\n","Iteration 7341, loss = 0.04956887\n","Iteration 7342, loss = 0.04956508\n","Iteration 7343, loss = 0.04956129\n","Iteration 7344, loss = 0.04955755\n","Iteration 7345, loss = 0.04955376\n","Iteration 7346, loss = 0.04955008\n","Iteration 7347, loss = 0.04954630\n","Iteration 7348, loss = 0.04954250\n","Iteration 7349, loss = 0.04953882\n","Iteration 7350, loss = 0.04953511\n","Iteration 7351, loss = 0.04953135\n","Iteration 7352, loss = 0.04952755\n","Iteration 7353, loss = 0.04952377\n","Iteration 7354, loss = 0.04952006\n","Iteration 7355, loss = 0.04951630\n","Iteration 7356, loss = 0.04951254\n","Iteration 7357, loss = 0.04950883\n","Iteration 7358, loss = 0.04950506\n","Iteration 7359, loss = 0.04950132\n","Iteration 7360, loss = 0.04949759\n","Iteration 7361, loss = 0.04949382\n","Iteration 7362, loss = 0.04949008\n","Iteration 7363, loss = 0.04948638\n","Iteration 7364, loss = 0.04948266\n","Iteration 7365, loss = 0.04947890\n","Iteration 7366, loss = 0.04947518\n","Iteration 7367, loss = 0.04947142\n","Iteration 7368, loss = 0.04946778\n","Iteration 7369, loss = 0.04946407\n","Iteration 7370, loss = 0.04946030\n","Iteration 7371, loss = 0.04945654\n","Iteration 7372, loss = 0.04945284\n","Iteration 7373, loss = 0.04944913\n","Iteration 7374, loss = 0.04944535\n","Iteration 7375, loss = 0.04944164\n","Iteration 7376, loss = 0.04943795\n","Iteration 7377, loss = 0.04943423\n","Iteration 7378, loss = 0.04943048\n","Iteration 7379, loss = 0.04942677\n","Iteration 7380, loss = 0.04942307\n","Iteration 7381, loss = 0.04941933\n","Iteration 7382, loss = 0.04941569\n","Iteration 7383, loss = 0.04941191\n","Iteration 7384, loss = 0.04940821\n","Iteration 7385, loss = 0.04940453\n","Iteration 7386, loss = 0.04940081\n","Iteration 7387, loss = 0.04939713\n","Iteration 7388, loss = 0.04939343\n","Iteration 7389, loss = 0.04938969\n","Iteration 7390, loss = 0.04938601\n","Iteration 7391, loss = 0.04938230\n","Iteration 7392, loss = 0.04937859\n","Iteration 7393, loss = 0.04937496\n","Iteration 7394, loss = 0.04937128\n","Iteration 7395, loss = 0.04936755\n","Iteration 7396, loss = 0.04936385\n","Iteration 7397, loss = 0.04936017\n","Iteration 7398, loss = 0.04935643\n","Iteration 7399, loss = 0.04935281\n","Iteration 7400, loss = 0.04934919\n","Iteration 7401, loss = 0.04934545\n","Iteration 7402, loss = 0.04934171\n","Iteration 7403, loss = 0.04933805\n","Iteration 7404, loss = 0.04933441\n","Iteration 7405, loss = 0.04933070\n","Iteration 7406, loss = 0.04932694\n","Iteration 7407, loss = 0.04932327\n","Iteration 7408, loss = 0.04931961\n","Iteration 7409, loss = 0.04931592\n","Iteration 7410, loss = 0.04931223\n","Iteration 7411, loss = 0.04930859\n","Iteration 7412, loss = 0.04930490\n","Iteration 7413, loss = 0.04930127\n","Iteration 7414, loss = 0.04929760\n","Iteration 7415, loss = 0.04929388\n","Iteration 7416, loss = 0.04929020\n","Iteration 7417, loss = 0.04928657\n","Iteration 7418, loss = 0.04928289\n","Iteration 7419, loss = 0.04927925\n","Iteration 7420, loss = 0.04927560\n","Iteration 7421, loss = 0.04927190\n","Iteration 7422, loss = 0.04926829\n","Iteration 7423, loss = 0.04926465\n","Iteration 7424, loss = 0.04926094\n","Iteration 7425, loss = 0.04925729\n","Iteration 7426, loss = 0.04925366\n","Iteration 7427, loss = 0.04925004\n","Iteration 7428, loss = 0.04924627\n","Iteration 7429, loss = 0.04924275\n","Iteration 7430, loss = 0.04923916\n","Iteration 7431, loss = 0.04923550\n","Iteration 7432, loss = 0.04923177\n","Iteration 7433, loss = 0.04922815\n","Iteration 7434, loss = 0.04922457\n","Iteration 7435, loss = 0.04922093\n","Iteration 7436, loss = 0.04921725\n","Iteration 7437, loss = 0.04921352\n","Iteration 7438, loss = 0.04920999\n","Iteration 7439, loss = 0.04920641\n","Iteration 7440, loss = 0.04920276\n","Iteration 7441, loss = 0.04919905\n","Iteration 7442, loss = 0.04919528\n","Iteration 7443, loss = 0.04919178\n","Iteration 7444, loss = 0.04918823\n","Iteration 7445, loss = 0.04918462\n","Iteration 7446, loss = 0.04918095\n","Iteration 7447, loss = 0.04917731\n","Iteration 7448, loss = 0.04917355\n","Iteration 7449, loss = 0.04916990\n","Iteration 7450, loss = 0.04916637\n","Iteration 7451, loss = 0.04916277\n","Iteration 7452, loss = 0.04915910\n","Iteration 7453, loss = 0.04915537\n","Iteration 7454, loss = 0.04915186\n","Iteration 7455, loss = 0.04914831\n","Iteration 7456, loss = 0.04914471\n","Iteration 7457, loss = 0.04914106\n","Iteration 7458, loss = 0.04913737\n","Iteration 7459, loss = 0.04913363\n","Iteration 7460, loss = 0.04913016\n","Iteration 7461, loss = 0.04912664\n","Iteration 7462, loss = 0.04912303\n","Iteration 7463, loss = 0.04911935\n","Iteration 7464, loss = 0.04911567\n","Iteration 7465, loss = 0.04911196\n","Iteration 7466, loss = 0.04910844\n","Iteration 7467, loss = 0.04910488\n","Iteration 7468, loss = 0.04910125\n","Iteration 7469, loss = 0.04909758\n","Iteration 7470, loss = 0.04909400\n","Iteration 7471, loss = 0.04909045\n","Iteration 7472, loss = 0.04908684\n","Iteration 7473, loss = 0.04908316\n","Iteration 7474, loss = 0.04907962\n","Iteration 7475, loss = 0.04907607\n","Iteration 7476, loss = 0.04907247\n","Iteration 7477, loss = 0.04906882\n","Iteration 7478, loss = 0.04906512\n","Iteration 7479, loss = 0.04906166\n","Iteration 7480, loss = 0.04905813\n","Iteration 7481, loss = 0.04905453\n","Iteration 7482, loss = 0.04905090\n","Iteration 7483, loss = 0.04904716\n","Iteration 7484, loss = 0.04904366\n","Iteration 7485, loss = 0.04904016\n","Iteration 7486, loss = 0.04903660\n","Iteration 7487, loss = 0.04903301\n","Iteration 7488, loss = 0.04902934\n","Iteration 7489, loss = 0.04902566\n","Iteration 7490, loss = 0.04902220\n","Iteration 7491, loss = 0.04901871\n","Iteration 7492, loss = 0.04901515\n","Iteration 7493, loss = 0.04901151\n","Iteration 7494, loss = 0.04900782\n","Iteration 7495, loss = 0.04900425\n","Iteration 7496, loss = 0.04900075\n","Iteration 7497, loss = 0.04899720\n","Iteration 7498, loss = 0.04899359\n","Iteration 7499, loss = 0.04898995\n","Iteration 7500, loss = 0.04898633\n","Iteration 7501, loss = 0.04898282\n","Iteration 7502, loss = 0.04897924\n","Iteration 7503, loss = 0.04897561\n","Iteration 7504, loss = 0.04897205\n","Iteration 7505, loss = 0.04896849\n","Iteration 7506, loss = 0.04896490\n","Iteration 7507, loss = 0.04896146\n","Iteration 7508, loss = 0.04895786\n","Iteration 7509, loss = 0.04895428\n","Iteration 7510, loss = 0.04895070\n","Iteration 7511, loss = 0.04894716\n","Iteration 7512, loss = 0.04894356\n","Iteration 7513, loss = 0.04894009\n","Iteration 7514, loss = 0.04893657\n","Iteration 7515, loss = 0.04893302\n","Iteration 7516, loss = 0.04892938\n","Iteration 7517, loss = 0.04892588\n","Iteration 7518, loss = 0.04892238\n","Iteration 7519, loss = 0.04891882\n","Iteration 7520, loss = 0.04891519\n","Iteration 7521, loss = 0.04891171\n","Iteration 7522, loss = 0.04890822\n","Iteration 7523, loss = 0.04890468\n","Iteration 7524, loss = 0.04890108\n","Iteration 7525, loss = 0.04889749\n","Iteration 7526, loss = 0.04889402\n","Iteration 7527, loss = 0.04889055\n","Iteration 7528, loss = 0.04888702\n","Iteration 7529, loss = 0.04888342\n","Iteration 7530, loss = 0.04887977\n","Iteration 7531, loss = 0.04887635\n","Iteration 7532, loss = 0.04887290\n","Iteration 7533, loss = 0.04886941\n","Iteration 7534, loss = 0.04886585\n","Iteration 7535, loss = 0.04886225\n","Iteration 7536, loss = 0.04885861\n","Iteration 7537, loss = 0.04885517\n","Iteration 7538, loss = 0.04885174\n","Iteration 7539, loss = 0.04884822\n","Iteration 7540, loss = 0.04884464\n","Iteration 7541, loss = 0.04884100\n","Iteration 7542, loss = 0.04883750\n","Iteration 7543, loss = 0.04883409\n","Iteration 7544, loss = 0.04883056\n","Iteration 7545, loss = 0.04882702\n","Iteration 7546, loss = 0.04882343\n","Iteration 7547, loss = 0.04881986\n","Iteration 7548, loss = 0.04881640\n","Iteration 7549, loss = 0.04881287\n","Iteration 7550, loss = 0.04880928\n","Iteration 7551, loss = 0.04880589\n","Iteration 7552, loss = 0.04880242\n","Iteration 7553, loss = 0.04879892\n","Iteration 7554, loss = 0.04879536\n","Iteration 7555, loss = 0.04879176\n","Iteration 7556, loss = 0.04878837\n","Iteration 7557, loss = 0.04878494\n","Iteration 7558, loss = 0.04878144\n","Iteration 7559, loss = 0.04877786\n","Iteration 7560, loss = 0.04877423\n","Iteration 7561, loss = 0.04877088\n","Iteration 7562, loss = 0.04876743\n","Iteration 7563, loss = 0.04876397\n","Iteration 7564, loss = 0.04876045\n","Iteration 7565, loss = 0.04875688\n","Iteration 7566, loss = 0.04875327\n","Iteration 7567, loss = 0.04874984\n","Iteration 7568, loss = 0.04874644\n","Iteration 7569, loss = 0.04874298\n","Iteration 7570, loss = 0.04873942\n","Iteration 7571, loss = 0.04873582\n","Iteration 7572, loss = 0.04873238\n","Iteration 7573, loss = 0.04872898\n","Iteration 7574, loss = 0.04872551\n","Iteration 7575, loss = 0.04872199\n","Iteration 7576, loss = 0.04871843\n","Iteration 7577, loss = 0.04871488\n","Iteration 7578, loss = 0.04871145\n","Iteration 7579, loss = 0.04870799\n","Iteration 7580, loss = 0.04870440\n","Iteration 7581, loss = 0.04870103\n","Iteration 7582, loss = 0.04869761\n","Iteration 7583, loss = 0.04869413\n","Iteration 7584, loss = 0.04869060\n","Iteration 7585, loss = 0.04868702\n","Iteration 7586, loss = 0.04868369\n","Iteration 7587, loss = 0.04868031\n","Iteration 7588, loss = 0.04867683\n","Iteration 7589, loss = 0.04867330\n","Iteration 7590, loss = 0.04866971\n","Iteration 7591, loss = 0.04866632\n","Iteration 7592, loss = 0.04866294\n","Iteration 7593, loss = 0.04865950\n","Iteration 7594, loss = 0.04865601\n","Iteration 7595, loss = 0.04865247\n","Iteration 7596, loss = 0.04864888\n","Iteration 7597, loss = 0.04864559\n","Iteration 7598, loss = 0.04864220\n","Iteration 7599, loss = 0.04863876\n","Iteration 7600, loss = 0.04863525\n","Iteration 7601, loss = 0.04863167\n","Iteration 7602, loss = 0.04862817\n","Iteration 7603, loss = 0.04862480\n","Iteration 7604, loss = 0.04862136\n","Iteration 7605, loss = 0.04861789\n","Iteration 7606, loss = 0.04861435\n","Iteration 7607, loss = 0.04861093\n","Iteration 7608, loss = 0.04860754\n","Iteration 7609, loss = 0.04860408\n","Iteration 7610, loss = 0.04860056\n","Iteration 7611, loss = 0.04859713\n","Iteration 7612, loss = 0.04859374\n","Iteration 7613, loss = 0.04859028\n","Iteration 7614, loss = 0.04858677\n","Iteration 7615, loss = 0.04858335\n","Iteration 7616, loss = 0.04857992\n","Iteration 7617, loss = 0.04857645\n","Iteration 7618, loss = 0.04857299\n","Iteration 7619, loss = 0.04856957\n","Iteration 7620, loss = 0.04856610\n","Iteration 7621, loss = 0.04856272\n","Iteration 7622, loss = 0.04855930\n","Iteration 7623, loss = 0.04855582\n","Iteration 7624, loss = 0.04855239\n","Iteration 7625, loss = 0.04854900\n","Iteration 7626, loss = 0.04854555\n","Iteration 7627, loss = 0.04854208\n","Iteration 7628, loss = 0.04853866\n","Iteration 7629, loss = 0.04853523\n","Iteration 7630, loss = 0.04853180\n","Iteration 7631, loss = 0.04852839\n","Iteration 7632, loss = 0.04852495\n","Iteration 7633, loss = 0.04852154\n","Iteration 7634, loss = 0.04851810\n","Iteration 7635, loss = 0.04851468\n","Iteration 7636, loss = 0.04851125\n","Iteration 7637, loss = 0.04850788\n","Iteration 7638, loss = 0.04850447\n","Iteration 7639, loss = 0.04850100\n","Iteration 7640, loss = 0.04849764\n","Iteration 7641, loss = 0.04849424\n","Iteration 7642, loss = 0.04849080\n","Iteration 7643, loss = 0.04848735\n","Iteration 7644, loss = 0.04848397\n","Iteration 7645, loss = 0.04848053\n","Iteration 7646, loss = 0.04847717\n","Iteration 7647, loss = 0.04847377\n","Iteration 7648, loss = 0.04847031\n","Iteration 7649, loss = 0.04846694\n","Iteration 7650, loss = 0.04846356\n","Iteration 7651, loss = 0.04846015\n","Iteration 7652, loss = 0.04845666\n","Iteration 7653, loss = 0.04845337\n","Iteration 7654, loss = 0.04845002\n","Iteration 7655, loss = 0.04844660\n","Iteration 7656, loss = 0.04844312\n","Iteration 7657, loss = 0.04843972\n","Iteration 7658, loss = 0.04843638\n","Iteration 7659, loss = 0.04843298\n","Iteration 7660, loss = 0.04842960\n","Iteration 7661, loss = 0.04842608\n","Iteration 7662, loss = 0.04842272\n","Iteration 7663, loss = 0.04841930\n","Iteration 7664, loss = 0.04841597\n","Iteration 7665, loss = 0.04841260\n","Iteration 7666, loss = 0.04840917\n","Iteration 7667, loss = 0.04840575\n","Iteration 7668, loss = 0.04840239\n","Iteration 7669, loss = 0.04839896\n","Iteration 7670, loss = 0.04839567\n","Iteration 7671, loss = 0.04839233\n","Iteration 7672, loss = 0.04838892\n","Iteration 7673, loss = 0.04838546\n","Iteration 7674, loss = 0.04838216\n","Iteration 7675, loss = 0.04837884\n","Iteration 7676, loss = 0.04837543\n","Iteration 7677, loss = 0.04837197\n","Iteration 7678, loss = 0.04836861\n","Iteration 7679, loss = 0.04836528\n","Iteration 7680, loss = 0.04836191\n","Iteration 7681, loss = 0.04835849\n","Iteration 7682, loss = 0.04835508\n","Iteration 7683, loss = 0.04835174\n","Iteration 7684, loss = 0.04834834\n","Iteration 7685, loss = 0.04834497\n","Iteration 7686, loss = 0.04834162\n","Iteration 7687, loss = 0.04833826\n","Iteration 7688, loss = 0.04833488\n","Iteration 7689, loss = 0.04833154\n","Iteration 7690, loss = 0.04832814\n","Iteration 7691, loss = 0.04832480\n","Iteration 7692, loss = 0.04832147\n","Iteration 7693, loss = 0.04831808\n","Iteration 7694, loss = 0.04831466\n","Iteration 7695, loss = 0.04831131\n","Iteration 7696, loss = 0.04830801\n","Iteration 7697, loss = 0.04830458\n","Iteration 7698, loss = 0.04830128\n","Iteration 7699, loss = 0.04829793\n","Iteration 7700, loss = 0.04829452\n","Iteration 7701, loss = 0.04829127\n","Iteration 7702, loss = 0.04828796\n","Iteration 7703, loss = 0.04828459\n","Iteration 7704, loss = 0.04828117\n","Iteration 7705, loss = 0.04827781\n","Iteration 7706, loss = 0.04827452\n","Iteration 7707, loss = 0.04827115\n","Iteration 7708, loss = 0.04826774\n","Iteration 7709, loss = 0.04826441\n","Iteration 7710, loss = 0.04826107\n","Iteration 7711, loss = 0.04825770\n","Iteration 7712, loss = 0.04825439\n","Iteration 7713, loss = 0.04825101\n","Iteration 7714, loss = 0.04824774\n","Iteration 7715, loss = 0.04824442\n","Iteration 7716, loss = 0.04824105\n","Iteration 7717, loss = 0.04823771\n","Iteration 7718, loss = 0.04823440\n","Iteration 7719, loss = 0.04823102\n","Iteration 7720, loss = 0.04822774\n","Iteration 7721, loss = 0.04822443\n","Iteration 7722, loss = 0.04822107\n","Iteration 7723, loss = 0.04821771\n","Iteration 7724, loss = 0.04821437\n","Iteration 7725, loss = 0.04821104\n","Iteration 7726, loss = 0.04820771\n","Iteration 7727, loss = 0.04820444\n","Iteration 7728, loss = 0.04820112\n","Iteration 7729, loss = 0.04819774\n","Iteration 7730, loss = 0.04819450\n","Iteration 7731, loss = 0.04819121\n","Iteration 7732, loss = 0.04818793\n","Iteration 7733, loss = 0.04818449\n","Iteration 7734, loss = 0.04818120\n","Iteration 7735, loss = 0.04817794\n","Iteration 7736, loss = 0.04817460\n","Iteration 7737, loss = 0.04817119\n","Iteration 7738, loss = 0.04816800\n","Iteration 7739, loss = 0.04816474\n","Iteration 7740, loss = 0.04816143\n","Iteration 7741, loss = 0.04815814\n","Iteration 7742, loss = 0.04815470\n","Iteration 7743, loss = 0.04815137\n","Iteration 7744, loss = 0.04814814\n","Iteration 7745, loss = 0.04814482\n","Iteration 7746, loss = 0.04814144\n","Iteration 7747, loss = 0.04813818\n","Iteration 7748, loss = 0.04813493\n","Iteration 7749, loss = 0.04813162\n","Iteration 7750, loss = 0.04812832\n","Iteration 7751, loss = 0.04812488\n","Iteration 7752, loss = 0.04812162\n","Iteration 7753, loss = 0.04811830\n","Iteration 7754, loss = 0.04811508\n","Iteration 7755, loss = 0.04811180\n","Iteration 7756, loss = 0.04810847\n","Iteration 7757, loss = 0.04810511\n","Iteration 7758, loss = 0.04810182\n","Iteration 7759, loss = 0.04809858\n","Iteration 7760, loss = 0.04809522\n","Iteration 7761, loss = 0.04809200\n","Iteration 7762, loss = 0.04808871\n","Iteration 7763, loss = 0.04808536\n","Iteration 7764, loss = 0.04808218\n","Iteration 7765, loss = 0.04807893\n","Iteration 7766, loss = 0.04807564\n","Iteration 7767, loss = 0.04807231\n","Iteration 7768, loss = 0.04806899\n","Iteration 7769, loss = 0.04806576\n","Iteration 7770, loss = 0.04806255\n","Iteration 7771, loss = 0.04805927\n","Iteration 7772, loss = 0.04805591\n","Iteration 7773, loss = 0.04805254\n","Iteration 7774, loss = 0.04804932\n","Iteration 7775, loss = 0.04804604\n","Iteration 7776, loss = 0.04804272\n","Iteration 7777, loss = 0.04803948\n","Iteration 7778, loss = 0.04803619\n","Iteration 7779, loss = 0.04803287\n","Iteration 7780, loss = 0.04802968\n","Iteration 7781, loss = 0.04802644\n","Iteration 7782, loss = 0.04802317\n","Iteration 7783, loss = 0.04801984\n","Iteration 7784, loss = 0.04801653\n","Iteration 7785, loss = 0.04801328\n","Iteration 7786, loss = 0.04801001\n","Iteration 7787, loss = 0.04800678\n","Iteration 7788, loss = 0.04800356\n","Iteration 7789, loss = 0.04800029\n","Iteration 7790, loss = 0.04799698\n","Iteration 7791, loss = 0.04799369\n","Iteration 7792, loss = 0.04799045\n","Iteration 7793, loss = 0.04798713\n","Iteration 7794, loss = 0.04798394\n","Iteration 7795, loss = 0.04798076\n","Iteration 7796, loss = 0.04797746\n","Iteration 7797, loss = 0.04797416\n","Iteration 7798, loss = 0.04797086\n","Iteration 7799, loss = 0.04796763\n","Iteration 7800, loss = 0.04796433\n","Iteration 7801, loss = 0.04796107\n","Iteration 7802, loss = 0.04795788\n","Iteration 7803, loss = 0.04795459\n","Iteration 7804, loss = 0.04795139\n","Iteration 7805, loss = 0.04794813\n","Iteration 7806, loss = 0.04794487\n","Iteration 7807, loss = 0.04794158\n","Iteration 7808, loss = 0.04793833\n","Iteration 7809, loss = 0.04793513\n","Iteration 7810, loss = 0.04793190\n","Iteration 7811, loss = 0.04792861\n","Iteration 7812, loss = 0.04792539\n","Iteration 7813, loss = 0.04792220\n","Iteration 7814, loss = 0.04791886\n","Iteration 7815, loss = 0.04791563\n","Iteration 7816, loss = 0.04791242\n","Iteration 7817, loss = 0.04790915\n","Iteration 7818, loss = 0.04790593\n","Iteration 7819, loss = 0.04790270\n","Iteration 7820, loss = 0.04789945\n","Iteration 7821, loss = 0.04789622\n","Iteration 7822, loss = 0.04789300\n","Iteration 7823, loss = 0.04788979\n","Iteration 7824, loss = 0.04788659\n","Iteration 7825, loss = 0.04788334\n","Iteration 7826, loss = 0.04788005\n","Iteration 7827, loss = 0.04787695\n","Iteration 7828, loss = 0.04787376\n","Iteration 7829, loss = 0.04787048\n","Iteration 7830, loss = 0.04786712\n","Iteration 7831, loss = 0.04786407\n","Iteration 7832, loss = 0.04786089\n","Iteration 7833, loss = 0.04785771\n","Iteration 7834, loss = 0.04785447\n","Iteration 7835, loss = 0.04785119\n","Iteration 7836, loss = 0.04784787\n","Iteration 7837, loss = 0.04784464\n","Iteration 7838, loss = 0.04784150\n","Iteration 7839, loss = 0.04783826\n","Iteration 7840, loss = 0.04783499\n","Iteration 7841, loss = 0.04783179\n","Iteration 7842, loss = 0.04782865\n","Iteration 7843, loss = 0.04782546\n","Iteration 7844, loss = 0.04782221\n","Iteration 7845, loss = 0.04781893\n","Iteration 7846, loss = 0.04781567\n","Iteration 7847, loss = 0.04781250\n","Iteration 7848, loss = 0.04780924\n","Iteration 7849, loss = 0.04780609\n","Iteration 7850, loss = 0.04780288\n","Iteration 7851, loss = 0.04779967\n","Iteration 7852, loss = 0.04779641\n","Iteration 7853, loss = 0.04779328\n","Iteration 7854, loss = 0.04779011\n","Iteration 7855, loss = 0.04778684\n","Iteration 7856, loss = 0.04778361\n","Iteration 7857, loss = 0.04778044\n","Iteration 7858, loss = 0.04777728\n","Iteration 7859, loss = 0.04777399\n","Iteration 7860, loss = 0.04777084\n","Iteration 7861, loss = 0.04776767\n","Iteration 7862, loss = 0.04776441\n","Iteration 7863, loss = 0.04776125\n","Iteration 7864, loss = 0.04775810\n","Iteration 7865, loss = 0.04775490\n","Iteration 7866, loss = 0.04775165\n","Iteration 7867, loss = 0.04774845\n","Iteration 7868, loss = 0.04774523\n","Iteration 7869, loss = 0.04774203\n","Iteration 7870, loss = 0.04773884\n","Iteration 7871, loss = 0.04773568\n","Iteration 7872, loss = 0.04773246\n","Iteration 7873, loss = 0.04772933\n","Iteration 7874, loss = 0.04772616\n","Iteration 7875, loss = 0.04772295\n","Iteration 7876, loss = 0.04771976\n","Iteration 7877, loss = 0.04771663\n","Iteration 7878, loss = 0.04771350\n","Iteration 7879, loss = 0.04771028\n","Iteration 7880, loss = 0.04770698\n","Iteration 7881, loss = 0.04770384\n","Iteration 7882, loss = 0.04770065\n","Iteration 7883, loss = 0.04769744\n","Iteration 7884, loss = 0.04769425\n","Iteration 7885, loss = 0.04769116\n","Iteration 7886, loss = 0.04768791\n","Iteration 7887, loss = 0.04768473\n","Iteration 7888, loss = 0.04768163\n","Iteration 7889, loss = 0.04767843\n","Iteration 7890, loss = 0.04767525\n","Iteration 7891, loss = 0.04767210\n","Iteration 7892, loss = 0.04766890\n","Iteration 7893, loss = 0.04766573\n","Iteration 7894, loss = 0.04766263\n","Iteration 7895, loss = 0.04765938\n","Iteration 7896, loss = 0.04765624\n","Iteration 7897, loss = 0.04765304\n","Iteration 7898, loss = 0.04764996\n","Iteration 7899, loss = 0.04764680\n","Iteration 7900, loss = 0.04764355\n","Iteration 7901, loss = 0.04764047\n","Iteration 7902, loss = 0.04763736\n","Iteration 7903, loss = 0.04763422\n","Iteration 7904, loss = 0.04763103\n","Iteration 7905, loss = 0.04762779\n","Iteration 7906, loss = 0.04762470\n","Iteration 7907, loss = 0.04762161\n","Iteration 7908, loss = 0.04761842\n","Iteration 7909, loss = 0.04761515\n","Iteration 7910, loss = 0.04761207\n","Iteration 7911, loss = 0.04760899\n","Iteration 7912, loss = 0.04760587\n","Iteration 7913, loss = 0.04760268\n","Iteration 7914, loss = 0.04759947\n","Iteration 7915, loss = 0.04759621\n","Iteration 7916, loss = 0.04759324\n","Iteration 7917, loss = 0.04759018\n","Iteration 7918, loss = 0.04758702\n","Iteration 7919, loss = 0.04758377\n","Iteration 7920, loss = 0.04758045\n","Iteration 7921, loss = 0.04757754\n","Iteration 7922, loss = 0.04757445\n","Iteration 7923, loss = 0.04757137\n","Iteration 7924, loss = 0.04756823\n","Iteration 7925, loss = 0.04756504\n","Iteration 7926, loss = 0.04756181\n","Iteration 7927, loss = 0.04755854\n","Iteration 7928, loss = 0.04755544\n","Iteration 7929, loss = 0.04755242\n","Iteration 7930, loss = 0.04754929\n","Iteration 7931, loss = 0.04754610\n","Iteration 7932, loss = 0.04754282\n","Iteration 7933, loss = 0.04753982\n","Iteration 7934, loss = 0.04753679\n","Iteration 7935, loss = 0.04753370\n","Iteration 7936, loss = 0.04753055\n","Iteration 7937, loss = 0.04752736\n","Iteration 7938, loss = 0.04752412\n","Iteration 7939, loss = 0.04752089\n","Iteration 7940, loss = 0.04751795\n","Iteration 7941, loss = 0.04751494\n","Iteration 7942, loss = 0.04751184\n","Iteration 7943, loss = 0.04750864\n","Iteration 7944, loss = 0.04750537\n","Iteration 7945, loss = 0.04750217\n","Iteration 7946, loss = 0.04749914\n","Iteration 7947, loss = 0.04749607\n","Iteration 7948, loss = 0.04749293\n","Iteration 7949, loss = 0.04748977\n","Iteration 7950, loss = 0.04748655\n","Iteration 7951, loss = 0.04748353\n","Iteration 7952, loss = 0.04748048\n","Iteration 7953, loss = 0.04747735\n","Iteration 7954, loss = 0.04747412\n","Iteration 7955, loss = 0.04747099\n","Iteration 7956, loss = 0.04746793\n","Iteration 7957, loss = 0.04746489\n","Iteration 7958, loss = 0.04746169\n","Iteration 7959, loss = 0.04745851\n","Iteration 7960, loss = 0.04745545\n","Iteration 7961, loss = 0.04745240\n","Iteration 7962, loss = 0.04744925\n","Iteration 7963, loss = 0.04744603\n","Iteration 7964, loss = 0.04744295\n","Iteration 7965, loss = 0.04743987\n","Iteration 7966, loss = 0.04743674\n","Iteration 7967, loss = 0.04743362\n","Iteration 7968, loss = 0.04743057\n","Iteration 7969, loss = 0.04742749\n","Iteration 7970, loss = 0.04742436\n","Iteration 7971, loss = 0.04742122\n","Iteration 7972, loss = 0.04741812\n","Iteration 7973, loss = 0.04741503\n","Iteration 7974, loss = 0.04741193\n","Iteration 7975, loss = 0.04740888\n","Iteration 7976, loss = 0.04740576\n","Iteration 7977, loss = 0.04740268\n","Iteration 7978, loss = 0.04739951\n","Iteration 7979, loss = 0.04739651\n","Iteration 7980, loss = 0.04739347\n","Iteration 7981, loss = 0.04739038\n","Iteration 7982, loss = 0.04738723\n","Iteration 7983, loss = 0.04738406\n","Iteration 7984, loss = 0.04738109\n","Iteration 7985, loss = 0.04737807\n","Iteration 7986, loss = 0.04737496\n","Iteration 7987, loss = 0.04737176\n","Iteration 7988, loss = 0.04736870\n","Iteration 7989, loss = 0.04736568\n","Iteration 7990, loss = 0.04736261\n","Iteration 7991, loss = 0.04735948\n","Iteration 7992, loss = 0.04735630\n","Iteration 7993, loss = 0.04735327\n","Iteration 7994, loss = 0.04735019\n","Iteration 7995, loss = 0.04734708\n","Iteration 7996, loss = 0.04734394\n","Iteration 7997, loss = 0.04734089\n","Iteration 7998, loss = 0.04733779\n","Iteration 7999, loss = 0.04733470\n","Iteration 8000, loss = 0.04733162\n","Iteration 8001, loss = 0.04732858\n","Iteration 8002, loss = 0.04732554\n","Iteration 8003, loss = 0.04732244\n","Iteration 8004, loss = 0.04731935\n","Iteration 8005, loss = 0.04731628\n","Iteration 8006, loss = 0.04731321\n","Iteration 8007, loss = 0.04731015\n","Iteration 8008, loss = 0.04730703\n","Iteration 8009, loss = 0.04730403\n","Iteration 8010, loss = 0.04730096\n","Iteration 8011, loss = 0.04729790\n","Iteration 8012, loss = 0.04729483\n","Iteration 8013, loss = 0.04729185\n","Iteration 8014, loss = 0.04728881\n","Iteration 8015, loss = 0.04728571\n","Iteration 8016, loss = 0.04728257\n","Iteration 8017, loss = 0.04727965\n","Iteration 8018, loss = 0.04727666\n","Iteration 8019, loss = 0.04727358\n","Iteration 8020, loss = 0.04727042\n","Iteration 8021, loss = 0.04726733\n","Iteration 8022, loss = 0.04726434\n","Iteration 8023, loss = 0.04726130\n","Iteration 8024, loss = 0.04725820\n","Iteration 8025, loss = 0.04725505\n","Iteration 8026, loss = 0.04725202\n","Iteration 8027, loss = 0.04724900\n","Iteration 8028, loss = 0.04724590\n","Iteration 8029, loss = 0.04724273\n","Iteration 8030, loss = 0.04723969\n","Iteration 8031, loss = 0.04723677\n","Iteration 8032, loss = 0.04723370\n","Iteration 8033, loss = 0.04723054\n","Iteration 8034, loss = 0.04722753\n","Iteration 8035, loss = 0.04722451\n","Iteration 8036, loss = 0.04722145\n","Iteration 8037, loss = 0.04721842\n","Iteration 8038, loss = 0.04721538\n","Iteration 8039, loss = 0.04721231\n","Iteration 8040, loss = 0.04720928\n","Iteration 8041, loss = 0.04720619\n","Iteration 8042, loss = 0.04720324\n","Iteration 8043, loss = 0.04720020\n","Iteration 8044, loss = 0.04719707\n","Iteration 8045, loss = 0.04719407\n","Iteration 8046, loss = 0.04719107\n","Iteration 8047, loss = 0.04718803\n","Iteration 8048, loss = 0.04718494\n","Iteration 8049, loss = 0.04718182\n","Iteration 8050, loss = 0.04717893\n","Iteration 8051, loss = 0.04717597\n","Iteration 8052, loss = 0.04717291\n","Iteration 8053, loss = 0.04716977\n","Iteration 8054, loss = 0.04716669\n","Iteration 8055, loss = 0.04716374\n","Iteration 8056, loss = 0.04716073\n","Iteration 8057, loss = 0.04715767\n","Iteration 8058, loss = 0.04715456\n","Iteration 8059, loss = 0.04715163\n","Iteration 8060, loss = 0.04714865\n","Iteration 8061, loss = 0.04714558\n","Iteration 8062, loss = 0.04714243\n","Iteration 8063, loss = 0.04713947\n","Iteration 8064, loss = 0.04713658\n","Iteration 8065, loss = 0.04713352\n","Iteration 8066, loss = 0.04713046\n","Iteration 8067, loss = 0.04712736\n","Iteration 8068, loss = 0.04712428\n","Iteration 8069, loss = 0.04712131\n","Iteration 8070, loss = 0.04711825\n","Iteration 8071, loss = 0.04711523\n","Iteration 8072, loss = 0.04711224\n","Iteration 8073, loss = 0.04710921\n","Iteration 8074, loss = 0.04710616\n","Iteration 8075, loss = 0.04710314\n","Iteration 8076, loss = 0.04710018\n","Iteration 8077, loss = 0.04709718\n","Iteration 8078, loss = 0.04709413\n","Iteration 8079, loss = 0.04709110\n","Iteration 8080, loss = 0.04708808\n","Iteration 8081, loss = 0.04708505\n","Iteration 8082, loss = 0.04708205\n","Iteration 8083, loss = 0.04707902\n","Iteration 8084, loss = 0.04707602\n","Iteration 8085, loss = 0.04707301\n","Iteration 8086, loss = 0.04707002\n","Iteration 8087, loss = 0.04706700\n","Iteration 8088, loss = 0.04706400\n","Iteration 8089, loss = 0.04706096\n","Iteration 8090, loss = 0.04705808\n","Iteration 8091, loss = 0.04705502\n","Iteration 8092, loss = 0.04705200\n","Iteration 8093, loss = 0.04704896\n","Iteration 8094, loss = 0.04704596\n","Iteration 8095, loss = 0.04704299\n","Iteration 8096, loss = 0.04703999\n","Iteration 8097, loss = 0.04703695\n","Iteration 8098, loss = 0.04703405\n","Iteration 8099, loss = 0.04703103\n","Iteration 8100, loss = 0.04702797\n","Iteration 8101, loss = 0.04702505\n","Iteration 8102, loss = 0.04702211\n","Iteration 8103, loss = 0.04701912\n","Iteration 8104, loss = 0.04701607\n","Iteration 8105, loss = 0.04701298\n","Iteration 8106, loss = 0.04701000\n","Iteration 8107, loss = 0.04700699\n","Iteration 8108, loss = 0.04700409\n","Iteration 8109, loss = 0.04700104\n","Iteration 8110, loss = 0.04699807\n","Iteration 8111, loss = 0.04699512\n","Iteration 8112, loss = 0.04699218\n","Iteration 8113, loss = 0.04698918\n","Iteration 8114, loss = 0.04698620\n","Iteration 8115, loss = 0.04698323\n","Iteration 8116, loss = 0.04698024\n","Iteration 8117, loss = 0.04697726\n","Iteration 8118, loss = 0.04697424\n","Iteration 8119, loss = 0.04697127\n","Iteration 8120, loss = 0.04696826\n","Iteration 8121, loss = 0.04696536\n","Iteration 8122, loss = 0.04696236\n","Iteration 8123, loss = 0.04695928\n","Iteration 8124, loss = 0.04695641\n","Iteration 8125, loss = 0.04695347\n","Iteration 8126, loss = 0.04695048\n","Iteration 8127, loss = 0.04694744\n","Iteration 8128, loss = 0.04694449\n","Iteration 8129, loss = 0.04694154\n","Iteration 8130, loss = 0.04693857\n","Iteration 8131, loss = 0.04693560\n","Iteration 8132, loss = 0.04693254\n","Iteration 8133, loss = 0.04692960\n","Iteration 8134, loss = 0.04692671\n","Iteration 8135, loss = 0.04692375\n","Iteration 8136, loss = 0.04692074\n","Iteration 8137, loss = 0.04691769\n","Iteration 8138, loss = 0.04691479\n","Iteration 8139, loss = 0.04691188\n","Iteration 8140, loss = 0.04690887\n","Iteration 8141, loss = 0.04690579\n","Iteration 8142, loss = 0.04690287\n","Iteration 8143, loss = 0.04689996\n","Iteration 8144, loss = 0.04689701\n","Iteration 8145, loss = 0.04689401\n","Iteration 8146, loss = 0.04689096\n","Iteration 8147, loss = 0.04688800\n","Iteration 8148, loss = 0.04688510\n","Iteration 8149, loss = 0.04688211\n","Iteration 8150, loss = 0.04687906\n","Iteration 8151, loss = 0.04687623\n","Iteration 8152, loss = 0.04687336\n","Iteration 8153, loss = 0.04687043\n","Iteration 8154, loss = 0.04686746\n","Iteration 8155, loss = 0.04686444\n","Iteration 8156, loss = 0.04686137\n","Iteration 8157, loss = 0.04685852\n","Iteration 8158, loss = 0.04685565\n","Iteration 8159, loss = 0.04685268\n","Iteration 8160, loss = 0.04684963\n","Iteration 8161, loss = 0.04684666\n","Iteration 8162, loss = 0.04684368\n","Iteration 8163, loss = 0.04684076\n","Iteration 8164, loss = 0.04683779\n","Iteration 8165, loss = 0.04683488\n","Iteration 8166, loss = 0.04683197\n","Iteration 8167, loss = 0.04682897\n","Iteration 8168, loss = 0.04682613\n","Iteration 8169, loss = 0.04682323\n","Iteration 8170, loss = 0.04682029\n","Iteration 8171, loss = 0.04681731\n","Iteration 8172, loss = 0.04681429\n","Iteration 8173, loss = 0.04681139\n","Iteration 8174, loss = 0.04680849\n","Iteration 8175, loss = 0.04680550\n","Iteration 8176, loss = 0.04680243\n","Iteration 8177, loss = 0.04679951\n","Iteration 8178, loss = 0.04679653\n","Iteration 8179, loss = 0.04679364\n","Iteration 8180, loss = 0.04679074\n","Iteration 8181, loss = 0.04678769\n","Iteration 8182, loss = 0.04678479\n","Iteration 8183, loss = 0.04678189\n","Iteration 8184, loss = 0.04677895\n","Iteration 8185, loss = 0.04677606\n","Iteration 8186, loss = 0.04677313\n","Iteration 8187, loss = 0.04677019\n","Iteration 8188, loss = 0.04676732\n","Iteration 8189, loss = 0.04676437\n","Iteration 8190, loss = 0.04676141\n","Iteration 8191, loss = 0.04675850\n","Iteration 8192, loss = 0.04675554\n","Iteration 8193, loss = 0.04675261\n","Iteration 8194, loss = 0.04674965\n","Iteration 8195, loss = 0.04674673\n","Iteration 8196, loss = 0.04674381\n","Iteration 8197, loss = 0.04674091\n","Iteration 8198, loss = 0.04673789\n","Iteration 8199, loss = 0.04673498\n","Iteration 8200, loss = 0.04673206\n","Iteration 8201, loss = 0.04672915\n","Iteration 8202, loss = 0.04672627\n","Iteration 8203, loss = 0.04672329\n","Iteration 8204, loss = 0.04672041\n","Iteration 8205, loss = 0.04671749\n","Iteration 8206, loss = 0.04671460\n","Iteration 8207, loss = 0.04671165\n","Iteration 8208, loss = 0.04670880\n","Iteration 8209, loss = 0.04670592\n","Iteration 8210, loss = 0.04670299\n","Iteration 8211, loss = 0.04670003\n","Iteration 8212, loss = 0.04669703\n","Iteration 8213, loss = 0.04669432\n","Iteration 8214, loss = 0.04669141\n","Iteration 8215, loss = 0.04668848\n","Iteration 8216, loss = 0.04668545\n","Iteration 8217, loss = 0.04668257\n","Iteration 8218, loss = 0.04667974\n","Iteration 8219, loss = 0.04667686\n","Iteration 8220, loss = 0.04667396\n","Iteration 8221, loss = 0.04667100\n","Iteration 8222, loss = 0.04666802\n","Iteration 8223, loss = 0.04666512\n","Iteration 8224, loss = 0.04666227\n","Iteration 8225, loss = 0.04665932\n","Iteration 8226, loss = 0.04665639\n","Iteration 8227, loss = 0.04665352\n","Iteration 8228, loss = 0.04665061\n","Iteration 8229, loss = 0.04664767\n","Iteration 8230, loss = 0.04664476\n","Iteration 8231, loss = 0.04664183\n","Iteration 8232, loss = 0.04663897\n","Iteration 8233, loss = 0.04663610\n","Iteration 8234, loss = 0.04663318\n","Iteration 8235, loss = 0.04663023\n","Iteration 8236, loss = 0.04662734\n","Iteration 8237, loss = 0.04662445\n","Iteration 8238, loss = 0.04662159\n","Iteration 8239, loss = 0.04661866\n","Iteration 8240, loss = 0.04661578\n","Iteration 8241, loss = 0.04661288\n","Iteration 8242, loss = 0.04660998\n","Iteration 8243, loss = 0.04660717\n","Iteration 8244, loss = 0.04660424\n","Iteration 8245, loss = 0.04660135\n","Iteration 8246, loss = 0.04659848\n","Iteration 8247, loss = 0.04659563\n","Iteration 8248, loss = 0.04659266\n","Iteration 8249, loss = 0.04658981\n","Iteration 8250, loss = 0.04658694\n","Iteration 8251, loss = 0.04658400\n","Iteration 8252, loss = 0.04658112\n","Iteration 8253, loss = 0.04657821\n","Iteration 8254, loss = 0.04657541\n","Iteration 8255, loss = 0.04657251\n","Iteration 8256, loss = 0.04656958\n","Iteration 8257, loss = 0.04656673\n","Iteration 8258, loss = 0.04656384\n","Iteration 8259, loss = 0.04656097\n","Iteration 8260, loss = 0.04655807\n","Iteration 8261, loss = 0.04655525\n","Iteration 8262, loss = 0.04655240\n","Iteration 8263, loss = 0.04654950\n","Iteration 8264, loss = 0.04654657\n","Iteration 8265, loss = 0.04654378\n","Iteration 8266, loss = 0.04654082\n","Iteration 8267, loss = 0.04653792\n","Iteration 8268, loss = 0.04653506\n","Iteration 8269, loss = 0.04653216\n","Iteration 8270, loss = 0.04652937\n","Iteration 8271, loss = 0.04652648\n","Iteration 8272, loss = 0.04652359\n","Iteration 8273, loss = 0.04652071\n","Iteration 8274, loss = 0.04651784\n","Iteration 8275, loss = 0.04651500\n","Iteration 8276, loss = 0.04651211\n","Iteration 8277, loss = 0.04650929\n","Iteration 8278, loss = 0.04650645\n","Iteration 8279, loss = 0.04650357\n","Iteration 8280, loss = 0.04650065\n","Iteration 8281, loss = 0.04649781\n","Iteration 8282, loss = 0.04649502\n","Iteration 8283, loss = 0.04649201\n","Iteration 8284, loss = 0.04648926\n","Iteration 8285, loss = 0.04648647\n","Iteration 8286, loss = 0.04648363\n","Iteration 8287, loss = 0.04648074\n","Iteration 8288, loss = 0.04647781\n","Iteration 8289, loss = 0.04647485\n","Iteration 8290, loss = 0.04647226\n","Iteration 8291, loss = 0.04646940\n","Iteration 8292, loss = 0.04646652\n","Iteration 8293, loss = 0.04646354\n","Iteration 8294, loss = 0.04646066\n","Iteration 8295, loss = 0.04645789\n","Iteration 8296, loss = 0.04645507\n","Iteration 8297, loss = 0.04645220\n","Iteration 8298, loss = 0.04644929\n","Iteration 8299, loss = 0.04644638\n","Iteration 8300, loss = 0.04644356\n","Iteration 8301, loss = 0.04644078\n","Iteration 8302, loss = 0.04643789\n","Iteration 8303, loss = 0.04643498\n","Iteration 8304, loss = 0.04643217\n","Iteration 8305, loss = 0.04642932\n","Iteration 8306, loss = 0.04642642\n","Iteration 8307, loss = 0.04642359\n","Iteration 8308, loss = 0.04642084\n","Iteration 8309, loss = 0.04641786\n","Iteration 8310, loss = 0.04641504\n","Iteration 8311, loss = 0.04641217\n","Iteration 8312, loss = 0.04640942\n","Iteration 8313, loss = 0.04640656\n","Iteration 8314, loss = 0.04640366\n","Iteration 8315, loss = 0.04640087\n","Iteration 8316, loss = 0.04639800\n","Iteration 8317, loss = 0.04639519\n","Iteration 8318, loss = 0.04639234\n","Iteration 8319, loss = 0.04638955\n","Iteration 8320, loss = 0.04638674\n","Iteration 8321, loss = 0.04638389\n","Iteration 8322, loss = 0.04638100\n","Iteration 8323, loss = 0.04637822\n","Iteration 8324, loss = 0.04637539\n","Iteration 8325, loss = 0.04637255\n","Iteration 8326, loss = 0.04636971\n","Iteration 8327, loss = 0.04636694\n","Iteration 8328, loss = 0.04636413\n","Iteration 8329, loss = 0.04636128\n","Iteration 8330, loss = 0.04635838\n","Iteration 8331, loss = 0.04635551\n","Iteration 8332, loss = 0.04635272\n","Iteration 8333, loss = 0.04634984\n","Iteration 8334, loss = 0.04634712\n","Iteration 8335, loss = 0.04634435\n","Iteration 8336, loss = 0.04634154\n","Iteration 8337, loss = 0.04633868\n","Iteration 8338, loss = 0.04633578\n","Iteration 8339, loss = 0.04633298\n","Iteration 8340, loss = 0.04633019\n","Iteration 8341, loss = 0.04632730\n","Iteration 8342, loss = 0.04632451\n","Iteration 8343, loss = 0.04632170\n","Iteration 8344, loss = 0.04631889\n","Iteration 8345, loss = 0.04631604\n","Iteration 8346, loss = 0.04631315\n","Iteration 8347, loss = 0.04631050\n","Iteration 8348, loss = 0.04630773\n","Iteration 8349, loss = 0.04630485\n","Iteration 8350, loss = 0.04630196\n","Iteration 8351, loss = 0.04629921\n","Iteration 8352, loss = 0.04629650\n","Iteration 8353, loss = 0.04629374\n","Iteration 8354, loss = 0.04629093\n","Iteration 8355, loss = 0.04628806\n","Iteration 8356, loss = 0.04628516\n","Iteration 8357, loss = 0.04628222\n","Iteration 8358, loss = 0.04627957\n","Iteration 8359, loss = 0.04627688\n","Iteration 8360, loss = 0.04627408\n","Iteration 8361, loss = 0.04627118\n","Iteration 8362, loss = 0.04626819\n","Iteration 8363, loss = 0.04626545\n","Iteration 8364, loss = 0.04626267\n","Iteration 8365, loss = 0.04625983\n","Iteration 8366, loss = 0.04625696\n","Iteration 8367, loss = 0.04625423\n","Iteration 8368, loss = 0.04625159\n","Iteration 8369, loss = 0.04624860\n","Iteration 8370, loss = 0.04624582\n","Iteration 8371, loss = 0.04624311\n","Iteration 8372, loss = 0.04624034\n","Iteration 8373, loss = 0.04623753\n","Iteration 8374, loss = 0.04623468\n","Iteration 8375, loss = 0.04623199\n","Iteration 8376, loss = 0.04622925\n","Iteration 8377, loss = 0.04622639\n","Iteration 8378, loss = 0.04622350\n","Iteration 8379, loss = 0.04622075\n","Iteration 8380, loss = 0.04621794\n","Iteration 8381, loss = 0.04621510\n","Iteration 8382, loss = 0.04621231\n","Iteration 8383, loss = 0.04620951\n","Iteration 8384, loss = 0.04620664\n","Iteration 8385, loss = 0.04620384\n","Iteration 8386, loss = 0.04620100\n","Iteration 8387, loss = 0.04619843\n","Iteration 8388, loss = 0.04619559\n","Iteration 8389, loss = 0.04619266\n","Iteration 8390, loss = 0.04618992\n","Iteration 8391, loss = 0.04618713\n","Iteration 8392, loss = 0.04618445\n","Iteration 8393, loss = 0.04618166\n","Iteration 8394, loss = 0.04617882\n","Iteration 8395, loss = 0.04617606\n","Iteration 8396, loss = 0.04617325\n","Iteration 8397, loss = 0.04617049\n","Iteration 8398, loss = 0.04616768\n","Iteration 8399, loss = 0.04616490\n","Iteration 8400, loss = 0.04616213\n","Iteration 8401, loss = 0.04615931\n","Iteration 8402, loss = 0.04615645\n","Iteration 8403, loss = 0.04615388\n","Iteration 8404, loss = 0.04615106\n","Iteration 8405, loss = 0.04614825\n","Iteration 8406, loss = 0.04614544\n","Iteration 8407, loss = 0.04614274\n","Iteration 8408, loss = 0.04613999\n","Iteration 8409, loss = 0.04613720\n","Iteration 8410, loss = 0.04613437\n","Iteration 8411, loss = 0.04613160\n","Iteration 8412, loss = 0.04612887\n","Iteration 8413, loss = 0.04612611\n","Iteration 8414, loss = 0.04612330\n","Iteration 8415, loss = 0.04612051\n","Iteration 8416, loss = 0.04611772\n","Iteration 8417, loss = 0.04611495\n","Iteration 8418, loss = 0.04611218\n","Iteration 8419, loss = 0.04610937\n","Iteration 8420, loss = 0.04610658\n","Iteration 8421, loss = 0.04610379\n","Iteration 8422, loss = 0.04610107\n","Iteration 8423, loss = 0.04609833\n","Iteration 8424, loss = 0.04609553\n","Iteration 8425, loss = 0.04609274\n","Iteration 8426, loss = 0.04609011\n","Iteration 8427, loss = 0.04608740\n","Iteration 8428, loss = 0.04608458\n","Iteration 8429, loss = 0.04608174\n","Iteration 8430, loss = 0.04607903\n","Iteration 8431, loss = 0.04607627\n","Iteration 8432, loss = 0.04607347\n","Iteration 8433, loss = 0.04607070\n","Iteration 8434, loss = 0.04606793\n","Iteration 8435, loss = 0.04606514\n","Iteration 8436, loss = 0.04606253\n","Iteration 8437, loss = 0.04605964\n","Iteration 8438, loss = 0.04605697\n","Iteration 8439, loss = 0.04605425\n","Iteration 8440, loss = 0.04605144\n","Iteration 8441, loss = 0.04604873\n","Iteration 8442, loss = 0.04604597\n","Iteration 8443, loss = 0.04604326\n","Iteration 8444, loss = 0.04604051\n","Iteration 8445, loss = 0.04603774\n","Iteration 8446, loss = 0.04603498\n","Iteration 8447, loss = 0.04603223\n","Iteration 8448, loss = 0.04602948\n","Iteration 8449, loss = 0.04602672\n","Iteration 8450, loss = 0.04602395\n","Iteration 8451, loss = 0.04602116\n","Iteration 8452, loss = 0.04601841\n","Iteration 8453, loss = 0.04601565\n","Iteration 8454, loss = 0.04601294\n","Iteration 8455, loss = 0.04601013\n","Iteration 8456, loss = 0.04600739\n","Iteration 8457, loss = 0.04600463\n","Iteration 8458, loss = 0.04600196\n","Iteration 8459, loss = 0.04599922\n","Iteration 8460, loss = 0.04599645\n","Iteration 8461, loss = 0.04599385\n","Iteration 8462, loss = 0.04599113\n","Iteration 8463, loss = 0.04598831\n","Iteration 8464, loss = 0.04598561\n","Iteration 8465, loss = 0.04598293\n","Iteration 8466, loss = 0.04598020\n","Iteration 8467, loss = 0.04597742\n","Iteration 8468, loss = 0.04597460\n","Iteration 8469, loss = 0.04597186\n","Iteration 8470, loss = 0.04596919\n","Iteration 8471, loss = 0.04596641\n","Iteration 8472, loss = 0.04596368\n","Iteration 8473, loss = 0.04596099\n","Iteration 8474, loss = 0.04595826\n","Iteration 8475, loss = 0.04595547\n","Iteration 8476, loss = 0.04595272\n","Iteration 8477, loss = 0.04595002\n","Iteration 8478, loss = 0.04594727\n","Iteration 8479, loss = 0.04594456\n","Iteration 8480, loss = 0.04594183\n","Iteration 8481, loss = 0.04593911\n","Iteration 8482, loss = 0.04593637\n","Iteration 8483, loss = 0.04593370\n","Iteration 8484, loss = 0.04593094\n","Iteration 8485, loss = 0.04592819\n","Iteration 8486, loss = 0.04592562\n","Iteration 8487, loss = 0.04592276\n","Iteration 8488, loss = 0.04592004\n","Iteration 8489, loss = 0.04591735\n","Iteration 8490, loss = 0.04591470\n","Iteration 8491, loss = 0.04591197\n","Iteration 8492, loss = 0.04590927\n","Iteration 8493, loss = 0.04590660\n","Iteration 8494, loss = 0.04590389\n","Iteration 8495, loss = 0.04590113\n","Iteration 8496, loss = 0.04589850\n","Iteration 8497, loss = 0.04589578\n","Iteration 8498, loss = 0.04589296\n","Iteration 8499, loss = 0.04589033\n","Iteration 8500, loss = 0.04588767\n","Iteration 8501, loss = 0.04588495\n","Iteration 8502, loss = 0.04588218\n","Iteration 8503, loss = 0.04587937\n","Iteration 8504, loss = 0.04587658\n","Iteration 8505, loss = 0.04587411\n","Iteration 8506, loss = 0.04587130\n","Iteration 8507, loss = 0.04586852\n","Iteration 8508, loss = 0.04586588\n","Iteration 8509, loss = 0.04586320\n","Iteration 8510, loss = 0.04586046\n","Iteration 8511, loss = 0.04585771\n","Iteration 8512, loss = 0.04585503\n","Iteration 8513, loss = 0.04585231\n","Iteration 8514, loss = 0.04584961\n","Iteration 8515, loss = 0.04584687\n","Iteration 8516, loss = 0.04584417\n","Iteration 8517, loss = 0.04584144\n","Iteration 8518, loss = 0.04583879\n","Iteration 8519, loss = 0.04583605\n","Iteration 8520, loss = 0.04583334\n","Iteration 8521, loss = 0.04583064\n","Iteration 8522, loss = 0.04582792\n","Iteration 8523, loss = 0.04582523\n","Iteration 8524, loss = 0.04582252\n","Iteration 8525, loss = 0.04581984\n","Iteration 8526, loss = 0.04581723\n","Iteration 8527, loss = 0.04581445\n","Iteration 8528, loss = 0.04581175\n","Iteration 8529, loss = 0.04580906\n","Iteration 8530, loss = 0.04580641\n","Iteration 8531, loss = 0.04580374\n","Iteration 8532, loss = 0.04580101\n","Iteration 8533, loss = 0.04579829\n","Iteration 8534, loss = 0.04579558\n","Iteration 8535, loss = 0.04579291\n","Iteration 8536, loss = 0.04579025\n","Iteration 8537, loss = 0.04578754\n","Iteration 8538, loss = 0.04578487\n","Iteration 8539, loss = 0.04578218\n","Iteration 8540, loss = 0.04577949\n","Iteration 8541, loss = 0.04577681\n","Iteration 8542, loss = 0.04577408\n","Iteration 8543, loss = 0.04577142\n","Iteration 8544, loss = 0.04576887\n","Iteration 8545, loss = 0.04576601\n","Iteration 8546, loss = 0.04576339\n","Iteration 8547, loss = 0.04576072\n","Iteration 8548, loss = 0.04575816\n","Iteration 8549, loss = 0.04575550\n","Iteration 8550, loss = 0.04575274\n","Iteration 8551, loss = 0.04575009\n","Iteration 8552, loss = 0.04574741\n","Iteration 8553, loss = 0.04574474\n","Iteration 8554, loss = 0.04574205\n","Iteration 8555, loss = 0.04573941\n","Iteration 8556, loss = 0.04573669\n","Iteration 8557, loss = 0.04573402\n","Iteration 8558, loss = 0.04573136\n","Iteration 8559, loss = 0.04572864\n","Iteration 8560, loss = 0.04572588\n","Iteration 8561, loss = 0.04572332\n","Iteration 8562, loss = 0.04572065\n","Iteration 8563, loss = 0.04571808\n","Iteration 8564, loss = 0.04571526\n","Iteration 8565, loss = 0.04571255\n","Iteration 8566, loss = 0.04570991\n","Iteration 8567, loss = 0.04570721\n","Iteration 8568, loss = 0.04570462\n","Iteration 8569, loss = 0.04570198\n","Iteration 8570, loss = 0.04569923\n","Iteration 8571, loss = 0.04569665\n","Iteration 8572, loss = 0.04569404\n","Iteration 8573, loss = 0.04569137\n","Iteration 8574, loss = 0.04568865\n","Iteration 8575, loss = 0.04568589\n","Iteration 8576, loss = 0.04568325\n","Iteration 8577, loss = 0.04568062\n","Iteration 8578, loss = 0.04567793\n","Iteration 8579, loss = 0.04567515\n","Iteration 8580, loss = 0.04567253\n","Iteration 8581, loss = 0.04566986\n","Iteration 8582, loss = 0.04566716\n","Iteration 8583, loss = 0.04566449\n","Iteration 8584, loss = 0.04566194\n","Iteration 8585, loss = 0.04565919\n","Iteration 8586, loss = 0.04565654\n","Iteration 8587, loss = 0.04565396\n","Iteration 8588, loss = 0.04565128\n","Iteration 8589, loss = 0.04564863\n","Iteration 8590, loss = 0.04564600\n","Iteration 8591, loss = 0.04564331\n","Iteration 8592, loss = 0.04564060\n","Iteration 8593, loss = 0.04563798\n","Iteration 8594, loss = 0.04563536\n","Iteration 8595, loss = 0.04563274\n","Iteration 8596, loss = 0.04563006\n","Iteration 8597, loss = 0.04562736\n","Iteration 8598, loss = 0.04562470\n","Iteration 8599, loss = 0.04562210\n","Iteration 8600, loss = 0.04561946\n","Iteration 8601, loss = 0.04561684\n","Iteration 8602, loss = 0.04561412\n","Iteration 8603, loss = 0.04561149\n","Iteration 8604, loss = 0.04560886\n","Iteration 8605, loss = 0.04560623\n","Iteration 8606, loss = 0.04560354\n","Iteration 8607, loss = 0.04560096\n","Iteration 8608, loss = 0.04559831\n","Iteration 8609, loss = 0.04559560\n","Iteration 8610, loss = 0.04559295\n","Iteration 8611, loss = 0.04559034\n","Iteration 8612, loss = 0.04558769\n","Iteration 8613, loss = 0.04558504\n","Iteration 8614, loss = 0.04558245\n","Iteration 8615, loss = 0.04557980\n","Iteration 8616, loss = 0.04557710\n","Iteration 8617, loss = 0.04557457\n","Iteration 8618, loss = 0.04557206\n","Iteration 8619, loss = 0.04556923\n","Iteration 8620, loss = 0.04556663\n","Iteration 8621, loss = 0.04556406\n","Iteration 8622, loss = 0.04556143\n","Iteration 8623, loss = 0.04555875\n","Iteration 8624, loss = 0.04555602\n","Iteration 8625, loss = 0.04555357\n","Iteration 8626, loss = 0.04555096\n","Iteration 8627, loss = 0.04554830\n","Iteration 8628, loss = 0.04554555\n","Iteration 8629, loss = 0.04554301\n","Iteration 8630, loss = 0.04554047\n","Iteration 8631, loss = 0.04553787\n","Iteration 8632, loss = 0.04553521\n","Iteration 8633, loss = 0.04553250\n","Iteration 8634, loss = 0.04552980\n","Iteration 8635, loss = 0.04552720\n","Iteration 8636, loss = 0.04552467\n","Iteration 8637, loss = 0.04552203\n","Iteration 8638, loss = 0.04551929\n","Iteration 8639, loss = 0.04551669\n","Iteration 8640, loss = 0.04551414\n","Iteration 8641, loss = 0.04551152\n","Iteration 8642, loss = 0.04550895\n","Iteration 8643, loss = 0.04550618\n","Iteration 8644, loss = 0.04550350\n","Iteration 8645, loss = 0.04550094\n","Iteration 8646, loss = 0.04549826\n","Iteration 8647, loss = 0.04549571\n","Iteration 8648, loss = 0.04549313\n","Iteration 8649, loss = 0.04549049\n","Iteration 8650, loss = 0.04548788\n","Iteration 8651, loss = 0.04548517\n","Iteration 8652, loss = 0.04548260\n","Iteration 8653, loss = 0.04547993\n","Iteration 8654, loss = 0.04547731\n","Iteration 8655, loss = 0.04547476\n","Iteration 8656, loss = 0.04547215\n","Iteration 8657, loss = 0.04546948\n","Iteration 8658, loss = 0.04546692\n","Iteration 8659, loss = 0.04546430\n","Iteration 8660, loss = 0.04546164\n","Iteration 8661, loss = 0.04545904\n","Iteration 8662, loss = 0.04545645\n","Iteration 8663, loss = 0.04545381\n","Iteration 8664, loss = 0.04545121\n","Iteration 8665, loss = 0.04544861\n","Iteration 8666, loss = 0.04544598\n","Iteration 8667, loss = 0.04544350\n","Iteration 8668, loss = 0.04544073\n","Iteration 8669, loss = 0.04543821\n","Iteration 8670, loss = 0.04543563\n","Iteration 8671, loss = 0.04543305\n","Iteration 8672, loss = 0.04543054\n","Iteration 8673, loss = 0.04542793\n","Iteration 8674, loss = 0.04542534\n","Iteration 8675, loss = 0.04542277\n","Iteration 8676, loss = 0.04542014\n","Iteration 8677, loss = 0.04541751\n","Iteration 8678, loss = 0.04541490\n","Iteration 8679, loss = 0.04541231\n","Iteration 8680, loss = 0.04540971\n","Iteration 8681, loss = 0.04540705\n","Iteration 8682, loss = 0.04540446\n","Iteration 8683, loss = 0.04540183\n","Iteration 8684, loss = 0.04539916\n","Iteration 8685, loss = 0.04539657\n","Iteration 8686, loss = 0.04539394\n","Iteration 8687, loss = 0.04539136\n","Iteration 8688, loss = 0.04538874\n","Iteration 8689, loss = 0.04538627\n","Iteration 8690, loss = 0.04538365\n","Iteration 8691, loss = 0.04538102\n","Iteration 8692, loss = 0.04537847\n","Iteration 8693, loss = 0.04537585\n","Iteration 8694, loss = 0.04537335\n","Iteration 8695, loss = 0.04537075\n","Iteration 8696, loss = 0.04536806\n","Iteration 8697, loss = 0.04536547\n","Iteration 8698, loss = 0.04536289\n","Iteration 8699, loss = 0.04536025\n","Iteration 8700, loss = 0.04535782\n","Iteration 8701, loss = 0.04535514\n","Iteration 8702, loss = 0.04535257\n","Iteration 8703, loss = 0.04535001\n","Iteration 8704, loss = 0.04534744\n","Iteration 8705, loss = 0.04534491\n","Iteration 8706, loss = 0.04534233\n","Iteration 8707, loss = 0.04533975\n","Iteration 8708, loss = 0.04533723\n","Iteration 8709, loss = 0.04533462\n","Iteration 8710, loss = 0.04533203\n","Iteration 8711, loss = 0.04532947\n","Iteration 8712, loss = 0.04532684\n","Iteration 8713, loss = 0.04532424\n","Iteration 8714, loss = 0.04532163\n","Iteration 8715, loss = 0.04531903\n","Iteration 8716, loss = 0.04531644\n","Iteration 8717, loss = 0.04531381\n","Iteration 8718, loss = 0.04531130\n","Iteration 8719, loss = 0.04530873\n","Iteration 8720, loss = 0.04530607\n","Iteration 8721, loss = 0.04530360\n","Iteration 8722, loss = 0.04530112\n","Iteration 8723, loss = 0.04529858\n","Iteration 8724, loss = 0.04529598\n","Iteration 8725, loss = 0.04529332\n","Iteration 8726, loss = 0.04529079\n","Iteration 8727, loss = 0.04528829\n","Iteration 8728, loss = 0.04528567\n","Iteration 8729, loss = 0.04528296\n","Iteration 8730, loss = 0.04528053\n","Iteration 8731, loss = 0.04527803\n","Iteration 8732, loss = 0.04527557\n","Iteration 8733, loss = 0.04527289\n","Iteration 8734, loss = 0.04527026\n","Iteration 8735, loss = 0.04526758\n","Iteration 8736, loss = 0.04526509\n","Iteration 8737, loss = 0.04526262\n","Iteration 8738, loss = 0.04526010\n","Iteration 8739, loss = 0.04525739\n","Iteration 8740, loss = 0.04525477\n","Iteration 8741, loss = 0.04525230\n","Iteration 8742, loss = 0.04524976\n","Iteration 8743, loss = 0.04524716\n","Iteration 8744, loss = 0.04524450\n","Iteration 8745, loss = 0.04524207\n","Iteration 8746, loss = 0.04523955\n","Iteration 8747, loss = 0.04523695\n","Iteration 8748, loss = 0.04523426\n","Iteration 8749, loss = 0.04523181\n","Iteration 8750, loss = 0.04522936\n","Iteration 8751, loss = 0.04522683\n","Iteration 8752, loss = 0.04522425\n","Iteration 8753, loss = 0.04522161\n","Iteration 8754, loss = 0.04521892\n","Iteration 8755, loss = 0.04521656\n","Iteration 8756, loss = 0.04521403\n","Iteration 8757, loss = 0.04521149\n","Iteration 8758, loss = 0.04520884\n","Iteration 8759, loss = 0.04520618\n","Iteration 8760, loss = 0.04520370\n","Iteration 8761, loss = 0.04520115\n","Iteration 8762, loss = 0.04519855\n","Iteration 8763, loss = 0.04519602\n","Iteration 8764, loss = 0.04519355\n","Iteration 8765, loss = 0.04519108\n","Iteration 8766, loss = 0.04518850\n","Iteration 8767, loss = 0.04518582\n","Iteration 8768, loss = 0.04518331\n","Iteration 8769, loss = 0.04518085\n","Iteration 8770, loss = 0.04517832\n","Iteration 8771, loss = 0.04517588\n","Iteration 8772, loss = 0.04517313\n","Iteration 8773, loss = 0.04517049\n","Iteration 8774, loss = 0.04516814\n","Iteration 8775, loss = 0.04516571\n","Iteration 8776, loss = 0.04516315\n","Iteration 8777, loss = 0.04516050\n","Iteration 8778, loss = 0.04515776\n","Iteration 8779, loss = 0.04515544\n","Iteration 8780, loss = 0.04515304\n","Iteration 8781, loss = 0.04515058\n","Iteration 8782, loss = 0.04514804\n","Iteration 8783, loss = 0.04514545\n","Iteration 8784, loss = 0.04514281\n","Iteration 8785, loss = 0.04514012\n","Iteration 8786, loss = 0.04513760\n","Iteration 8787, loss = 0.04513520\n","Iteration 8788, loss = 0.04513267\n","Iteration 8789, loss = 0.04513006\n","Iteration 8790, loss = 0.04512736\n","Iteration 8791, loss = 0.04512501\n","Iteration 8792, loss = 0.04512259\n","Iteration 8793, loss = 0.04512010\n","Iteration 8794, loss = 0.04511755\n","Iteration 8795, loss = 0.04511508\n","Iteration 8796, loss = 0.04511232\n","Iteration 8797, loss = 0.04510966\n","Iteration 8798, loss = 0.04510733\n","Iteration 8799, loss = 0.04510493\n","Iteration 8800, loss = 0.04510242\n","Iteration 8801, loss = 0.04509981\n","Iteration 8802, loss = 0.04509715\n","Iteration 8803, loss = 0.04509457\n","Iteration 8804, loss = 0.04509217\n","Iteration 8805, loss = 0.04508971\n","Iteration 8806, loss = 0.04508718\n","Iteration 8807, loss = 0.04508459\n","Iteration 8808, loss = 0.04508195\n","Iteration 8809, loss = 0.04507946\n","Iteration 8810, loss = 0.04507701\n","Iteration 8811, loss = 0.04507456\n","Iteration 8812, loss = 0.04507184\n","Iteration 8813, loss = 0.04506935\n","Iteration 8814, loss = 0.04506692\n","Iteration 8815, loss = 0.04506442\n","Iteration 8816, loss = 0.04506186\n","Iteration 8817, loss = 0.04505924\n","Iteration 8818, loss = 0.04505682\n","Iteration 8819, loss = 0.04505431\n","Iteration 8820, loss = 0.04505177\n","Iteration 8821, loss = 0.04504917\n","Iteration 8822, loss = 0.04504669\n","Iteration 8823, loss = 0.04504415\n","Iteration 8824, loss = 0.04504167\n","Iteration 8825, loss = 0.04503914\n","Iteration 8826, loss = 0.04503659\n","Iteration 8827, loss = 0.04503425\n","Iteration 8828, loss = 0.04503155\n","Iteration 8829, loss = 0.04502918\n","Iteration 8830, loss = 0.04502673\n","Iteration 8831, loss = 0.04502418\n","Iteration 8832, loss = 0.04502178\n","Iteration 8833, loss = 0.04501935\n","Iteration 8834, loss = 0.04501686\n","Iteration 8835, loss = 0.04501431\n","Iteration 8836, loss = 0.04501170\n","Iteration 8837, loss = 0.04500932\n","Iteration 8838, loss = 0.04500688\n","Iteration 8839, loss = 0.04500433\n","Iteration 8840, loss = 0.04500169\n","Iteration 8841, loss = 0.04499915\n","Iteration 8842, loss = 0.04499671\n","Iteration 8843, loss = 0.04499419\n","Iteration 8844, loss = 0.04499162\n","Iteration 8845, loss = 0.04498919\n","Iteration 8846, loss = 0.04498665\n","Iteration 8847, loss = 0.04498412\n","Iteration 8848, loss = 0.04498162\n","Iteration 8849, loss = 0.04497908\n","Iteration 8850, loss = 0.04497664\n","Iteration 8851, loss = 0.04497413\n","Iteration 8852, loss = 0.04497164\n","Iteration 8853, loss = 0.04496914\n","Iteration 8854, loss = 0.04496664\n","Iteration 8855, loss = 0.04496415\n","Iteration 8856, loss = 0.04496160\n","Iteration 8857, loss = 0.04495915\n","Iteration 8858, loss = 0.04495664\n","Iteration 8859, loss = 0.04495403\n","Iteration 8860, loss = 0.04495184\n","Iteration 8861, loss = 0.04494933\n","Iteration 8862, loss = 0.04494675\n","Iteration 8863, loss = 0.04494425\n","Iteration 8864, loss = 0.04494169\n","Iteration 8865, loss = 0.04493937\n","Iteration 8866, loss = 0.04493698\n","Iteration 8867, loss = 0.04493447\n","Iteration 8868, loss = 0.04493186\n","Iteration 8869, loss = 0.04492934\n","Iteration 8870, loss = 0.04492693\n","Iteration 8871, loss = 0.04492445\n","Iteration 8872, loss = 0.04492190\n","Iteration 8873, loss = 0.04491930\n","Iteration 8874, loss = 0.04491684\n","Iteration 8875, loss = 0.04491439\n","Iteration 8876, loss = 0.04491211\n","Iteration 8877, loss = 0.04490942\n","Iteration 8878, loss = 0.04490696\n","Iteration 8879, loss = 0.04490462\n","Iteration 8880, loss = 0.04490219\n","Iteration 8881, loss = 0.04489970\n","Iteration 8882, loss = 0.04489715\n","Iteration 8883, loss = 0.04489455\n","Iteration 8884, loss = 0.04489222\n","Iteration 8885, loss = 0.04488985\n","Iteration 8886, loss = 0.04488736\n","Iteration 8887, loss = 0.04488477\n","Iteration 8888, loss = 0.04488209\n","Iteration 8889, loss = 0.04487975\n","Iteration 8890, loss = 0.04487737\n","Iteration 8891, loss = 0.04487507\n","Iteration 8892, loss = 0.04487250\n","Iteration 8893, loss = 0.04486997\n","Iteration 8894, loss = 0.04486743\n","Iteration 8895, loss = 0.04486483\n","Iteration 8896, loss = 0.04486259\n","Iteration 8897, loss = 0.04486027\n","Iteration 8898, loss = 0.04485784\n","Iteration 8899, loss = 0.04485529\n","Iteration 8900, loss = 0.04485265\n","Iteration 8901, loss = 0.04485008\n","Iteration 8902, loss = 0.04484771\n","Iteration 8903, loss = 0.04484526\n","Iteration 8904, loss = 0.04484275\n","Iteration 8905, loss = 0.04484018\n","Iteration 8906, loss = 0.04483756\n","Iteration 8907, loss = 0.04483545\n","Iteration 8908, loss = 0.04483302\n","Iteration 8909, loss = 0.04483048\n","Iteration 8910, loss = 0.04482795\n","Iteration 8911, loss = 0.04482534\n","Iteration 8912, loss = 0.04482297\n","Iteration 8913, loss = 0.04482054\n","Iteration 8914, loss = 0.04481803\n","Iteration 8915, loss = 0.04481560\n","Iteration 8916, loss = 0.04481315\n","Iteration 8917, loss = 0.04481060\n","Iteration 8918, loss = 0.04480823\n","Iteration 8919, loss = 0.04480581\n","Iteration 8920, loss = 0.04480332\n","Iteration 8921, loss = 0.04480077\n","Iteration 8922, loss = 0.04479829\n","Iteration 8923, loss = 0.04479594\n","Iteration 8924, loss = 0.04479361\n","Iteration 8925, loss = 0.04479118\n","Iteration 8926, loss = 0.04478865\n","Iteration 8927, loss = 0.04478609\n","Iteration 8928, loss = 0.04478374\n","Iteration 8929, loss = 0.04478131\n","Iteration 8930, loss = 0.04477881\n","Iteration 8931, loss = 0.04477628\n","Iteration 8932, loss = 0.04477383\n","Iteration 8933, loss = 0.04477137\n","Iteration 8934, loss = 0.04476890\n","Iteration 8935, loss = 0.04476641\n","Iteration 8936, loss = 0.04476391\n","Iteration 8937, loss = 0.04476146\n","Iteration 8938, loss = 0.04475917\n","Iteration 8939, loss = 0.04475665\n","Iteration 8940, loss = 0.04475416\n","Iteration 8941, loss = 0.04475175\n","Iteration 8942, loss = 0.04474932\n","Iteration 8943, loss = 0.04474688\n","Iteration 8944, loss = 0.04474453\n","Iteration 8945, loss = 0.04474211\n","Iteration 8946, loss = 0.04473963\n","Iteration 8947, loss = 0.04473713\n","Iteration 8948, loss = 0.04473468\n","Iteration 8949, loss = 0.04473224\n","Iteration 8950, loss = 0.04472977\n","Iteration 8951, loss = 0.04472726\n","Iteration 8952, loss = 0.04472481\n","Iteration 8953, loss = 0.04472251\n","Iteration 8954, loss = 0.04472001\n","Iteration 8955, loss = 0.04471752\n","Iteration 8956, loss = 0.04471519\n","Iteration 8957, loss = 0.04471278\n","Iteration 8958, loss = 0.04471032\n","Iteration 8959, loss = 0.04470792\n","Iteration 8960, loss = 0.04470545\n","Iteration 8961, loss = 0.04470314\n","Iteration 8962, loss = 0.04470071\n","Iteration 8963, loss = 0.04469818\n","Iteration 8964, loss = 0.04469576\n","Iteration 8965, loss = 0.04469336\n","Iteration 8966, loss = 0.04469090\n","Iteration 8967, loss = 0.04468838\n","Iteration 8968, loss = 0.04468590\n","Iteration 8969, loss = 0.04468348\n","Iteration 8970, loss = 0.04468099\n","Iteration 8971, loss = 0.04467867\n","Iteration 8972, loss = 0.04467629\n","Iteration 8973, loss = 0.04467395\n","Iteration 8974, loss = 0.04467137\n","Iteration 8975, loss = 0.04466892\n","Iteration 8976, loss = 0.04466655\n","Iteration 8977, loss = 0.04466407\n","Iteration 8978, loss = 0.04466171\n","Iteration 8979, loss = 0.04465933\n","Iteration 8980, loss = 0.04465687\n","Iteration 8981, loss = 0.04465436\n","Iteration 8982, loss = 0.04465208\n","Iteration 8983, loss = 0.04464960\n","Iteration 8984, loss = 0.04464714\n","Iteration 8985, loss = 0.04464468\n","Iteration 8986, loss = 0.04464231\n","Iteration 8987, loss = 0.04463986\n","Iteration 8988, loss = 0.04463737\n","Iteration 8989, loss = 0.04463508\n","Iteration 8990, loss = 0.04463260\n","Iteration 8991, loss = 0.04463016\n","Iteration 8992, loss = 0.04462780\n","Iteration 8993, loss = 0.04462542\n","Iteration 8994, loss = 0.04462297\n","Iteration 8995, loss = 0.04462047\n","Iteration 8996, loss = 0.04461804\n","Iteration 8997, loss = 0.04461584\n","Iteration 8998, loss = 0.04461329\n","Iteration 8999, loss = 0.04461084\n","Iteration 9000, loss = 0.04460852\n","Iteration 9001, loss = 0.04460613\n","Iteration 9002, loss = 0.04460364\n","Iteration 9003, loss = 0.04460125\n","Iteration 9004, loss = 0.04459899\n","Iteration 9005, loss = 0.04459649\n","Iteration 9006, loss = 0.04459403\n","Iteration 9007, loss = 0.04459163\n","Iteration 9008, loss = 0.04458927\n","Iteration 9009, loss = 0.04458679\n","Iteration 9010, loss = 0.04458442\n","Iteration 9011, loss = 0.04458204\n","Iteration 9012, loss = 0.04457969\n","Iteration 9013, loss = 0.04457715\n","Iteration 9014, loss = 0.04457482\n","Iteration 9015, loss = 0.04457247\n","Iteration 9016, loss = 0.04457002\n","Iteration 9017, loss = 0.04456755\n","Iteration 9018, loss = 0.04456518\n","Iteration 9019, loss = 0.04456275\n","Iteration 9020, loss = 0.04456033\n","Iteration 9021, loss = 0.04455794\n","Iteration 9022, loss = 0.04455561\n","Iteration 9023, loss = 0.04455323\n","Iteration 9024, loss = 0.04455078\n","Iteration 9025, loss = 0.04454841\n","Iteration 9026, loss = 0.04454601\n","Iteration 9027, loss = 0.04454351\n","Iteration 9028, loss = 0.04454140\n","Iteration 9029, loss = 0.04453892\n","Iteration 9030, loss = 0.04453654\n","Iteration 9031, loss = 0.04453414\n","Iteration 9032, loss = 0.04453170\n","Iteration 9033, loss = 0.04452937\n","Iteration 9034, loss = 0.04452695\n","Iteration 9035, loss = 0.04452458\n","Iteration 9036, loss = 0.04452223\n","Iteration 9037, loss = 0.04451983\n","Iteration 9038, loss = 0.04451739\n","Iteration 9039, loss = 0.04451498\n","Iteration 9040, loss = 0.04451260\n","Iteration 9041, loss = 0.04451014\n","Iteration 9042, loss = 0.04450775\n","Iteration 9043, loss = 0.04450533\n","Iteration 9044, loss = 0.04450289\n","Iteration 9045, loss = 0.04450072\n","Iteration 9046, loss = 0.04449827\n","Iteration 9047, loss = 0.04449578\n","Iteration 9048, loss = 0.04449346\n","Iteration 9049, loss = 0.04449107\n","Iteration 9050, loss = 0.04448877\n","Iteration 9051, loss = 0.04448642\n","Iteration 9052, loss = 0.04448395\n","Iteration 9053, loss = 0.04448166\n","Iteration 9054, loss = 0.04447933\n","Iteration 9055, loss = 0.04447693\n","Iteration 9056, loss = 0.04447446\n","Iteration 9057, loss = 0.04447195\n","Iteration 9058, loss = 0.04446958\n","Iteration 9059, loss = 0.04446724\n","Iteration 9060, loss = 0.04446476\n","Iteration 9061, loss = 0.04446250\n","Iteration 9062, loss = 0.04446016\n","Iteration 9063, loss = 0.04445778\n","Iteration 9064, loss = 0.04445543\n","Iteration 9065, loss = 0.04445310\n","Iteration 9066, loss = 0.04445070\n","Iteration 9067, loss = 0.04444835\n","Iteration 9068, loss = 0.04444597\n","Iteration 9069, loss = 0.04444357\n","Iteration 9070, loss = 0.04444123\n","Iteration 9071, loss = 0.04443881\n","Iteration 9072, loss = 0.04443640\n","Iteration 9073, loss = 0.04443401\n","Iteration 9074, loss = 0.04443156\n","Iteration 9075, loss = 0.04442952\n","Iteration 9076, loss = 0.04442710\n","Iteration 9077, loss = 0.04442450\n","Iteration 9078, loss = 0.04442224\n","Iteration 9079, loss = 0.04441997\n","Iteration 9080, loss = 0.04441762\n","Iteration 9081, loss = 0.04441519\n","Iteration 9082, loss = 0.04441278\n","Iteration 9083, loss = 0.04441045\n","Iteration 9084, loss = 0.04440802\n","Iteration 9085, loss = 0.04440572\n","Iteration 9086, loss = 0.04440339\n","Iteration 9087, loss = 0.04440098\n","Iteration 9088, loss = 0.04439850\n","Iteration 9089, loss = 0.04439628\n","Iteration 9090, loss = 0.04439387\n","Iteration 9091, loss = 0.04439150\n","Iteration 9092, loss = 0.04438913\n","Iteration 9093, loss = 0.04438685\n","Iteration 9094, loss = 0.04438450\n","Iteration 9095, loss = 0.04438213\n","Iteration 9096, loss = 0.04437978\n","Iteration 9097, loss = 0.04437744\n","Iteration 9098, loss = 0.04437509\n","Iteration 9099, loss = 0.04437267\n","Iteration 9100, loss = 0.04437039\n","Iteration 9101, loss = 0.04436804\n","Iteration 9102, loss = 0.04436558\n","Iteration 9103, loss = 0.04436319\n","Iteration 9104, loss = 0.04436086\n","Iteration 9105, loss = 0.04435850\n","Iteration 9106, loss = 0.04435608\n","Iteration 9107, loss = 0.04435378\n","Iteration 9108, loss = 0.04435147\n","Iteration 9109, loss = 0.04434910\n","Iteration 9110, loss = 0.04434674\n","Iteration 9111, loss = 0.04434445\n","Iteration 9112, loss = 0.04434209\n","Iteration 9113, loss = 0.04433968\n","Iteration 9114, loss = 0.04433732\n","Iteration 9115, loss = 0.04433503\n","Iteration 9116, loss = 0.04433267\n","Iteration 9117, loss = 0.04433025\n","Iteration 9118, loss = 0.04432805\n","Iteration 9119, loss = 0.04432563\n","Iteration 9120, loss = 0.04432322\n","Iteration 9121, loss = 0.04432094\n","Iteration 9122, loss = 0.04431865\n","Iteration 9123, loss = 0.04431629\n","Iteration 9124, loss = 0.04431391\n","Iteration 9125, loss = 0.04431159\n","Iteration 9126, loss = 0.04430931\n","Iteration 9127, loss = 0.04430692\n","Iteration 9128, loss = 0.04430460\n","Iteration 9129, loss = 0.04430229\n","Iteration 9130, loss = 0.04429992\n","Iteration 9131, loss = 0.04429747\n","Iteration 9132, loss = 0.04429526\n","Iteration 9133, loss = 0.04429313\n","Iteration 9134, loss = 0.04429062\n","Iteration 9135, loss = 0.04428818\n","Iteration 9136, loss = 0.04428602\n","Iteration 9137, loss = 0.04428383\n","Iteration 9138, loss = 0.04428155\n","Iteration 9139, loss = 0.04427920\n","Iteration 9140, loss = 0.04427678\n","Iteration 9141, loss = 0.04427432\n","Iteration 9142, loss = 0.04427205\n","Iteration 9143, loss = 0.04426967\n","Iteration 9144, loss = 0.04426733\n","Iteration 9145, loss = 0.04426500\n","Iteration 9146, loss = 0.04426260\n","Iteration 9147, loss = 0.04426024\n","Iteration 9148, loss = 0.04425788\n","Iteration 9149, loss = 0.04425559\n","Iteration 9150, loss = 0.04425320\n","Iteration 9151, loss = 0.04425091\n","Iteration 9152, loss = 0.04424860\n","Iteration 9153, loss = 0.04424637\n","Iteration 9154, loss = 0.04424410\n","Iteration 9155, loss = 0.04424175\n","Iteration 9156, loss = 0.04423940\n","Iteration 9157, loss = 0.04423708\n","Iteration 9158, loss = 0.04423472\n","Iteration 9159, loss = 0.04423238\n","Iteration 9160, loss = 0.04423005\n","Iteration 9161, loss = 0.04422768\n","Iteration 9162, loss = 0.04422538\n","Iteration 9163, loss = 0.04422308\n","Iteration 9164, loss = 0.04422070\n","Iteration 9165, loss = 0.04421837\n","Iteration 9166, loss = 0.04421606\n","Iteration 9167, loss = 0.04421370\n","Iteration 9168, loss = 0.04421142\n","Iteration 9169, loss = 0.04420917\n","Iteration 9170, loss = 0.04420685\n","Iteration 9171, loss = 0.04420458\n","Iteration 9172, loss = 0.04420229\n","Iteration 9173, loss = 0.04419993\n","Iteration 9174, loss = 0.04419761\n","Iteration 9175, loss = 0.04419529\n","Iteration 9176, loss = 0.04419288\n","Iteration 9177, loss = 0.04419064\n","Iteration 9178, loss = 0.04418832\n","Iteration 9179, loss = 0.04418600\n","Iteration 9180, loss = 0.04418368\n","Iteration 9181, loss = 0.04418139\n","Iteration 9182, loss = 0.04417904\n","Iteration 9183, loss = 0.04417682\n","Iteration 9184, loss = 0.04417455\n","Iteration 9185, loss = 0.04417218\n","Iteration 9186, loss = 0.04416998\n","Iteration 9187, loss = 0.04416773\n","Iteration 9188, loss = 0.04416541\n","Iteration 9189, loss = 0.04416301\n","Iteration 9190, loss = 0.04416062\n","Iteration 9191, loss = 0.04415833\n","Iteration 9192, loss = 0.04415619\n","Iteration 9193, loss = 0.04415384\n","Iteration 9194, loss = 0.04415155\n","Iteration 9195, loss = 0.04414928\n","Iteration 9196, loss = 0.04414694\n","Iteration 9197, loss = 0.04414475\n","Iteration 9198, loss = 0.04414253\n","Iteration 9199, loss = 0.04414020\n","Iteration 9200, loss = 0.04413776\n","Iteration 9201, loss = 0.04413563\n","Iteration 9202, loss = 0.04413341\n","Iteration 9203, loss = 0.04413112\n","Iteration 9204, loss = 0.04412875\n","Iteration 9205, loss = 0.04412632\n","Iteration 9206, loss = 0.04412383\n","Iteration 9207, loss = 0.04412157\n","Iteration 9208, loss = 0.04411950\n","Iteration 9209, loss = 0.04411716\n","Iteration 9210, loss = 0.04411472\n","Iteration 9211, loss = 0.04411244\n","Iteration 9212, loss = 0.04411021\n","Iteration 9213, loss = 0.04410795\n","Iteration 9214, loss = 0.04410559\n","Iteration 9215, loss = 0.04410344\n","Iteration 9216, loss = 0.04410121\n","Iteration 9217, loss = 0.04409890\n","Iteration 9218, loss = 0.04409652\n","Iteration 9219, loss = 0.04409409\n","Iteration 9220, loss = 0.04409181\n","Iteration 9221, loss = 0.04408944\n","Iteration 9222, loss = 0.04408745\n","Iteration 9223, loss = 0.04408509\n","Iteration 9224, loss = 0.04408265\n","Iteration 9225, loss = 0.04408045\n","Iteration 9226, loss = 0.04407819\n","Iteration 9227, loss = 0.04407594\n","Iteration 9228, loss = 0.04407369\n","Iteration 9229, loss = 0.04407137\n","Iteration 9230, loss = 0.04406917\n","Iteration 9231, loss = 0.04406690\n","Iteration 9232, loss = 0.04406452\n","Iteration 9233, loss = 0.04406225\n","Iteration 9234, loss = 0.04406000\n","Iteration 9235, loss = 0.04405767\n","Iteration 9236, loss = 0.04405535\n","Iteration 9237, loss = 0.04405305\n","Iteration 9238, loss = 0.04405083\n","Iteration 9239, loss = 0.04404850\n","Iteration 9240, loss = 0.04404621\n","Iteration 9241, loss = 0.04404397\n","Iteration 9242, loss = 0.04404170\n","Iteration 9243, loss = 0.04403943\n","Iteration 9244, loss = 0.04403717\n","Iteration 9245, loss = 0.04403489\n","Iteration 9246, loss = 0.04403262\n","Iteration 9247, loss = 0.04403029\n","Iteration 9248, loss = 0.04402800\n","Iteration 9249, loss = 0.04402572\n","Iteration 9250, loss = 0.04402361\n","Iteration 9251, loss = 0.04402121\n","Iteration 9252, loss = 0.04401898\n","Iteration 9253, loss = 0.04401675\n","Iteration 9254, loss = 0.04401457\n","Iteration 9255, loss = 0.04401232\n","Iteration 9256, loss = 0.04401006\n","Iteration 9257, loss = 0.04400782\n","Iteration 9258, loss = 0.04400550\n","Iteration 9259, loss = 0.04400336\n","Iteration 9260, loss = 0.04400110\n","Iteration 9261, loss = 0.04399874\n","Iteration 9262, loss = 0.04399642\n","Iteration 9263, loss = 0.04399418\n","Iteration 9264, loss = 0.04399186\n","Iteration 9265, loss = 0.04398947\n","Iteration 9266, loss = 0.04398761\n","Iteration 9267, loss = 0.04398535\n","Iteration 9268, loss = 0.04398284\n","Iteration 9269, loss = 0.04398048\n","Iteration 9270, loss = 0.04397844\n","Iteration 9271, loss = 0.04397631\n","Iteration 9272, loss = 0.04397409\n","Iteration 9273, loss = 0.04397179\n","Iteration 9274, loss = 0.04396942\n","Iteration 9275, loss = 0.04396699\n","Iteration 9276, loss = 0.04396496\n","Iteration 9277, loss = 0.04396281\n","Iteration 9278, loss = 0.04396054\n","Iteration 9279, loss = 0.04395828\n","Iteration 9280, loss = 0.04395577\n","Iteration 9281, loss = 0.04395343\n","Iteration 9282, loss = 0.04395130\n","Iteration 9283, loss = 0.04394911\n","Iteration 9284, loss = 0.04394685\n","Iteration 9285, loss = 0.04394454\n","Iteration 9286, loss = 0.04394224\n","Iteration 9287, loss = 0.04394007\n","Iteration 9288, loss = 0.04393778\n","Iteration 9289, loss = 0.04393550\n","Iteration 9290, loss = 0.04393327\n","Iteration 9291, loss = 0.04393096\n","Iteration 9292, loss = 0.04392871\n","Iteration 9293, loss = 0.04392660\n","Iteration 9294, loss = 0.04392415\n","Iteration 9295, loss = 0.04392197\n","Iteration 9296, loss = 0.04391986\n","Iteration 9297, loss = 0.04391763\n","Iteration 9298, loss = 0.04391543\n","Iteration 9299, loss = 0.04391323\n","Iteration 9300, loss = 0.04391095\n","Iteration 9301, loss = 0.04390877\n","Iteration 9302, loss = 0.04390654\n","Iteration 9303, loss = 0.04390420\n","Iteration 9304, loss = 0.04390201\n","Iteration 9305, loss = 0.04389980\n","Iteration 9306, loss = 0.04389751\n","Iteration 9307, loss = 0.04389515\n","Iteration 9308, loss = 0.04389285\n","Iteration 9309, loss = 0.04389095\n","Iteration 9310, loss = 0.04388861\n","Iteration 9311, loss = 0.04388616\n","Iteration 9312, loss = 0.04388401\n","Iteration 9313, loss = 0.04388178\n","Iteration 9314, loss = 0.04387953\n","Iteration 9315, loss = 0.04387731\n","Iteration 9316, loss = 0.04387510\n","Iteration 9317, loss = 0.04387286\n","Iteration 9318, loss = 0.04387057\n","Iteration 9319, loss = 0.04386831\n","Iteration 9320, loss = 0.04386608\n","Iteration 9321, loss = 0.04386378\n","Iteration 9322, loss = 0.04386172\n","Iteration 9323, loss = 0.04385938\n","Iteration 9324, loss = 0.04385715\n","Iteration 9325, loss = 0.04385506\n","Iteration 9326, loss = 0.04385287\n","Iteration 9327, loss = 0.04385060\n","Iteration 9328, loss = 0.04384840\n","Iteration 9329, loss = 0.04384620\n","Iteration 9330, loss = 0.04384394\n","Iteration 9331, loss = 0.04384179\n","Iteration 9332, loss = 0.04383958\n","Iteration 9333, loss = 0.04383729\n","Iteration 9334, loss = 0.04383496\n","Iteration 9335, loss = 0.04383271\n","Iteration 9336, loss = 0.04383045\n","Iteration 9337, loss = 0.04382843\n","Iteration 9338, loss = 0.04382615\n","Iteration 9339, loss = 0.04382380\n","Iteration 9340, loss = 0.04382169\n","Iteration 9341, loss = 0.04381953\n","Iteration 9342, loss = 0.04381729\n","Iteration 9343, loss = 0.04381511\n","Iteration 9344, loss = 0.04381292\n","Iteration 9345, loss = 0.04381062\n","Iteration 9346, loss = 0.04380849\n","Iteration 9347, loss = 0.04380631\n","Iteration 9348, loss = 0.04380404\n","Iteration 9349, loss = 0.04380171\n","Iteration 9350, loss = 0.04379944\n","Iteration 9351, loss = 0.04379758\n","Iteration 9352, loss = 0.04379524\n","Iteration 9353, loss = 0.04379283\n","Iteration 9354, loss = 0.04379071\n","Iteration 9355, loss = 0.04378850\n","Iteration 9356, loss = 0.04378631\n","Iteration 9357, loss = 0.04378412\n","Iteration 9358, loss = 0.04378189\n","Iteration 9359, loss = 0.04377968\n","Iteration 9360, loss = 0.04377747\n","Iteration 9361, loss = 0.04377521\n","Iteration 9362, loss = 0.04377304\n","Iteration 9363, loss = 0.04377082\n","Iteration 9364, loss = 0.04376853\n","Iteration 9365, loss = 0.04376658\n","Iteration 9366, loss = 0.04376431\n","Iteration 9367, loss = 0.04376189\n","Iteration 9368, loss = 0.04375988\n","Iteration 9369, loss = 0.04375778\n","Iteration 9370, loss = 0.04375559\n","Iteration 9371, loss = 0.04375332\n","Iteration 9372, loss = 0.04375107\n","Iteration 9373, loss = 0.04374892\n","Iteration 9374, loss = 0.04374665\n","Iteration 9375, loss = 0.04374445\n","Iteration 9376, loss = 0.04374226\n","Iteration 9377, loss = 0.04373999\n","Iteration 9378, loss = 0.04373770\n","Iteration 9379, loss = 0.04373572\n","Iteration 9380, loss = 0.04373346\n","Iteration 9381, loss = 0.04373117\n","Iteration 9382, loss = 0.04372900\n","Iteration 9383, loss = 0.04372683\n","Iteration 9384, loss = 0.04372472\n","Iteration 9385, loss = 0.04372249\n","Iteration 9386, loss = 0.04372040\n","Iteration 9387, loss = 0.04371823\n","Iteration 9388, loss = 0.04371599\n","Iteration 9389, loss = 0.04371367\n","Iteration 9390, loss = 0.04371164\n","Iteration 9391, loss = 0.04370948\n","Iteration 9392, loss = 0.04370722\n","Iteration 9393, loss = 0.04370510\n","Iteration 9394, loss = 0.04370282\n","Iteration 9395, loss = 0.04370064\n","Iteration 9396, loss = 0.04369852\n","Iteration 9397, loss = 0.04369632\n","Iteration 9398, loss = 0.04369404\n","Iteration 9399, loss = 0.04369204\n","Iteration 9400, loss = 0.04368995\n","Iteration 9401, loss = 0.04368774\n","Iteration 9402, loss = 0.04368543\n","Iteration 9403, loss = 0.04368311\n","Iteration 9404, loss = 0.04368098\n","Iteration 9405, loss = 0.04367876\n","Iteration 9406, loss = 0.04367647\n","Iteration 9407, loss = 0.04367451\n","Iteration 9408, loss = 0.04367228\n","Iteration 9409, loss = 0.04366995\n","Iteration 9410, loss = 0.04366787\n","Iteration 9411, loss = 0.04366578\n","Iteration 9412, loss = 0.04366361\n","Iteration 9413, loss = 0.04366135\n","Iteration 9414, loss = 0.04365930\n","Iteration 9415, loss = 0.04365719\n","Iteration 9416, loss = 0.04365495\n","Iteration 9417, loss = 0.04365261\n","Iteration 9418, loss = 0.04365052\n","Iteration 9419, loss = 0.04364840\n","Iteration 9420, loss = 0.04364620\n","Iteration 9421, loss = 0.04364422\n","Iteration 9422, loss = 0.04364185\n","Iteration 9423, loss = 0.04363955\n","Iteration 9424, loss = 0.04363752\n","Iteration 9425, loss = 0.04363537\n","Iteration 9426, loss = 0.04363311\n","Iteration 9427, loss = 0.04363104\n","Iteration 9428, loss = 0.04362896\n","Iteration 9429, loss = 0.04362679\n","Iteration 9430, loss = 0.04362454\n","Iteration 9431, loss = 0.04362221\n","Iteration 9432, loss = 0.04362018\n","Iteration 9433, loss = 0.04361807\n","Iteration 9434, loss = 0.04361585\n","Iteration 9435, loss = 0.04361359\n","Iteration 9436, loss = 0.04361129\n","Iteration 9437, loss = 0.04360920\n","Iteration 9438, loss = 0.04360702\n","Iteration 9439, loss = 0.04360490\n","Iteration 9440, loss = 0.04360273\n","Iteration 9441, loss = 0.04360064\n","Iteration 9442, loss = 0.04359843\n","Iteration 9443, loss = 0.04359622\n","Iteration 9444, loss = 0.04359410\n","Iteration 9445, loss = 0.04359189\n","Iteration 9446, loss = 0.04358968\n","Iteration 9447, loss = 0.04358769\n","Iteration 9448, loss = 0.04358537\n","Iteration 9449, loss = 0.04358323\n","Iteration 9450, loss = 0.04358106\n","Iteration 9451, loss = 0.04357887\n","Iteration 9452, loss = 0.04357676\n","Iteration 9453, loss = 0.04357461\n","Iteration 9454, loss = 0.04357258\n","Iteration 9455, loss = 0.04357048\n","Iteration 9456, loss = 0.04356830\n","Iteration 9457, loss = 0.04356604\n","Iteration 9458, loss = 0.04356388\n","Iteration 9459, loss = 0.04356176\n","Iteration 9460, loss = 0.04355957\n","Iteration 9461, loss = 0.04355743\n","Iteration 9462, loss = 0.04355520\n","Iteration 9463, loss = 0.04355316\n","Iteration 9464, loss = 0.04355104\n","Iteration 9465, loss = 0.04354882\n","Iteration 9466, loss = 0.04354667\n","Iteration 9467, loss = 0.04354471\n","Iteration 9468, loss = 0.04354234\n","Iteration 9469, loss = 0.04354031\n","Iteration 9470, loss = 0.04353823\n","Iteration 9471, loss = 0.04353607\n","Iteration 9472, loss = 0.04353382\n","Iteration 9473, loss = 0.04353171\n","Iteration 9474, loss = 0.04352974\n","Iteration 9475, loss = 0.04352745\n","Iteration 9476, loss = 0.04352520\n","Iteration 9477, loss = 0.04352311\n","Iteration 9478, loss = 0.04352093\n","Iteration 9479, loss = 0.04351882\n","Iteration 9480, loss = 0.04351663\n","Iteration 9481, loss = 0.04351471\n","Iteration 9482, loss = 0.04351244\n","Iteration 9483, loss = 0.04351022\n","Iteration 9484, loss = 0.04350825\n","Iteration 9485, loss = 0.04350618\n","Iteration 9486, loss = 0.04350402\n","Iteration 9487, loss = 0.04350181\n","Iteration 9488, loss = 0.04349956\n","Iteration 9489, loss = 0.04349750\n","Iteration 9490, loss = 0.04349533\n","Iteration 9491, loss = 0.04349332\n","Iteration 9492, loss = 0.04349122\n","Iteration 9493, loss = 0.04348903\n","Iteration 9494, loss = 0.04348677\n","Iteration 9495, loss = 0.04348484\n","Iteration 9496, loss = 0.04348272\n","Iteration 9497, loss = 0.04348058\n","Iteration 9498, loss = 0.04347832\n","Iteration 9499, loss = 0.04347623\n","Iteration 9500, loss = 0.04347418\n","Iteration 9501, loss = 0.04347213\n","Iteration 9502, loss = 0.04346989\n","Iteration 9503, loss = 0.04346766\n","Iteration 9504, loss = 0.04346569\n","Iteration 9505, loss = 0.04346367\n","Iteration 9506, loss = 0.04346152\n","Iteration 9507, loss = 0.04345926\n","Iteration 9508, loss = 0.04345700\n","Iteration 9509, loss = 0.04345499\n","Iteration 9510, loss = 0.04345289\n","Iteration 9511, loss = 0.04345070\n","Iteration 9512, loss = 0.04344864\n","Iteration 9513, loss = 0.04344655\n","Iteration 9514, loss = 0.04344435\n","Iteration 9515, loss = 0.04344220\n","Iteration 9516, loss = 0.04344012\n","Iteration 9517, loss = 0.04343799\n","Iteration 9518, loss = 0.04343586\n","Iteration 9519, loss = 0.04343375\n","Iteration 9520, loss = 0.04343161\n","Iteration 9521, loss = 0.04342947\n","Iteration 9522, loss = 0.04342745\n","Iteration 9523, loss = 0.04342522\n","Iteration 9524, loss = 0.04342320\n","Iteration 9525, loss = 0.04342111\n","Iteration 9526, loss = 0.04341894\n","Iteration 9527, loss = 0.04341683\n","Iteration 9528, loss = 0.04341475\n","Iteration 9529, loss = 0.04341258\n","Iteration 9530, loss = 0.04341059\n","Iteration 9531, loss = 0.04340855\n","Iteration 9532, loss = 0.04340641\n","Iteration 9533, loss = 0.04340420\n","Iteration 9534, loss = 0.04340213\n","Iteration 9535, loss = 0.04340006\n","Iteration 9536, loss = 0.04339803\n","Iteration 9537, loss = 0.04339566\n","Iteration 9538, loss = 0.04339376\n","Iteration 9539, loss = 0.04339176\n","Iteration 9540, loss = 0.04338966\n","Iteration 9541, loss = 0.04338749\n","Iteration 9542, loss = 0.04338530\n","Iteration 9543, loss = 0.04338318\n","Iteration 9544, loss = 0.04338119\n","Iteration 9545, loss = 0.04337908\n","Iteration 9546, loss = 0.04337686\n","Iteration 9547, loss = 0.04337484\n","Iteration 9548, loss = 0.04337280\n","Iteration 9549, loss = 0.04337066\n","Iteration 9550, loss = 0.04336865\n","Iteration 9551, loss = 0.04336627\n","Iteration 9552, loss = 0.04336443\n","Iteration 9553, loss = 0.04336251\n","Iteration 9554, loss = 0.04336046\n","Iteration 9555, loss = 0.04335829\n","Iteration 9556, loss = 0.04335602\n","Iteration 9557, loss = 0.04335413\n","Iteration 9558, loss = 0.04335217\n","Iteration 9559, loss = 0.04335011\n","Iteration 9560, loss = 0.04334797\n","Iteration 9561, loss = 0.04334574\n","Iteration 9562, loss = 0.04334344\n","Iteration 9563, loss = 0.04334129\n","Iteration 9564, loss = 0.04333928\n","Iteration 9565, loss = 0.04333740\n","Iteration 9566, loss = 0.04333517\n","Iteration 9567, loss = 0.04333279\n","Iteration 9568, loss = 0.04333082\n","Iteration 9569, loss = 0.04332876\n","Iteration 9570, loss = 0.04332668\n","Iteration 9571, loss = 0.04332460\n","Iteration 9572, loss = 0.04332254\n","Iteration 9573, loss = 0.04332045\n","Iteration 9574, loss = 0.04331828\n","Iteration 9575, loss = 0.04331629\n","Iteration 9576, loss = 0.04331420\n","Iteration 9577, loss = 0.04331201\n","Iteration 9578, loss = 0.04331014\n","Iteration 9579, loss = 0.04330802\n","Iteration 9580, loss = 0.04330575\n","Iteration 9581, loss = 0.04330371\n","Iteration 9582, loss = 0.04330168\n","Iteration 9583, loss = 0.04329962\n","Iteration 9584, loss = 0.04329755\n","Iteration 9585, loss = 0.04329546\n","Iteration 9586, loss = 0.04329335\n","Iteration 9587, loss = 0.04329134\n","Iteration 9588, loss = 0.04328926\n","Iteration 9589, loss = 0.04328709\n","Iteration 9590, loss = 0.04328497\n","Iteration 9591, loss = 0.04328300\n","Iteration 9592, loss = 0.04328075\n","Iteration 9593, loss = 0.04327884\n","Iteration 9594, loss = 0.04327689\n","Iteration 9595, loss = 0.04327484\n","Iteration 9596, loss = 0.04327270\n","Iteration 9597, loss = 0.04327069\n","Iteration 9598, loss = 0.04326869\n","Iteration 9599, loss = 0.04326656\n","Iteration 9600, loss = 0.04326433\n","Iteration 9601, loss = 0.04326243\n","Iteration 9602, loss = 0.04326042\n","Iteration 9603, loss = 0.04325832\n","Iteration 9604, loss = 0.04325614\n","Iteration 9605, loss = 0.04325415\n","Iteration 9606, loss = 0.04325198\n","Iteration 9607, loss = 0.04324990\n","Iteration 9608, loss = 0.04324788\n","Iteration 9609, loss = 0.04324574\n","Iteration 9610, loss = 0.04324377\n","Iteration 9611, loss = 0.04324180\n","Iteration 9612, loss = 0.04323974\n","Iteration 9613, loss = 0.04323759\n","Iteration 9614, loss = 0.04323538\n","Iteration 9615, loss = 0.04323333\n","Iteration 9616, loss = 0.04323117\n","Iteration 9617, loss = 0.04322909\n","Iteration 9618, loss = 0.04322727\n","Iteration 9619, loss = 0.04322510\n","Iteration 9620, loss = 0.04322301\n","Iteration 9621, loss = 0.04322101\n","Iteration 9622, loss = 0.04321893\n","Iteration 9623, loss = 0.04321691\n","Iteration 9624, loss = 0.04321489\n","Iteration 9625, loss = 0.04321281\n","Iteration 9626, loss = 0.04321081\n","Iteration 9627, loss = 0.04320876\n","Iteration 9628, loss = 0.04320662\n","Iteration 9629, loss = 0.04320453\n","Iteration 9630, loss = 0.04320246\n","Iteration 9631, loss = 0.04320039\n","Iteration 9632, loss = 0.04319836\n","Iteration 9633, loss = 0.04319644\n","Iteration 9634, loss = 0.04319443\n","Iteration 9635, loss = 0.04319233\n","Iteration 9636, loss = 0.04319034\n","Iteration 9637, loss = 0.04318837\n","Iteration 9638, loss = 0.04318628\n","Iteration 9639, loss = 0.04318410\n","Iteration 9640, loss = 0.04318206\n","Iteration 9641, loss = 0.04317995\n","Iteration 9642, loss = 0.04317790\n","Iteration 9643, loss = 0.04317577\n","Iteration 9644, loss = 0.04317377\n","Iteration 9645, loss = 0.04317202\n","Iteration 9646, loss = 0.04316982\n","Iteration 9647, loss = 0.04316770\n","Iteration 9648, loss = 0.04316578\n","Iteration 9649, loss = 0.04316377\n","Iteration 9650, loss = 0.04316166\n","Iteration 9651, loss = 0.04315958\n","Iteration 9652, loss = 0.04315759\n","Iteration 9653, loss = 0.04315549\n","Iteration 9654, loss = 0.04315344\n","Iteration 9655, loss = 0.04315140\n","Iteration 9656, loss = 0.04314928\n","Iteration 9657, loss = 0.04314723\n","Iteration 9658, loss = 0.04314517\n","Iteration 9659, loss = 0.04314310\n","Iteration 9660, loss = 0.04314105\n","Iteration 9661, loss = 0.04313909\n","Iteration 9662, loss = 0.04313707\n","Iteration 9663, loss = 0.04313505\n","Iteration 9664, loss = 0.04313305\n","Iteration 9665, loss = 0.04313097\n","Iteration 9666, loss = 0.04312896\n","Iteration 9667, loss = 0.04312690\n","Iteration 9668, loss = 0.04312485\n","Iteration 9669, loss = 0.04312275\n","Iteration 9670, loss = 0.04312095\n","Iteration 9671, loss = 0.04311875\n","Iteration 9672, loss = 0.04311681\n","Iteration 9673, loss = 0.04311486\n","Iteration 9674, loss = 0.04311283\n","Iteration 9675, loss = 0.04311084\n","Iteration 9676, loss = 0.04310886\n","Iteration 9677, loss = 0.04310681\n","Iteration 9678, loss = 0.04310484\n","Iteration 9679, loss = 0.04310282\n","Iteration 9680, loss = 0.04310071\n","Iteration 9681, loss = 0.04309868\n","Iteration 9682, loss = 0.04309664\n","Iteration 9683, loss = 0.04309448\n","Iteration 9684, loss = 0.04309250\n","Iteration 9685, loss = 0.04309052\n","Iteration 9686, loss = 0.04308848\n","Iteration 9687, loss = 0.04308639\n","Iteration 9688, loss = 0.04308448\n","Iteration 9689, loss = 0.04308257\n","Iteration 9690, loss = 0.04308053\n","Iteration 9691, loss = 0.04307838\n","Iteration 9692, loss = 0.04307651\n","Iteration 9693, loss = 0.04307458\n","Iteration 9694, loss = 0.04307255\n","Iteration 9695, loss = 0.04307043\n","Iteration 9696, loss = 0.04306834\n","Iteration 9697, loss = 0.04306628\n","Iteration 9698, loss = 0.04306439\n","Iteration 9699, loss = 0.04306236\n","Iteration 9700, loss = 0.04306022\n","Iteration 9701, loss = 0.04305828\n","Iteration 9702, loss = 0.04305630\n","Iteration 9703, loss = 0.04305431\n","Iteration 9704, loss = 0.04305224\n","Iteration 9705, loss = 0.04305020\n","Iteration 9706, loss = 0.04304824\n","Iteration 9707, loss = 0.04304615\n","Iteration 9708, loss = 0.04304413\n","Iteration 9709, loss = 0.04304238\n","Iteration 9710, loss = 0.04304016\n","Iteration 9711, loss = 0.04303814\n","Iteration 9712, loss = 0.04303622\n","Iteration 9713, loss = 0.04303429\n","Iteration 9714, loss = 0.04303232\n","Iteration 9715, loss = 0.04303033\n","Iteration 9716, loss = 0.04302832\n","Iteration 9717, loss = 0.04302637\n","Iteration 9718, loss = 0.04302437\n","Iteration 9719, loss = 0.04302227\n","Iteration 9720, loss = 0.04302030\n","Iteration 9721, loss = 0.04301829\n","Iteration 9722, loss = 0.04301616\n","Iteration 9723, loss = 0.04301411\n","Iteration 9724, loss = 0.04301245\n","Iteration 9725, loss = 0.04301038\n","Iteration 9726, loss = 0.04300806\n","Iteration 9727, loss = 0.04300630\n","Iteration 9728, loss = 0.04300442\n","Iteration 9729, loss = 0.04300241\n","Iteration 9730, loss = 0.04300028\n","Iteration 9731, loss = 0.04299832\n","Iteration 9732, loss = 0.04299641\n","Iteration 9733, loss = 0.04299440\n","Iteration 9734, loss = 0.04299230\n","Iteration 9735, loss = 0.04299013\n","Iteration 9736, loss = 0.04298856\n","Iteration 9737, loss = 0.04298657\n","Iteration 9738, loss = 0.04298446\n","Iteration 9739, loss = 0.04298243\n","Iteration 9740, loss = 0.04298034\n","Iteration 9741, loss = 0.04297846\n","Iteration 9742, loss = 0.04297649\n","Iteration 9743, loss = 0.04297442\n","Iteration 9744, loss = 0.04297254\n","Iteration 9745, loss = 0.04297058\n","Iteration 9746, loss = 0.04296851\n","Iteration 9747, loss = 0.04296635\n","Iteration 9748, loss = 0.04296436\n","Iteration 9749, loss = 0.04296240\n","Iteration 9750, loss = 0.04296042\n","Iteration 9751, loss = 0.04295851\n","Iteration 9752, loss = 0.04295651\n","Iteration 9753, loss = 0.04295468\n","Iteration 9754, loss = 0.04295279\n","Iteration 9755, loss = 0.04295081\n","Iteration 9756, loss = 0.04294874\n","Iteration 9757, loss = 0.04294672\n","Iteration 9758, loss = 0.04294478\n","Iteration 9759, loss = 0.04294272\n","Iteration 9760, loss = 0.04294065\n","Iteration 9761, loss = 0.04293866\n","Iteration 9762, loss = 0.04293670\n","Iteration 9763, loss = 0.04293469\n","Iteration 9764, loss = 0.04293279\n","Iteration 9765, loss = 0.04293080\n","Iteration 9766, loss = 0.04292899\n","Iteration 9767, loss = 0.04292711\n","Iteration 9768, loss = 0.04292513\n","Iteration 9769, loss = 0.04292306\n","Iteration 9770, loss = 0.04292107\n","Iteration 9771, loss = 0.04291914\n","Iteration 9772, loss = 0.04291708\n","Iteration 9773, loss = 0.04291499\n","Iteration 9774, loss = 0.04291300\n","Iteration 9775, loss = 0.04291112\n","Iteration 9776, loss = 0.04290917\n","Iteration 9777, loss = 0.04290720\n","Iteration 9778, loss = 0.04290522\n","Iteration 9779, loss = 0.04290336\n","Iteration 9780, loss = 0.04290149\n","Iteration 9781, loss = 0.04289951\n","Iteration 9782, loss = 0.04289745\n","Iteration 9783, loss = 0.04289553\n","Iteration 9784, loss = 0.04289360\n","Iteration 9785, loss = 0.04289156\n","Iteration 9786, loss = 0.04288941\n","Iteration 9787, loss = 0.04288742\n","Iteration 9788, loss = 0.04288568\n","Iteration 9789, loss = 0.04288366\n","Iteration 9790, loss = 0.04288154\n","Iteration 9791, loss = 0.04287978\n","Iteration 9792, loss = 0.04287787\n","Iteration 9793, loss = 0.04287585\n","Iteration 9794, loss = 0.04287399\n","Iteration 9795, loss = 0.04287210\n","Iteration 9796, loss = 0.04287011\n","Iteration 9797, loss = 0.04286804\n","Iteration 9798, loss = 0.04286602\n","Iteration 9799, loss = 0.04286408\n","Iteration 9800, loss = 0.04286205\n","Iteration 9801, loss = 0.04286006\n","Iteration 9802, loss = 0.04285815\n","Iteration 9803, loss = 0.04285614\n","Iteration 9804, loss = 0.04285426\n","Iteration 9805, loss = 0.04285234\n","Iteration 9806, loss = 0.04285033\n","Iteration 9807, loss = 0.04284853\n","Iteration 9808, loss = 0.04284665\n","Iteration 9809, loss = 0.04284467\n","Iteration 9810, loss = 0.04284261\n","Iteration 9811, loss = 0.04284061\n","Iteration 9812, loss = 0.04283878\n","Iteration 9813, loss = 0.04283673\n","Iteration 9814, loss = 0.04283473\n","Iteration 9815, loss = 0.04283283\n","Iteration 9816, loss = 0.04283082\n","Iteration 9817, loss = 0.04282897\n","Iteration 9818, loss = 0.04282707\n","Iteration 9819, loss = 0.04282508\n","Iteration 9820, loss = 0.04282322\n","Iteration 9821, loss = 0.04282134\n","Iteration 9822, loss = 0.04281937\n","Iteration 9823, loss = 0.04281731\n","Iteration 9824, loss = 0.04281539\n","Iteration 9825, loss = 0.04281368\n","Iteration 9826, loss = 0.04281153\n","Iteration 9827, loss = 0.04280954\n","Iteration 9828, loss = 0.04280789\n","Iteration 9829, loss = 0.04280611\n","Iteration 9830, loss = 0.04280423\n","Iteration 9831, loss = 0.04280225\n","Iteration 9832, loss = 0.04280018\n","Iteration 9833, loss = 0.04279821\n","Iteration 9834, loss = 0.04279636\n","Iteration 9835, loss = 0.04279439\n","Iteration 9836, loss = 0.04279229\n","Iteration 9837, loss = 0.04279035\n","Iteration 9838, loss = 0.04278844\n","Iteration 9839, loss = 0.04278648\n","Iteration 9840, loss = 0.04278444\n","Iteration 9841, loss = 0.04278243\n","Iteration 9842, loss = 0.04278065\n","Iteration 9843, loss = 0.04277861\n","Iteration 9844, loss = 0.04277679\n","Iteration 9845, loss = 0.04277493\n","Iteration 9846, loss = 0.04277297\n","Iteration 9847, loss = 0.04277094\n","Iteration 9848, loss = 0.04276901\n","Iteration 9849, loss = 0.04276708\n","Iteration 9850, loss = 0.04276514\n","Iteration 9851, loss = 0.04276320\n","Iteration 9852, loss = 0.04276128\n","Iteration 9853, loss = 0.04275943\n","Iteration 9854, loss = 0.04275751\n","Iteration 9855, loss = 0.04275550\n","Iteration 9856, loss = 0.04275381\n","Iteration 9857, loss = 0.04275178\n","Iteration 9858, loss = 0.04274981\n","Iteration 9859, loss = 0.04274789\n","Iteration 9860, loss = 0.04274602\n","Iteration 9861, loss = 0.04274405\n","Iteration 9862, loss = 0.04274215\n","Iteration 9863, loss = 0.04274015\n","Iteration 9864, loss = 0.04273832\n","Iteration 9865, loss = 0.04273642\n","Iteration 9866, loss = 0.04273443\n","Iteration 9867, loss = 0.04273250\n","Iteration 9868, loss = 0.04273061\n","Iteration 9869, loss = 0.04272885\n","Iteration 9870, loss = 0.04272684\n","Iteration 9871, loss = 0.04272506\n","Iteration 9872, loss = 0.04272318\n","Iteration 9873, loss = 0.04272128\n","Iteration 9874, loss = 0.04271944\n","Iteration 9875, loss = 0.04271751\n","Iteration 9876, loss = 0.04271560\n","Iteration 9877, loss = 0.04271377\n","Iteration 9878, loss = 0.04271183\n","Iteration 9879, loss = 0.04270983\n","Iteration 9880, loss = 0.04270789\n","Iteration 9881, loss = 0.04270593\n","Iteration 9882, loss = 0.04270393\n","Iteration 9883, loss = 0.04270206\n","Iteration 9884, loss = 0.04270048\n","Iteration 9885, loss = 0.04269849\n","Iteration 9886, loss = 0.04269629\n","Iteration 9887, loss = 0.04269448\n","Iteration 9888, loss = 0.04269255\n","Iteration 9889, loss = 0.04269067\n","Iteration 9890, loss = 0.04268883\n","Iteration 9891, loss = 0.04268691\n","Iteration 9892, loss = 0.04268497\n","Iteration 9893, loss = 0.04268302\n","Iteration 9894, loss = 0.04268114\n","Iteration 9895, loss = 0.04267941\n","Iteration 9896, loss = 0.04267731\n","Iteration 9897, loss = 0.04267555\n","Iteration 9898, loss = 0.04267377\n","Iteration 9899, loss = 0.04267185\n","Iteration 9900, loss = 0.04266998\n","Iteration 9901, loss = 0.04266816\n","Iteration 9902, loss = 0.04266624\n","Iteration 9903, loss = 0.04266423\n","Iteration 9904, loss = 0.04266231\n","Iteration 9905, loss = 0.04266046\n","Iteration 9906, loss = 0.04265853\n","Iteration 9907, loss = 0.04265650\n","Iteration 9908, loss = 0.04265468\n","Iteration 9909, loss = 0.04265285\n","Iteration 9910, loss = 0.04265089\n","Iteration 9911, loss = 0.04264892\n","Iteration 9912, loss = 0.04264712\n","Iteration 9913, loss = 0.04264525\n","Iteration 9914, loss = 0.04264340\n","Iteration 9915, loss = 0.04264152\n","Iteration 9916, loss = 0.04263959\n","Iteration 9917, loss = 0.04263768\n","Iteration 9918, loss = 0.04263579\n","Iteration 9919, loss = 0.04263383\n","Iteration 9920, loss = 0.04263222\n","Iteration 9921, loss = 0.04263023\n","Iteration 9922, loss = 0.04262829\n","Iteration 9923, loss = 0.04262651\n","Iteration 9924, loss = 0.04262471\n","Iteration 9925, loss = 0.04262278\n","Iteration 9926, loss = 0.04262104\n","Iteration 9927, loss = 0.04261922\n","Iteration 9928, loss = 0.04261731\n","Iteration 9929, loss = 0.04261531\n","Iteration 9930, loss = 0.04261339\n","Iteration 9931, loss = 0.04261153\n","Iteration 9932, loss = 0.04260955\n","Iteration 9933, loss = 0.04260757\n","Iteration 9934, loss = 0.04260571\n","Iteration 9935, loss = 0.04260380\n","Iteration 9936, loss = 0.04260202\n","Iteration 9937, loss = 0.04260017\n","Iteration 9938, loss = 0.04259824\n","Iteration 9939, loss = 0.04259654\n","Iteration 9940, loss = 0.04259475\n","Iteration 9941, loss = 0.04259286\n","Iteration 9942, loss = 0.04259088\n","Iteration 9943, loss = 0.04258889\n","Iteration 9944, loss = 0.04258703\n","Iteration 9945, loss = 0.04258538\n","Iteration 9946, loss = 0.04258343\n","Iteration 9947, loss = 0.04258154\n","Iteration 9948, loss = 0.04257971\n","Iteration 9949, loss = 0.04257781\n","Iteration 9950, loss = 0.04257599\n","Iteration 9951, loss = 0.04257418\n","Iteration 9952, loss = 0.04257232\n","Iteration 9953, loss = 0.04257040\n","Iteration 9954, loss = 0.04256849\n","Iteration 9955, loss = 0.04256665\n","Iteration 9956, loss = 0.04256469\n","Iteration 9957, loss = 0.04256286\n","Iteration 9958, loss = 0.04256112\n","Iteration 9959, loss = 0.04255914\n","Iteration 9960, loss = 0.04255722\n","Iteration 9961, loss = 0.04255545\n","Iteration 9962, loss = 0.04255365\n","Iteration 9963, loss = 0.04255181\n","Iteration 9964, loss = 0.04254997\n","Iteration 9965, loss = 0.04254809\n","Iteration 9966, loss = 0.04254627\n","Iteration 9967, loss = 0.04254440\n","Iteration 9968, loss = 0.04254244\n","Iteration 9969, loss = 0.04254059\n","Iteration 9970, loss = 0.04253878\n","Iteration 9971, loss = 0.04253679\n","Iteration 9972, loss = 0.04253499\n","Iteration 9973, loss = 0.04253323\n","Iteration 9974, loss = 0.04253138\n","Iteration 9975, loss = 0.04252948\n","Iteration 9976, loss = 0.04252775\n","Iteration 9977, loss = 0.04252598\n","Iteration 9978, loss = 0.04252407\n","Iteration 9979, loss = 0.04252205\n","Iteration 9980, loss = 0.04252036\n","Iteration 9981, loss = 0.04251858\n","Iteration 9982, loss = 0.04251694\n","Iteration 9983, loss = 0.04251490\n","Iteration 9984, loss = 0.04251294\n","Iteration 9985, loss = 0.04251110\n","Iteration 9986, loss = 0.04250941\n","Iteration 9987, loss = 0.04250759\n","Iteration 9988, loss = 0.04250563\n","Iteration 9989, loss = 0.04250394\n","Iteration 9990, loss = 0.04250218\n","Iteration 9991, loss = 0.04250031\n","Iteration 9992, loss = 0.04249835\n","Iteration 9993, loss = 0.04249631\n","Iteration 9994, loss = 0.04249455\n","Iteration 9995, loss = 0.04249286\n","Iteration 9996, loss = 0.04249094\n","Iteration 9997, loss = 0.04248905\n","Iteration 9998, loss = 0.04248715\n","Iteration 9999, loss = 0.04248545\n","Iteration 10000, loss = 0.04248364\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["MLPClassifier(learning_rate_init=0.0001, max_iter=10000, tol=1e-06,\n","              verbose=True)"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(learning_rate_init=0.0001, max_iter=10000, tol=1e-06,\n","              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(learning_rate_init=0.0001, max_iter=10000, tol=1e-06,\n","              verbose=True)</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["redeneural.predict([[6.7,3.0,5.2,2.3]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sk4fhzfrcYj6","executionInfo":{"status":"ok","timestamp":1678450501356,"user_tz":180,"elapsed":580,"user":{"displayName":"João Vitor Braz","userId":"02116333837339986756"}},"outputId":"016329da-1ee2-4230-a3fc-07399e0fa134"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2])"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["from sklearn.neural_network import MLPClassifier\n","import numpy as np\n","dataset = np.loadtxt('c/users/XXX/desktop/XXX/XXX.txt', delimiter=',')\n","entradas = dataset[:,1:]\n","saidas = dataset[:,0]\n","\n","redeneural = MLPClassifier(verbose=True,\n","                           max_iter=,\n","                           )"],"metadata":{"id":"TD5qVRLXggZx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["redeneural.predict([[14.23,1.71,2.43,15.6,127,2.8,3.06,.28,2.29,5.64,1.04,]])"],"metadata":{"id":"T5BpAoPEg-kh"},"execution_count":null,"outputs":[]}]}